{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *   # bring everything in the folder models\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16\"\n",
    "model = VGG16()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch, gamma):\n",
    "    batch_time = AverageMeter()   ## at the begining of each epoch, this should be reset\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    sum_losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()  # measure current time\n",
    "    \n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)  # data loading time\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        sum_loss = model.features[0].weight.abs().sum()\n",
    "        # Add gamma as a factor here\n",
    "        loss = criterion(output, target) + gamma*sum_loss\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        sum_losses.update(sum_loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end) # time spent to process one batch\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n    ## n is impact factor\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "welsh-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [20, 30, 150, 225]\n",
    "    p_adjust_list = [25, 40]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1\n",
    "    if epoch in p_adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['momentum'] = param_group['momentum'] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "small-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.278 (0.278)\tData 0.248 (0.248)\tLoss 2.4627 (2.4627)\tPrec 10.938% (10.938%)\n",
      "Epoch: [0][100/391]\tTime 0.036 (0.038)\tData 0.017 (0.011)\tLoss 2.3911 (2.9762)\tPrec 11.719% (10.272%)\n",
      "Epoch: [0][200/391]\tTime 0.045 (0.037)\tData 0.028 (0.011)\tLoss 2.3643 (2.6624)\tPrec 10.938% (10.459%)\n",
      "Epoch: [0][300/391]\tTime 0.043 (0.036)\tData 0.025 (0.011)\tLoss 2.1542 (2.5469)\tPrec 21.875% (11.101%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 2.1623 (2.1623)\tPrec 19.531% (19.531%)\n",
      " * Prec 16.710% \n",
      "best acc: 16.710000\n",
      "Epoch: [1][0/391]\tTime 0.267 (0.267)\tData 0.243 (0.243)\tLoss 2.0720 (2.0720)\tPrec 20.312% (20.312%)\n",
      "Epoch: [1][100/391]\tTime 0.032 (0.035)\tData 0.000 (0.008)\tLoss 1.9287 (2.0352)\tPrec 21.094% (18.820%)\n",
      "Epoch: [1][200/391]\tTime 0.033 (0.034)\tData 0.001 (0.006)\tLoss 1.9319 (2.0000)\tPrec 25.000% (19.706%)\n",
      "Epoch: [1][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.005)\tLoss 1.8047 (1.9753)\tPrec 28.906% (20.795%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 1.9068 (1.9068)\tPrec 19.531% (19.531%)\n",
      " * Prec 23.430% \n",
      "best acc: 23.430000\n",
      "Epoch: [2][0/391]\tTime 0.274 (0.274)\tData 0.251 (0.251)\tLoss 1.8919 (1.8919)\tPrec 18.750% (18.750%)\n",
      "Epoch: [2][100/391]\tTime 0.032 (0.036)\tData 0.006 (0.008)\tLoss 1.9070 (1.8511)\tPrec 25.781% (25.549%)\n",
      "Epoch: [2][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.005)\tLoss 1.7794 (1.8143)\tPrec 33.594% (27.383%)\n",
      "Epoch: [2][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.004)\tLoss 1.7925 (1.7805)\tPrec 28.125% (28.963%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 1.6964 (1.6964)\tPrec 29.688% (29.688%)\n",
      " * Prec 33.690% \n",
      "best acc: 33.690000\n",
      "Epoch: [3][0/391]\tTime 0.258 (0.258)\tData 0.236 (0.236)\tLoss 1.6593 (1.6593)\tPrec 40.625% (40.625%)\n",
      "Epoch: [3][100/391]\tTime 0.038 (0.036)\tData 0.020 (0.007)\tLoss 1.5615 (1.6126)\tPrec 34.375% (36.262%)\n",
      "Epoch: [3][200/391]\tTime 0.033 (0.035)\tData 0.003 (0.006)\tLoss 1.5426 (1.5886)\tPrec 39.062% (37.547%)\n",
      "Epoch: [3][300/391]\tTime 0.034 (0.035)\tData 0.015 (0.007)\tLoss 1.5873 (1.5679)\tPrec 37.500% (38.738%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 1.5291 (1.5291)\tPrec 44.531% (44.531%)\n",
      " * Prec 38.990% \n",
      "best acc: 38.990000\n",
      "Epoch: [4][0/391]\tTime 0.267 (0.267)\tData 0.243 (0.243)\tLoss 1.3661 (1.3661)\tPrec 47.656% (47.656%)\n",
      "Epoch: [4][100/391]\tTime 0.033 (0.037)\tData 0.002 (0.008)\tLoss 1.2547 (1.4152)\tPrec 50.781% (45.668%)\n",
      "Epoch: [4][200/391]\tTime 0.033 (0.036)\tData 0.002 (0.007)\tLoss 1.4441 (1.3999)\tPrec 41.406% (46.879%)\n",
      "Epoch: [4][300/391]\tTime 0.033 (0.035)\tData 0.002 (0.005)\tLoss 1.3257 (1.3722)\tPrec 52.344% (48.347%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 1.4449 (1.4449)\tPrec 50.781% (50.781%)\n",
      " * Prec 49.480% \n",
      "best acc: 49.480000\n",
      "Epoch: [5][0/391]\tTime 0.253 (0.253)\tData 0.232 (0.232)\tLoss 1.1988 (1.1988)\tPrec 58.594% (58.594%)\n",
      "Epoch: [5][100/391]\tTime 0.033 (0.036)\tData 0.002 (0.006)\tLoss 1.3158 (1.1889)\tPrec 54.688% (57.109%)\n",
      "Epoch: [5][200/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 0.9818 (1.1526)\tPrec 65.625% (58.656%)\n",
      "Epoch: [5][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1201 (1.1317)\tPrec 59.375% (59.596%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 1.0110 (1.0110)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.810% \n",
      "best acc: 63.810000\n",
      "Epoch: [6][0/391]\tTime 0.278 (0.278)\tData 0.255 (0.255)\tLoss 0.9662 (0.9662)\tPrec 64.844% (64.844%)\n",
      "Epoch: [6][100/391]\tTime 0.034 (0.036)\tData 0.002 (0.006)\tLoss 1.1392 (0.9813)\tPrec 60.938% (64.743%)\n",
      "Epoch: [6][200/391]\tTime 0.033 (0.035)\tData 0.001 (0.004)\tLoss 0.8643 (0.9643)\tPrec 70.312% (65.862%)\n",
      "Epoch: [6][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.8996 (0.9453)\tPrec 67.969% (66.713%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.8646 (0.8646)\tPrec 68.750% (68.750%)\n",
      " * Prec 69.390% \n",
      "best acc: 69.390000\n",
      "Epoch: [7][0/391]\tTime 0.287 (0.287)\tData 0.263 (0.263)\tLoss 0.6231 (0.6231)\tPrec 79.688% (79.688%)\n",
      "Epoch: [7][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.007)\tLoss 0.8616 (0.8322)\tPrec 71.094% (70.746%)\n",
      "Epoch: [7][200/391]\tTime 0.034 (0.035)\tData 0.002 (0.004)\tLoss 0.6944 (0.8165)\tPrec 78.125% (71.537%)\n",
      "Epoch: [7][300/391]\tTime 0.035 (0.035)\tData 0.001 (0.003)\tLoss 0.7214 (0.8047)\tPrec 72.656% (71.953%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.8062 (0.8062)\tPrec 73.438% (73.438%)\n",
      " * Prec 71.780% \n",
      "best acc: 71.780000\n",
      "Epoch: [8][0/391]\tTime 0.263 (0.263)\tData 0.241 (0.241)\tLoss 0.6581 (0.6581)\tPrec 78.906% (78.906%)\n",
      "Epoch: [8][100/391]\tTime 0.033 (0.037)\tData 0.002 (0.007)\tLoss 0.7437 (0.7329)\tPrec 74.219% (74.892%)\n",
      "Epoch: [8][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.005)\tLoss 0.6733 (0.7282)\tPrec 78.125% (74.961%)\n",
      "Epoch: [8][300/391]\tTime 0.036 (0.035)\tData 0.002 (0.004)\tLoss 0.6523 (0.7183)\tPrec 76.562% (75.343%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.7611 (0.7611)\tPrec 71.094% (71.094%)\n",
      " * Prec 74.180% \n",
      "best acc: 74.180000\n",
      "Epoch: [9][0/391]\tTime 0.272 (0.272)\tData 0.250 (0.250)\tLoss 0.5813 (0.5813)\tPrec 79.688% (79.688%)\n",
      "Epoch: [9][100/391]\tTime 0.033 (0.037)\tData 0.002 (0.006)\tLoss 0.4587 (0.6456)\tPrec 83.594% (78.264%)\n",
      "Epoch: [9][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.4696 (0.6402)\tPrec 85.156% (78.424%)\n",
      "Epoch: [9][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.4209 (0.6399)\tPrec 82.812% (78.538%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.248 (0.248)\tLoss 0.7500 (0.7500)\tPrec 75.781% (75.781%)\n",
      " * Prec 72.990% \n",
      "best acc: 74.180000\n",
      "Epoch: [10][0/391]\tTime 0.249 (0.249)\tData 0.227 (0.227)\tLoss 0.5898 (0.5898)\tPrec 81.250% (81.250%)\n",
      "Epoch: [10][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.005)\tLoss 0.6408 (0.5789)\tPrec 78.125% (80.337%)\n",
      "Epoch: [10][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.6259 (0.5781)\tPrec 79.688% (80.523%)\n",
      "Epoch: [10][300/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 0.6302 (0.5760)\tPrec 80.469% (80.624%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.6894 (0.6894)\tPrec 74.219% (74.219%)\n",
      " * Prec 77.170% \n",
      "best acc: 77.170000\n",
      "Epoch: [11][0/391]\tTime 0.268 (0.268)\tData 0.242 (0.242)\tLoss 0.5295 (0.5295)\tPrec 81.250% (81.250%)\n",
      "Epoch: [11][100/391]\tTime 0.036 (0.038)\tData 0.013 (0.009)\tLoss 0.6960 (0.5231)\tPrec 76.562% (82.333%)\n",
      "Epoch: [11][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.005)\tLoss 0.6487 (0.5286)\tPrec 80.469% (82.171%)\n",
      "Epoch: [11][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.5796 (0.5283)\tPrec 85.156% (82.179%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.5394 (0.5394)\tPrec 81.250% (81.250%)\n",
      " * Prec 80.980% \n",
      "best acc: 80.980000\n",
      "Epoch: [12][0/391]\tTime 0.262 (0.262)\tData 0.241 (0.241)\tLoss 0.4560 (0.4560)\tPrec 83.594% (83.594%)\n",
      "Epoch: [12][100/391]\tTime 0.034 (0.037)\tData 0.003 (0.005)\tLoss 0.4369 (0.4829)\tPrec 85.938% (83.253%)\n",
      "Epoch: [12][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.5297 (0.4868)\tPrec 86.719% (83.345%)\n",
      "Epoch: [12][300/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 0.4151 (0.4866)\tPrec 86.719% (83.422%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.5749 (0.5749)\tPrec 81.250% (81.250%)\n",
      " * Prec 80.820% \n",
      "best acc: 80.980000\n",
      "Epoch: [13][0/391]\tTime 0.287 (0.287)\tData 0.263 (0.263)\tLoss 0.4724 (0.4724)\tPrec 86.719% (86.719%)\n",
      "Epoch: [13][100/391]\tTime 0.034 (0.038)\tData 0.002 (0.006)\tLoss 0.3244 (0.4577)\tPrec 90.625% (84.592%)\n",
      "Epoch: [13][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.3920 (0.4503)\tPrec 85.938% (84.783%)\n",
      "Epoch: [13][300/391]\tTime 0.033 (0.036)\tData 0.002 (0.003)\tLoss 0.4103 (0.4534)\tPrec 85.156% (84.681%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.5234 (0.5234)\tPrec 83.594% (83.594%)\n",
      " * Prec 83.140% \n",
      "best acc: 83.140000\n",
      "Epoch: [14][0/391]\tTime 0.289 (0.289)\tData 0.269 (0.269)\tLoss 0.4579 (0.4579)\tPrec 83.594% (83.594%)\n",
      "Epoch: [14][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.008)\tLoss 0.4407 (0.4258)\tPrec 85.156% (85.558%)\n",
      "Epoch: [14][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 0.5442 (0.4223)\tPrec 83.594% (85.770%)\n",
      "Epoch: [14][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.3898 (0.4215)\tPrec 87.500% (85.816%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.4559 (0.4559)\tPrec 83.594% (83.594%)\n",
      " * Prec 83.350% \n",
      "best acc: 83.350000\n",
      "Epoch: [15][0/391]\tTime 0.239 (0.239)\tData 0.218 (0.218)\tLoss 0.4974 (0.4974)\tPrec 87.500% (87.500%)\n",
      "Epoch: [15][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.007)\tLoss 0.3659 (0.3972)\tPrec 89.062% (86.502%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.005)\tLoss 0.2712 (0.3893)\tPrec 89.062% (86.812%)\n",
      "Epoch: [15][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.5353 (0.3924)\tPrec 83.594% (86.641%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.4111 (0.4111)\tPrec 84.375% (84.375%)\n",
      " * Prec 84.520% \n",
      "best acc: 84.520000\n",
      "Epoch: [16][0/391]\tTime 0.262 (0.262)\tData 0.240 (0.240)\tLoss 0.3995 (0.3995)\tPrec 85.156% (85.156%)\n",
      "Epoch: [16][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.007)\tLoss 0.3618 (0.3650)\tPrec 85.938% (87.577%)\n",
      "Epoch: [16][200/391]\tTime 0.034 (0.036)\tData 0.001 (0.004)\tLoss 0.5349 (0.3698)\tPrec 82.031% (87.438%)\n",
      "Epoch: [16][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 0.3729 (0.3711)\tPrec 86.719% (87.417%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.238 (0.238)\tLoss 0.3823 (0.3823)\tPrec 86.719% (86.719%)\n",
      " * Prec 85.010% \n",
      "best acc: 85.010000\n",
      "Epoch: [17][0/391]\tTime 0.296 (0.296)\tData 0.273 (0.273)\tLoss 0.2898 (0.2898)\tPrec 89.062% (89.062%)\n",
      "Epoch: [17][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.006)\tLoss 0.3351 (0.3426)\tPrec 87.500% (88.598%)\n",
      "Epoch: [17][200/391]\tTime 0.035 (0.036)\tData 0.003 (0.004)\tLoss 0.4024 (0.3443)\tPrec 83.594% (88.382%)\n",
      "Epoch: [17][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.3735 (0.3490)\tPrec 86.719% (88.017%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 0.3613 (0.3613)\tPrec 87.500% (87.500%)\n",
      " * Prec 85.400% \n",
      "best acc: 85.400000\n",
      "Epoch: [18][0/391]\tTime 0.263 (0.263)\tData 0.242 (0.242)\tLoss 0.3128 (0.3128)\tPrec 91.406% (91.406%)\n",
      "Epoch: [18][100/391]\tTime 0.035 (0.037)\tData 0.001 (0.006)\tLoss 0.3007 (0.3255)\tPrec 87.500% (89.032%)\n",
      "Epoch: [18][200/391]\tTime 0.034 (0.036)\tData 0.001 (0.005)\tLoss 0.1580 (0.3275)\tPrec 95.312% (89.028%)\n",
      "Epoch: [18][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 0.1894 (0.3271)\tPrec 96.875% (89.024%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.270 (0.270)\tLoss 0.3868 (0.3868)\tPrec 89.062% (89.062%)\n",
      " * Prec 83.140% \n",
      "best acc: 85.400000\n",
      "Epoch: [19][0/391]\tTime 0.287 (0.287)\tData 0.261 (0.261)\tLoss 0.2832 (0.2832)\tPrec 91.406% (91.406%)\n",
      "Epoch: [19][100/391]\tTime 0.034 (0.037)\tData 0.001 (0.006)\tLoss 0.2747 (0.2950)\tPrec 89.062% (89.898%)\n",
      "Epoch: [19][200/391]\tTime 0.036 (0.036)\tData 0.002 (0.004)\tLoss 0.2322 (0.3029)\tPrec 92.969% (89.665%)\n",
      "Epoch: [19][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.003)\tLoss 0.4527 (0.3065)\tPrec 86.719% (89.584%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 0.2927 (0.2927)\tPrec 92.188% (92.188%)\n",
      " * Prec 85.890% \n",
      "best acc: 85.890000\n",
      "Epoch: [20][0/391]\tTime 0.243 (0.243)\tData 0.221 (0.221)\tLoss 0.3135 (0.3135)\tPrec 88.281% (88.281%)\n",
      "Epoch: [20][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.005)\tLoss 0.2146 (0.2281)\tPrec 91.406% (92.110%)\n",
      "Epoch: [20][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1407 (0.2208)\tPrec 94.531% (92.432%)\n",
      "Epoch: [20][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1657 (0.2150)\tPrec 92.188% (92.717%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.242 (0.242)\tLoss 0.1651 (0.1651)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.760% \n",
      "best acc: 89.760000\n",
      "Epoch: [21][0/391]\tTime 0.277 (0.277)\tData 0.253 (0.253)\tLoss 0.1784 (0.1784)\tPrec 94.531% (94.531%)\n",
      "Epoch: [21][100/391]\tTime 0.053 (0.038)\tData 0.033 (0.009)\tLoss 0.1610 (0.1772)\tPrec 94.531% (93.959%)\n",
      "Epoch: [21][200/391]\tTime 0.035 (0.037)\tData 0.001 (0.006)\tLoss 0.1695 (0.1760)\tPrec 95.312% (94.073%)\n",
      "Epoch: [21][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.005)\tLoss 0.2479 (0.1788)\tPrec 93.750% (93.978%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.1742 (0.1742)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.890% \n",
      "best acc: 89.890000\n",
      "Epoch: [22][0/391]\tTime 0.299 (0.299)\tData 0.277 (0.277)\tLoss 0.2248 (0.2248)\tPrec 90.625% (90.625%)\n",
      "Epoch: [22][100/391]\tTime 0.036 (0.038)\tData 0.004 (0.007)\tLoss 0.0784 (0.1612)\tPrec 97.656% (94.446%)\n",
      "Epoch: [22][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.1644 (0.1681)\tPrec 92.969% (94.263%)\n",
      "Epoch: [22][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1644 (0.1669)\tPrec 92.969% (94.399%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.230 (0.230)\tLoss 0.1701 (0.1701)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.950% \n",
      "best acc: 89.950000\n",
      "Epoch: [23][0/391]\tTime 0.235 (0.235)\tData 0.211 (0.211)\tLoss 0.1957 (0.1957)\tPrec 92.188% (92.188%)\n",
      "Epoch: [23][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.2293 (0.1582)\tPrec 92.969% (94.407%)\n",
      "Epoch: [23][200/391]\tTime 0.036 (0.036)\tData 0.001 (0.004)\tLoss 0.1890 (0.1608)\tPrec 92.969% (94.356%)\n",
      "Epoch: [23][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1613 (0.1592)\tPrec 95.312% (94.503%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.1599 (0.1599)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.230% \n",
      "best acc: 90.230000\n",
      "Epoch: [24][0/391]\tTime 0.284 (0.284)\tData 0.264 (0.264)\tLoss 0.1998 (0.1998)\tPrec 91.406% (91.406%)\n",
      "Epoch: [24][100/391]\tTime 0.035 (0.038)\tData 0.003 (0.009)\tLoss 0.1955 (0.1527)\tPrec 93.750% (94.678%)\n",
      "Epoch: [24][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.005)\tLoss 0.1326 (0.1486)\tPrec 96.094% (94.807%)\n",
      "Epoch: [24][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1950 (0.1498)\tPrec 92.969% (94.793%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.1929 (0.1929)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.200% \n",
      "best acc: 90.230000\n",
      "Epoch: [25][0/391]\tTime 0.276 (0.276)\tData 0.252 (0.252)\tLoss 0.2424 (0.2424)\tPrec 91.406% (91.406%)\n",
      "Epoch: [25][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 0.2206 (0.1331)\tPrec 92.969% (95.459%)\n",
      "Epoch: [25][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.1118 (0.1336)\tPrec 96.875% (95.491%)\n",
      "Epoch: [25][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.003)\tLoss 0.0934 (0.1323)\tPrec 97.656% (95.481%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.230 (0.230)\tLoss 0.1758 (0.1758)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.340% \n",
      "best acc: 90.340000\n",
      "Epoch: [26][0/391]\tTime 0.234 (0.234)\tData 0.213 (0.213)\tLoss 0.2525 (0.2525)\tPrec 92.188% (92.188%)\n",
      "Epoch: [26][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.1215 (0.1291)\tPrec 95.312% (95.529%)\n",
      "Epoch: [26][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.1269 (0.1345)\tPrec 94.531% (95.414%)\n",
      "Epoch: [26][300/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 0.1998 (0.1334)\tPrec 92.969% (95.494%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.2028 (0.2028)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.430% \n",
      "best acc: 90.430000\n",
      "Epoch: [27][0/391]\tTime 0.266 (0.266)\tData 0.244 (0.244)\tLoss 0.1659 (0.1659)\tPrec 94.531% (94.531%)\n",
      "Epoch: [27][100/391]\tTime 0.037 (0.037)\tData 0.002 (0.007)\tLoss 0.1458 (0.1338)\tPrec 95.312% (95.444%)\n",
      "Epoch: [27][200/391]\tTime 0.034 (0.036)\tData 0.001 (0.004)\tLoss 0.2870 (0.1352)\tPrec 90.625% (95.441%)\n",
      "Epoch: [27][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.003)\tLoss 0.1460 (0.1332)\tPrec 94.531% (95.564%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.1848 (0.1848)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.400% \n",
      "best acc: 90.430000\n",
      "Epoch: [28][0/391]\tTime 0.257 (0.257)\tData 0.235 (0.235)\tLoss 0.1471 (0.1471)\tPrec 95.312% (95.312%)\n",
      "Epoch: [28][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.007)\tLoss 0.1232 (0.1324)\tPrec 94.531% (95.514%)\n",
      "Epoch: [28][200/391]\tTime 0.035 (0.036)\tData 0.004 (0.004)\tLoss 0.0812 (0.1286)\tPrec 97.656% (95.608%)\n",
      "Epoch: [28][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1381 (0.1311)\tPrec 93.750% (95.549%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.1875 (0.1875)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.400% \n",
      "best acc: 90.430000\n",
      "Epoch: [29][0/391]\tTime 0.246 (0.246)\tData 0.226 (0.226)\tLoss 0.1211 (0.1211)\tPrec 96.875% (96.875%)\n",
      "Epoch: [29][100/391]\tTime 0.033 (0.037)\tData 0.002 (0.005)\tLoss 0.0889 (0.1225)\tPrec 96.094% (95.900%)\n",
      "Epoch: [29][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.0474 (0.1261)\tPrec 98.438% (95.744%)\n",
      "Epoch: [29][300/391]\tTime 0.035 (0.036)\tData 0.004 (0.003)\tLoss 0.1826 (0.1281)\tPrec 94.531% (95.642%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.1685 (0.1685)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.440% \n",
      "best acc: 90.440000\n",
      "Epoch: [30][0/391]\tTime 0.278 (0.278)\tData 0.255 (0.255)\tLoss 0.0776 (0.0776)\tPrec 97.656% (97.656%)\n",
      "Epoch: [30][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.005)\tLoss 0.0509 (0.1190)\tPrec 99.219% (96.047%)\n",
      "Epoch: [30][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1161 (0.1177)\tPrec 95.312% (96.175%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.003)\tLoss 0.0397 (0.1212)\tPrec 100.000% (96.055%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.1800 (0.1800)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.440% \n",
      "best acc: 90.440000\n",
      "Epoch: [31][0/391]\tTime 0.234 (0.234)\tData 0.215 (0.215)\tLoss 0.1954 (0.1954)\tPrec 95.312% (95.312%)\n",
      "Epoch: [31][100/391]\tTime 0.035 (0.037)\tData 0.001 (0.005)\tLoss 0.1067 (0.1195)\tPrec 95.312% (96.047%)\n",
      "Epoch: [31][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.003)\tLoss 0.1322 (0.1209)\tPrec 96.875% (95.923%)\n",
      "Epoch: [31][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.003)\tLoss 0.0958 (0.1209)\tPrec 96.094% (95.946%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.240 (0.240)\tLoss 0.1757 (0.1757)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.330% \n",
      "best acc: 90.440000\n",
      "Epoch: [32][0/391]\tTime 0.269 (0.269)\tData 0.246 (0.246)\tLoss 0.1019 (0.1019)\tPrec 96.094% (96.094%)\n",
      "Epoch: [32][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.1187 (0.1252)\tPrec 97.656% (95.838%)\n",
      "Epoch: [32][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 0.0741 (0.1226)\tPrec 98.438% (95.919%)\n",
      "Epoch: [32][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1108 (0.1231)\tPrec 96.875% (95.876%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.232 (0.232)\tLoss 0.1780 (0.1780)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.430% \n",
      "best acc: 90.440000\n",
      "Epoch: [33][0/391]\tTime 0.260 (0.260)\tData 0.239 (0.239)\tLoss 0.1474 (0.1474)\tPrec 95.312% (95.312%)\n",
      "Epoch: [33][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 0.1516 (0.1236)\tPrec 94.531% (95.730%)\n",
      "Epoch: [33][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.0645 (0.1218)\tPrec 96.875% (95.818%)\n",
      "Epoch: [33][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1513 (0.1207)\tPrec 94.531% (95.884%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.1763 (0.1763)\tPrec 90.625% (90.625%)\n",
      " * Prec 90.410% \n",
      "best acc: 90.440000\n",
      "Epoch: [34][0/391]\tTime 0.277 (0.277)\tData 0.253 (0.253)\tLoss 0.1346 (0.1346)\tPrec 96.094% (96.094%)\n",
      "Epoch: [34][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 0.0480 (0.1195)\tPrec 98.438% (96.016%)\n",
      "Epoch: [34][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.0986 (0.1215)\tPrec 96.875% (95.946%)\n",
      "Epoch: [34][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1374 (0.1245)\tPrec 96.094% (95.795%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.1799 (0.1799)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.430% \n",
      "best acc: 90.440000\n",
      "Epoch: [35][0/391]\tTime 0.264 (0.264)\tData 0.241 (0.241)\tLoss 0.1509 (0.1509)\tPrec 93.750% (93.750%)\n",
      "Epoch: [35][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 0.1399 (0.1254)\tPrec 96.875% (95.753%)\n",
      "Epoch: [35][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.1915 (0.1222)\tPrec 94.531% (95.752%)\n",
      "Epoch: [35][300/391]\tTime 0.033 (0.036)\tData 0.002 (0.003)\tLoss 0.0307 (0.1217)\tPrec 100.000% (95.826%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.237 (0.237)\tLoss 0.1660 (0.1660)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.460% \n",
      "best acc: 90.460000\n",
      "Epoch: [36][0/391]\tTime 0.282 (0.282)\tData 0.260 (0.260)\tLoss 0.1093 (0.1093)\tPrec 96.094% (96.094%)\n",
      "Epoch: [36][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.0664 (0.1205)\tPrec 97.656% (95.885%)\n",
      "Epoch: [36][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 0.1563 (0.1242)\tPrec 94.531% (95.818%)\n",
      "Epoch: [36][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1820 (0.1224)\tPrec 95.312% (95.878%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.1813 (0.1813)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.320% \n",
      "best acc: 90.460000\n",
      "Epoch: [37][0/391]\tTime 0.264 (0.264)\tData 0.241 (0.241)\tLoss 0.2190 (0.2190)\tPrec 92.188% (92.188%)\n",
      "Epoch: [37][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.1955 (0.1221)\tPrec 95.312% (95.761%)\n",
      "Epoch: [37][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1115 (0.1221)\tPrec 96.875% (95.845%)\n",
      "Epoch: [37][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.003)\tLoss 0.1756 (0.1239)\tPrec 92.969% (95.733%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.1717 (0.1717)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.320% \n",
      "best acc: 90.460000\n",
      "Epoch: [38][0/391]\tTime 0.261 (0.261)\tData 0.237 (0.237)\tLoss 0.0745 (0.0745)\tPrec 97.656% (97.656%)\n",
      "Epoch: [38][100/391]\tTime 0.036 (0.037)\tData 0.002 (0.006)\tLoss 0.0818 (0.1217)\tPrec 96.875% (95.761%)\n",
      "Epoch: [38][200/391]\tTime 0.035 (0.036)\tData 0.003 (0.004)\tLoss 0.1739 (0.1250)\tPrec 94.531% (95.666%)\n",
      "Epoch: [38][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1215 (0.1222)\tPrec 95.312% (95.800%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.237 (0.237)\tLoss 0.1701 (0.1701)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.420% \n",
      "best acc: 90.460000\n",
      "Epoch: [39][0/391]\tTime 0.259 (0.259)\tData 0.235 (0.235)\tLoss 0.1414 (0.1414)\tPrec 93.750% (93.750%)\n",
      "Epoch: [39][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 0.1768 (0.1235)\tPrec 92.188% (95.715%)\n",
      "Epoch: [39][200/391]\tTime 0.036 (0.036)\tData 0.002 (0.004)\tLoss 0.0701 (0.1205)\tPrec 96.875% (95.814%)\n",
      "Epoch: [39][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1977 (0.1222)\tPrec 92.188% (95.816%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.246 (0.246)\tLoss 0.1641 (0.1641)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.390% \n",
      "best acc: 90.460000\n",
      "Epoch: [40][0/391]\tTime 0.281 (0.281)\tData 0.257 (0.257)\tLoss 0.1044 (0.1044)\tPrec 96.875% (96.875%)\n",
      "Epoch: [40][100/391]\tTime 0.037 (0.038)\tData 0.017 (0.007)\tLoss 0.1458 (0.1289)\tPrec 95.312% (95.599%)\n",
      "Epoch: [40][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.005)\tLoss 0.0504 (0.1221)\tPrec 98.438% (95.810%)\n",
      "Epoch: [40][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.2040 (0.1235)\tPrec 92.969% (95.785%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.244 (0.244)\tLoss 0.1698 (0.1698)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.380% \n",
      "best acc: 90.460000\n",
      "Epoch: [41][0/391]\tTime 0.257 (0.257)\tData 0.236 (0.236)\tLoss 0.0701 (0.0701)\tPrec 97.656% (97.656%)\n",
      "Epoch: [41][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 0.1654 (0.1243)\tPrec 93.750% (95.877%)\n",
      "Epoch: [41][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.0682 (0.1199)\tPrec 98.438% (96.063%)\n",
      "Epoch: [41][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1590 (0.1203)\tPrec 94.531% (96.047%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.1766 (0.1766)\tPrec 91.406% (91.406%)\n",
      " * Prec 90.400% \n",
      "best acc: 90.460000\n",
      "Epoch: [42][0/391]\tTime 0.244 (0.244)\tData 0.223 (0.223)\tLoss 0.0779 (0.0779)\tPrec 96.094% (96.094%)\n",
      "Epoch: [42][100/391]\tTime 0.034 (0.037)\tData 0.001 (0.006)\tLoss 0.1508 (0.1279)\tPrec 93.750% (95.630%)\n",
      "Epoch: [42][200/391]\tTime 0.036 (0.036)\tData 0.001 (0.004)\tLoss 0.0740 (0.1244)\tPrec 97.656% (95.705%)\n",
      "Epoch: [42][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.003)\tLoss 0.0589 (0.1239)\tPrec 97.656% (95.780%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.1731 (0.1731)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.450% \n",
      "best acc: 90.460000\n",
      "Epoch: [43][0/391]\tTime 0.265 (0.265)\tData 0.240 (0.240)\tLoss 0.0503 (0.0503)\tPrec 98.438% (98.438%)\n",
      "Epoch: [43][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.005)\tLoss 0.1104 (0.1163)\tPrec 96.094% (96.156%)\n",
      "Epoch: [43][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1189 (0.1208)\tPrec 93.750% (96.000%)\n",
      "Epoch: [43][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.1104 (0.1238)\tPrec 96.094% (95.842%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.1683 (0.1683)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.470% \n",
      "best acc: 90.470000\n",
      "Epoch: [44][0/391]\tTime 0.254 (0.254)\tData 0.231 (0.231)\tLoss 0.1786 (0.1786)\tPrec 93.750% (93.750%)\n",
      "Epoch: [44][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.1418 (0.1259)\tPrec 96.094% (95.854%)\n",
      "Epoch: [44][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.0933 (0.1277)\tPrec 96.875% (95.717%)\n",
      "Epoch: [44][300/391]\tTime 0.034 (0.036)\tData 0.001 (0.003)\tLoss 0.0873 (0.1249)\tPrec 97.656% (95.816%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.1723 (0.1723)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.260% \n",
      "best acc: 90.470000\n"
     ]
    }
   ],
   "source": [
    "# This cell is from the website\n",
    "\n",
    "lr = 0.05\n",
    "weight_decay = 1e-4\n",
    "epochs = 45\n",
    "best_prec = 0\n",
    "\n",
    "gamma = 0\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# weight decay: for regularization to prevent overfitting\n",
    "\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "    \n",
    "fdir = 'result/'+str(model_name)\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(trainloader, model, criterion, optimizer, epoch, gamma)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hydraulic-passport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.1683 (0.1683)\tPrec 92.188% (92.188%)\n",
      " * Prec 90.470% \n",
      "Weight sum: tensor(334.6383, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "fdir = 'result/'+str(model_name)+'/model_best.pth.tar'\n",
    "\n",
    "checkpoint = torch.load(fdir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "prec = validate(testloader, model, criterion)\n",
    "print(\"Weight sum:\", model.features[0].weight.abs().sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7869fffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 2.305 (2.305)\tData 0.192 (0.192)\tLoss 169.2770 (169.2770)\tPrec 10.938% (10.938%)\n",
      "Epoch: [0][100/391]\tTime 0.032 (0.056)\tData 0.004 (0.008)\tLoss 105.8183 (178.7593)\tPrec 7.812% (9.886%)\n",
      "Epoch: [0][200/391]\tTime 0.033 (0.044)\tData 0.001 (0.005)\tLoss 97.9920 (140.9062)\tPrec 10.938% (10.028%)\n",
      "Epoch: [0][300/391]\tTime 0.033 (0.041)\tData 0.000 (0.005)\tLoss 94.9430 (126.8525)\tPrec 7.812% (10.148%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 2.3038 (2.3038)\tPrec 8.594% (8.594%)\n",
      " * Prec 10.000% \n",
      "best acc: 10.000000\n",
      "Epoch: [1][0/391]\tTime 0.244 (0.244)\tData 0.221 (0.221)\tLoss 96.2724 (96.2724)\tPrec 6.250% (6.250%)\n",
      "Epoch: [1][100/391]\tTime 0.032 (0.035)\tData 0.001 (0.005)\tLoss 95.7760 (95.9580)\tPrec 10.156% (10.295%)\n",
      "Epoch: [1][200/391]\tTime 0.037 (0.035)\tData 0.019 (0.006)\tLoss 98.9733 (95.8596)\tPrec 10.156% (10.417%)\n",
      "Epoch: [1][300/391]\tTime 0.033 (0.035)\tData 0.004 (0.007)\tLoss 95.2933 (95.6353)\tPrec 8.594% (10.405%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 2.2827 (2.2827)\tPrec 10.156% (10.156%)\n",
      " * Prec 10.640% \n",
      "best acc: 10.640000\n",
      "Epoch: [2][0/391]\tTime 0.262 (0.262)\tData 0.239 (0.239)\tLoss 94.0370 (94.0370)\tPrec 8.594% (8.594%)\n",
      "Epoch: [2][100/391]\tTime 0.033 (0.036)\tData 0.003 (0.008)\tLoss 95.4395 (95.1560)\tPrec 10.156% (10.396%)\n",
      "Epoch: [2][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.005)\tLoss 95.0022 (95.3105)\tPrec 7.031% (10.086%)\n",
      "Epoch: [2][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.005)\tLoss 91.6958 (95.3688)\tPrec 17.188% (10.392%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 2.3486 (2.3486)\tPrec 17.969% (17.969%)\n",
      " * Prec 13.160% \n",
      "best acc: 13.160000\n",
      "Epoch: [3][0/391]\tTime 0.261 (0.261)\tData 0.237 (0.237)\tLoss 94.2939 (94.2939)\tPrec 7.812% (7.812%)\n",
      "Epoch: [3][100/391]\tTime 0.033 (0.036)\tData 0.001 (0.007)\tLoss 94.7718 (95.2233)\tPrec 8.594% (10.845%)\n",
      "Epoch: [3][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.004)\tLoss 93.9787 (95.1009)\tPrec 11.719% (10.755%)\n",
      "Epoch: [3][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.004)\tLoss 96.3563 (95.1278)\tPrec 10.156% (10.862%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 2.3153 (2.3153)\tPrec 7.812% (7.812%)\n",
      " * Prec 10.440% \n",
      "best acc: 13.160000\n",
      "Epoch: [4][0/391]\tTime 0.266 (0.266)\tData 0.245 (0.245)\tLoss 91.9670 (91.9670)\tPrec 10.938% (10.938%)\n",
      "Epoch: [4][100/391]\tTime 0.033 (0.036)\tData 0.001 (0.008)\tLoss 93.7299 (94.8380)\tPrec 8.594% (10.736%)\n",
      "Epoch: [4][200/391]\tTime 0.035 (0.035)\tData 0.000 (0.006)\tLoss 93.1171 (95.0278)\tPrec 7.031% (11.004%)\n",
      "Epoch: [4][300/391]\tTime 0.033 (0.035)\tData 0.002 (0.005)\tLoss 94.8473 (95.0439)\tPrec 12.500% (10.932%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 2.3032 (2.3032)\tPrec 14.844% (14.844%)\n",
      " * Prec 9.990% \n",
      "best acc: 13.160000\n",
      "Epoch: [5][0/391]\tTime 0.256 (0.256)\tData 0.231 (0.231)\tLoss 94.6869 (94.6869)\tPrec 4.688% (4.688%)\n",
      "Epoch: [5][100/391]\tTime 0.033 (0.037)\tData 0.002 (0.007)\tLoss 96.3272 (95.2930)\tPrec 9.375% (12.183%)\n",
      "Epoch: [5][200/391]\tTime 0.033 (0.036)\tData 0.001 (0.006)\tLoss 93.6412 (95.8998)\tPrec 13.281% (11.991%)\n",
      "Epoch: [5][300/391]\tTime 0.033 (0.035)\tData 0.007 (0.005)\tLoss 98.2945 (96.4239)\tPrec 9.375% (12.033%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 2.1797 (2.1797)\tPrec 19.531% (19.531%)\n",
      " * Prec 14.800% \n",
      "best acc: 14.800000\n",
      "Epoch: [6][0/391]\tTime 0.298 (0.298)\tData 0.274 (0.274)\tLoss 99.6122 (99.6122)\tPrec 10.938% (10.938%)\n",
      "Epoch: [6][100/391]\tTime 0.034 (0.037)\tData 0.000 (0.007)\tLoss 102.8860 (99.1740)\tPrec 10.938% (13.985%)\n",
      "Epoch: [6][200/391]\tTime 0.033 (0.035)\tData 0.002 (0.006)\tLoss 103.9156 (99.8003)\tPrec 14.844% (14.968%)\n",
      "Epoch: [6][300/391]\tTime 0.033 (0.035)\tData 0.002 (0.005)\tLoss 105.5193 (100.6246)\tPrec 10.156% (15.308%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 2.2352 (2.2352)\tPrec 10.938% (10.938%)\n",
      " * Prec 16.690% \n",
      "best acc: 16.690000\n",
      "Epoch: [7][0/391]\tTime 0.288 (0.288)\tData 0.264 (0.264)\tLoss 97.7980 (97.7980)\tPrec 16.406% (16.406%)\n",
      "Epoch: [7][100/391]\tTime 0.032 (0.038)\tData 0.002 (0.011)\tLoss 101.2312 (100.8334)\tPrec 14.844% (16.383%)\n",
      "Epoch: [7][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.006)\tLoss 99.9249 (101.0038)\tPrec 14.844% (16.468%)\n",
      "Epoch: [7][300/391]\tTime 0.034 (0.036)\tData 0.001 (0.005)\tLoss 97.6823 (101.0362)\tPrec 21.094% (16.759%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 2.1429 (2.1429)\tPrec 14.844% (14.844%)\n",
      " * Prec 17.490% \n",
      "best acc: 17.490000\n",
      "Epoch: [8][0/391]\tTime 0.301 (0.301)\tData 0.277 (0.277)\tLoss 99.5838 (99.5838)\tPrec 16.406% (16.406%)\n",
      "Epoch: [8][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.008)\tLoss 104.7947 (102.0408)\tPrec 14.844% (17.690%)\n",
      "Epoch: [8][200/391]\tTime 0.033 (0.036)\tData 0.002 (0.005)\tLoss 101.0555 (101.3991)\tPrec 18.750% (17.634%)\n",
      "Epoch: [8][300/391]\tTime 0.035 (0.035)\tData 0.002 (0.004)\tLoss 99.9712 (100.9708)\tPrec 21.875% (17.673%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 2.1645 (2.1645)\tPrec 16.406% (16.406%)\n",
      " * Prec 15.400% \n",
      "best acc: 17.490000\n",
      "Epoch: [9][0/391]\tTime 0.304 (0.304)\tData 0.280 (0.280)\tLoss 100.1059 (100.1059)\tPrec 25.000% (25.000%)\n",
      "Epoch: [9][100/391]\tTime 0.033 (0.038)\tData 0.003 (0.007)\tLoss 98.7079 (99.6043)\tPrec 17.188% (18.433%)\n",
      "Epoch: [9][200/391]\tTime 0.046 (0.037)\tData 0.027 (0.008)\tLoss 103.8190 (99.8090)\tPrec 17.188% (18.319%)\n",
      "Epoch: [9][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.006)\tLoss 100.0206 (99.9107)\tPrec 17.188% (18.745%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.246 (0.246)\tLoss 2.0847 (2.0847)\tPrec 23.438% (23.438%)\n",
      " * Prec 20.160% \n",
      "best acc: 20.160000\n",
      "Epoch: [10][0/391]\tTime 0.295 (0.295)\tData 0.271 (0.271)\tLoss 99.7474 (99.7474)\tPrec 23.438% (23.438%)\n",
      "Epoch: [10][100/391]\tTime 0.035 (0.038)\tData 0.004 (0.011)\tLoss 97.5013 (99.2821)\tPrec 19.531% (21.612%)\n",
      "Epoch: [10][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 100.2224 (98.8522)\tPrec 17.969% (22.726%)\n",
      "Epoch: [10][300/391]\tTime 0.034 (0.036)\tData 0.000 (0.005)\tLoss 95.8699 (98.8433)\tPrec 25.000% (23.523%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 2.2288 (2.2288)\tPrec 15.625% (15.625%)\n",
      " * Prec 16.240% \n",
      "best acc: 20.160000\n",
      "Epoch: [11][0/391]\tTime 0.263 (0.263)\tData 0.239 (0.239)\tLoss 97.7757 (97.7757)\tPrec 27.344% (27.344%)\n",
      "Epoch: [11][100/391]\tTime 0.034 (0.037)\tData 0.003 (0.008)\tLoss 101.4127 (99.5073)\tPrec 26.562% (27.243%)\n",
      "Epoch: [11][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.007)\tLoss 100.5036 (98.8480)\tPrec 30.469% (27.888%)\n",
      "Epoch: [11][300/391]\tTime 0.035 (0.036)\tData 0.004 (0.005)\tLoss 96.7461 (98.6775)\tPrec 29.688% (27.964%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 1.9465 (1.9465)\tPrec 26.562% (26.562%)\n",
      " * Prec 27.640% \n",
      "best acc: 27.640000\n",
      "Epoch: [12][0/391]\tTime 0.274 (0.274)\tData 0.249 (0.249)\tLoss 98.5758 (98.5758)\tPrec 30.469% (30.469%)\n",
      "Epoch: [12][100/391]\tTime 0.035 (0.037)\tData 0.004 (0.006)\tLoss 95.9678 (99.1049)\tPrec 30.469% (29.602%)\n",
      "Epoch: [12][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 101.1662 (99.0057)\tPrec 31.250% (30.154%)\n",
      "Epoch: [12][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 99.8752 (99.0385)\tPrec 37.500% (31.198%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 2.3774 (2.3774)\tPrec 19.531% (19.531%)\n",
      " * Prec 22.700% \n",
      "best acc: 27.640000\n",
      "Epoch: [13][0/391]\tTime 0.283 (0.283)\tData 0.258 (0.258)\tLoss 99.3436 (99.3436)\tPrec 36.719% (36.719%)\n",
      "Epoch: [13][100/391]\tTime 0.035 (0.037)\tData 0.001 (0.007)\tLoss 94.3534 (97.7290)\tPrec 53.906% (35.968%)\n",
      "Epoch: [13][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 96.4111 (97.3434)\tPrec 37.500% (37.010%)\n",
      "Epoch: [13][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 101.9292 (97.5530)\tPrec 37.500% (38.149%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 1.8524 (1.8524)\tPrec 32.031% (32.031%)\n",
      " * Prec 33.840% \n",
      "best acc: 33.840000\n",
      "Epoch: [14][0/391]\tTime 0.256 (0.256)\tData 0.232 (0.232)\tLoss 99.1465 (99.1465)\tPrec 38.281% (38.281%)\n",
      "Epoch: [14][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 98.0680 (97.6031)\tPrec 42.969% (44.462%)\n",
      "Epoch: [14][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 98.1917 (97.2949)\tPrec 42.188% (44.799%)\n",
      "Epoch: [14][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 96.1835 (97.3286)\tPrec 54.688% (45.720%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 1.3781 (1.3781)\tPrec 46.875% (46.875%)\n",
      " * Prec 48.840% \n",
      "best acc: 48.840000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][0/391]\tTime 0.269 (0.269)\tData 0.245 (0.245)\tLoss 94.8267 (94.8267)\tPrec 53.906% (53.906%)\n",
      "Epoch: [15][100/391]\tTime 0.035 (0.040)\tData 0.014 (0.012)\tLoss 94.4915 (95.6557)\tPrec 48.438% (50.456%)\n",
      "Epoch: [15][200/391]\tTime 0.033 (0.037)\tData 0.001 (0.007)\tLoss 96.5593 (96.0399)\tPrec 45.312% (51.337%)\n",
      "Epoch: [15][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 97.5649 (96.2324)\tPrec 55.469% (51.856%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 2.9400 (2.9400)\tPrec 35.156% (35.156%)\n",
      " * Prec 26.390% \n",
      "best acc: 48.840000\n",
      "Epoch: [16][0/391]\tTime 0.394 (0.394)\tData 0.368 (0.368)\tLoss 98.5697 (98.5697)\tPrec 58.594% (58.594%)\n",
      "Epoch: [16][100/391]\tTime 0.035 (0.039)\tData 0.002 (0.009)\tLoss 97.9239 (96.1450)\tPrec 64.844% (56.389%)\n",
      "Epoch: [16][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 94.4505 (95.5006)\tPrec 57.812% (56.561%)\n",
      "Epoch: [16][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.004)\tLoss 93.3636 (95.1584)\tPrec 59.375% (56.824%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 1.5631 (1.5631)\tPrec 46.875% (46.875%)\n",
      " * Prec 42.790% \n",
      "best acc: 48.840000\n",
      "Epoch: [17][0/391]\tTime 0.258 (0.258)\tData 0.233 (0.233)\tLoss 97.7008 (97.7008)\tPrec 55.469% (55.469%)\n",
      "Epoch: [17][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 95.4097 (95.1314)\tPrec 64.062% (59.855%)\n",
      "Epoch: [17][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 96.7626 (94.8010)\tPrec 64.844% (60.281%)\n",
      "Epoch: [17][300/391]\tTime 0.035 (0.036)\tData 0.004 (0.003)\tLoss 94.5242 (94.7609)\tPrec 64.062% (60.683%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 1.2366 (1.2366)\tPrec 57.031% (57.031%)\n",
      " * Prec 56.650% \n",
      "best acc: 56.650000\n",
      "Epoch: [18][0/391]\tTime 0.272 (0.272)\tData 0.246 (0.246)\tLoss 93.0699 (93.0699)\tPrec 71.875% (71.875%)\n",
      "Epoch: [18][100/391]\tTime 0.041 (0.038)\tData 0.023 (0.007)\tLoss 92.7372 (93.8501)\tPrec 57.031% (63.653%)\n",
      "Epoch: [18][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.006)\tLoss 95.0339 (93.7887)\tPrec 63.281% (63.880%)\n",
      "Epoch: [18][300/391]\tTime 0.034 (0.036)\tData 0.008 (0.005)\tLoss 92.8292 (94.1167)\tPrec 58.594% (63.909%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 1.8070 (1.8070)\tPrec 42.188% (42.188%)\n",
      " * Prec 47.100% \n",
      "best acc: 56.650000\n",
      "Epoch: [19][0/391]\tTime 0.295 (0.295)\tData 0.272 (0.272)\tLoss 93.2831 (93.2831)\tPrec 60.156% (60.156%)\n",
      "Epoch: [19][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 94.0102 (94.5227)\tPrec 67.188% (66.453%)\n",
      "Epoch: [19][200/391]\tTime 0.035 (0.036)\tData 0.004 (0.004)\tLoss 93.4358 (94.3882)\tPrec 63.281% (66.134%)\n",
      "Epoch: [19][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.003)\tLoss 91.9871 (94.8984)\tPrec 69.531% (66.580%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 1.5923 (1.5923)\tPrec 46.875% (46.875%)\n",
      " * Prec 49.870% \n",
      "best acc: 56.650000\n",
      "Epoch: [20][0/391]\tTime 0.275 (0.275)\tData 0.252 (0.252)\tLoss 95.8644 (95.8644)\tPrec 69.531% (69.531%)\n",
      "Epoch: [20][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.005)\tLoss 11.2597 (19.5862)\tPrec 76.562% (71.411%)\n",
      "Epoch: [20][200/391]\tTime 0.035 (0.036)\tData 0.000 (0.004)\tLoss 11.6064 (15.6734)\tPrec 75.000% (71.910%)\n",
      "Epoch: [20][300/391]\tTime 0.035 (0.035)\tData 0.005 (0.003)\tLoss 11.9475 (14.3876)\tPrec 68.750% (72.423%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 1.4655 (1.4655)\tPrec 52.344% (52.344%)\n",
      " * Prec 47.980% \n",
      "best acc: 56.650000\n",
      "Epoch: [21][0/391]\tTime 0.244 (0.244)\tData 0.221 (0.221)\tLoss 11.7526 (11.7526)\tPrec 77.344% (77.344%)\n",
      "Epoch: [21][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.006)\tLoss 12.0634 (11.8406)\tPrec 75.000% (74.141%)\n",
      "Epoch: [21][200/391]\tTime 0.033 (0.036)\tData 0.002 (0.004)\tLoss 11.8357 (11.8754)\tPrec 79.688% (73.842%)\n",
      "Epoch: [21][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 11.9089 (11.8323)\tPrec 71.875% (74.045%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.7469 (0.7469)\tPrec 76.562% (76.562%)\n",
      " * Prec 71.330% \n",
      "best acc: 71.330000\n",
      "Epoch: [22][0/391]\tTime 0.254 (0.254)\tData 0.230 (0.230)\tLoss 11.8756 (11.8756)\tPrec 70.312% (70.312%)\n",
      "Epoch: [22][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.007)\tLoss 11.7394 (11.8759)\tPrec 77.344% (74.737%)\n",
      "Epoch: [22][200/391]\tTime 0.035 (0.036)\tData 0.000 (0.004)\tLoss 11.3727 (11.8646)\tPrec 78.125% (74.572%)\n",
      "Epoch: [22][300/391]\tTime 0.035 (0.035)\tData 0.002 (0.004)\tLoss 12.0820 (11.7977)\tPrec 62.500% (74.727%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.8963 (0.8963)\tPrec 71.875% (71.875%)\n",
      " * Prec 63.060% \n",
      "best acc: 71.330000\n",
      "Epoch: [23][0/391]\tTime 0.253 (0.253)\tData 0.229 (0.229)\tLoss 11.4341 (11.4341)\tPrec 79.688% (79.688%)\n",
      "Epoch: [23][100/391]\tTime 0.034 (0.037)\tData 0.004 (0.006)\tLoss 11.9858 (11.6595)\tPrec 75.781% (75.766%)\n",
      "Epoch: [23][200/391]\tTime 0.035 (0.036)\tData 0.003 (0.005)\tLoss 12.6282 (11.8776)\tPrec 75.000% (75.408%)\n",
      "Epoch: [23][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 11.4918 (11.8902)\tPrec 77.344% (75.291%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 1.2237 (1.2237)\tPrec 52.344% (52.344%)\n",
      " * Prec 53.180% \n",
      "best acc: 71.330000\n",
      "Epoch: [24][0/391]\tTime 0.246 (0.246)\tData 0.222 (0.222)\tLoss 11.8505 (11.8505)\tPrec 75.000% (75.000%)\n",
      "Epoch: [24][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.009)\tLoss 11.1752 (11.6129)\tPrec 78.906% (75.464%)\n",
      "Epoch: [24][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.006)\tLoss 11.6862 (11.6659)\tPrec 79.688% (75.770%)\n",
      "Epoch: [24][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.005)\tLoss 12.0440 (11.6627)\tPrec 74.219% (75.820%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.234 (0.234)\tLoss 1.7570 (1.7570)\tPrec 47.656% (47.656%)\n",
      " * Prec 44.560% \n",
      "best acc: 71.330000\n",
      "Epoch: [25][0/391]\tTime 0.260 (0.260)\tData 0.238 (0.238)\tLoss 11.8660 (11.8660)\tPrec 74.219% (74.219%)\n",
      "Epoch: [25][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.006)\tLoss 5.2834 (5.5063)\tPrec 77.344% (76.083%)\n",
      "Epoch: [25][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 5.7562 (5.4546)\tPrec 75.000% (76.232%)\n",
      "Epoch: [25][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 5.7389 (5.4336)\tPrec 74.219% (76.383%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 1.8684 (1.8684)\tPrec 43.750% (43.750%)\n",
      " * Prec 41.720% \n",
      "best acc: 71.330000\n",
      "Epoch: [26][0/391]\tTime 0.258 (0.258)\tData 0.235 (0.235)\tLoss 5.6619 (5.6619)\tPrec 61.719% (61.719%)\n",
      "Epoch: [26][100/391]\tTime 0.034 (0.037)\tData 0.000 (0.007)\tLoss 5.2169 (5.4433)\tPrec 75.781% (76.191%)\n",
      "Epoch: [26][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.005)\tLoss 5.4333 (5.4036)\tPrec 73.438% (76.244%)\n",
      "Epoch: [26][300/391]\tTime 0.034 (0.036)\tData 0.011 (0.004)\tLoss 6.1850 (5.3937)\tPrec 78.125% (76.222%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 1.4087 (1.4087)\tPrec 53.906% (53.906%)\n",
      " * Prec 54.660% \n",
      "best acc: 71.330000\n",
      "Epoch: [27][0/391]\tTime 0.249 (0.249)\tData 0.227 (0.227)\tLoss 6.2235 (6.2235)\tPrec 77.344% (77.344%)\n",
      "Epoch: [27][100/391]\tTime 0.035 (0.038)\tData 0.001 (0.011)\tLoss 5.3343 (5.4282)\tPrec 75.781% (77.228%)\n",
      "Epoch: [27][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.007)\tLoss 5.4571 (5.3731)\tPrec 75.781% (77.169%)\n",
      "Epoch: [27][300/391]\tTime 0.035 (0.036)\tData 0.010 (0.005)\tLoss 5.1862 (5.3841)\tPrec 76.562% (76.975%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.242 (0.242)\tLoss 0.9037 (0.9037)\tPrec 71.875% (71.875%)\n",
      " * Prec 66.230% \n",
      "best acc: 71.330000\n",
      "Epoch: [28][0/391]\tTime 0.256 (0.256)\tData 0.233 (0.233)\tLoss 5.3589 (5.3589)\tPrec 77.344% (77.344%)\n",
      "Epoch: [28][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.007)\tLoss 5.5267 (5.3430)\tPrec 75.781% (77.475%)\n",
      "Epoch: [28][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 5.2677 (5.3552)\tPrec 73.438% (77.013%)\n",
      "Epoch: [28][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 5.7722 (5.3756)\tPrec 75.781% (76.952%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.230 (0.230)\tLoss 0.7935 (0.7935)\tPrec 74.219% (74.219%)\n",
      " * Prec 66.260% \n",
      "best acc: 71.330000\n",
      "Epoch: [29][0/391]\tTime 0.275 (0.275)\tData 0.251 (0.251)\tLoss 5.2785 (5.2785)\tPrec 82.031% (82.031%)\n",
      "Epoch: [29][100/391]\tTime 0.035 (0.037)\tData 0.001 (0.006)\tLoss 6.0567 (5.3708)\tPrec 71.875% (77.104%)\n",
      "Epoch: [29][200/391]\tTime 0.034 (0.036)\tData 0.001 (0.004)\tLoss 5.5705 (5.3834)\tPrec 64.844% (76.881%)\n",
      "Epoch: [29][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 5.5087 (5.3822)\tPrec 77.344% (76.980%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 1.3142 (1.3142)\tPrec 57.031% (57.031%)\n",
      " * Prec 56.630% \n",
      "best acc: 71.330000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][0/391]\tTime 0.253 (0.253)\tData 0.230 (0.230)\tLoss 5.7437 (5.7437)\tPrec 79.688% (79.688%)\n",
      "Epoch: [30][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.009)\tLoss 1.2508 (1.5103)\tPrec 74.219% (77.197%)\n",
      "Epoch: [30][200/391]\tTime 0.035 (0.036)\tData 0.005 (0.006)\tLoss 1.1479 (1.3667)\tPrec 80.469% (77.456%)\n",
      "Epoch: [30][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 1.3849 (1.3179)\tPrec 73.438% (77.637%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.8602 (0.8602)\tPrec 71.094% (71.094%)\n",
      " * Prec 69.380% \n",
      "best acc: 71.330000\n",
      "Epoch: [31][0/391]\tTime 0.315 (0.315)\tData 0.290 (0.290)\tLoss 1.1547 (1.1547)\tPrec 82.031% (82.031%)\n",
      "Epoch: [31][100/391]\tTime 0.034 (0.038)\tData 0.000 (0.006)\tLoss 1.0626 (1.2608)\tPrec 79.688% (77.328%)\n",
      "Epoch: [31][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 1.3528 (1.2483)\tPrec 75.781% (77.456%)\n",
      "Epoch: [31][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 1.2439 (1.2516)\tPrec 75.000% (77.424%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.6905 (0.6905)\tPrec 76.562% (76.562%)\n",
      " * Prec 72.050% \n",
      "best acc: 72.050000\n",
      "Epoch: [32][0/391]\tTime 0.268 (0.268)\tData 0.246 (0.246)\tLoss 1.3451 (1.3451)\tPrec 73.438% (73.438%)\n",
      "Epoch: [32][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 1.2054 (1.2208)\tPrec 75.000% (77.823%)\n",
      "Epoch: [32][200/391]\tTime 0.034 (0.036)\tData 0.001 (0.004)\tLoss 1.1857 (1.2329)\tPrec 77.344% (77.278%)\n",
      "Epoch: [32][300/391]\tTime 0.034 (0.035)\tData 0.000 (0.003)\tLoss 1.3894 (1.2289)\tPrec 67.188% (77.409%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 1.0277 (1.0277)\tPrec 65.625% (65.625%)\n",
      " * Prec 65.260% \n",
      "best acc: 72.050000\n",
      "Epoch: [33][0/391]\tTime 0.259 (0.259)\tData 0.235 (0.235)\tLoss 1.4014 (1.4014)\tPrec 72.656% (72.656%)\n",
      "Epoch: [33][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.008)\tLoss 1.2729 (1.2529)\tPrec 79.688% (77.877%)\n",
      "Epoch: [33][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 1.3430 (1.2458)\tPrec 77.344% (78.071%)\n",
      "Epoch: [33][300/391]\tTime 0.035 (0.036)\tData 0.003 (0.004)\tLoss 1.2145 (1.2694)\tPrec 78.125% (77.863%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.7733 (0.7733)\tPrec 75.000% (75.000%)\n",
      " * Prec 73.070% \n",
      "best acc: 73.070000\n",
      "Epoch: [34][0/391]\tTime 0.279 (0.279)\tData 0.256 (0.256)\tLoss 1.1335 (1.1335)\tPrec 82.031% (82.031%)\n",
      "Epoch: [34][100/391]\tTime 0.035 (0.037)\tData 0.003 (0.007)\tLoss 2.0892 (1.2553)\tPrec 65.625% (77.669%)\n",
      "Epoch: [34][200/391]\tTime 0.035 (0.036)\tData 0.000 (0.005)\tLoss 1.1656 (1.2581)\tPrec 81.250% (78.109%)\n",
      "Epoch: [34][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 1.2399 (1.2470)\tPrec 79.688% (78.135%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 0.6140 (0.6140)\tPrec 78.906% (78.906%)\n",
      " * Prec 77.490% \n",
      "best acc: 77.490000\n",
      "Epoch: [35][0/391]\tTime 0.253 (0.253)\tData 0.231 (0.231)\tLoss 1.2300 (1.2300)\tPrec 80.469% (80.469%)\n",
      "Epoch: [35][100/391]\tTime 0.034 (0.037)\tData 0.003 (0.005)\tLoss 0.9893 (1.2942)\tPrec 84.375% (78.071%)\n",
      "Epoch: [35][200/391]\tTime 0.036 (0.036)\tData 0.001 (0.004)\tLoss 1.1617 (1.2565)\tPrec 80.469% (78.176%)\n",
      "Epoch: [35][300/391]\tTime 0.035 (0.035)\tData 0.001 (0.003)\tLoss 1.3011 (1.2530)\tPrec 74.219% (78.011%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.7497 (0.7497)\tPrec 74.219% (74.219%)\n",
      " * Prec 72.660% \n",
      "best acc: 77.490000\n",
      "Epoch: [36][0/391]\tTime 0.266 (0.266)\tData 0.244 (0.244)\tLoss 1.3221 (1.3221)\tPrec 72.656% (72.656%)\n",
      "Epoch: [36][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.007)\tLoss 1.1859 (1.2145)\tPrec 79.688% (78.048%)\n",
      "Epoch: [36][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 1.1964 (1.2121)\tPrec 78.125% (78.385%)\n",
      "Epoch: [36][300/391]\tTime 0.034 (0.036)\tData 0.001 (0.004)\tLoss 1.1365 (1.2006)\tPrec 81.250% (78.618%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.6319 (0.6319)\tPrec 80.469% (80.469%)\n",
      " * Prec 76.330% \n",
      "best acc: 77.490000\n",
      "Epoch: [37][0/391]\tTime 0.251 (0.251)\tData 0.230 (0.230)\tLoss 1.1403 (1.1403)\tPrec 78.125% (78.125%)\n",
      "Epoch: [37][100/391]\tTime 0.035 (0.038)\tData 0.001 (0.007)\tLoss 1.0252 (1.3021)\tPrec 82.031% (78.403%)\n",
      "Epoch: [37][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 1.2245 (1.2702)\tPrec 78.125% (78.183%)\n",
      "Epoch: [37][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 1.3516 (1.2644)\tPrec 74.219% (78.122%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.8109 (0.8109)\tPrec 71.094% (71.094%)\n",
      " * Prec 72.220% \n",
      "best acc: 77.490000\n",
      "Epoch: [38][0/391]\tTime 0.274 (0.274)\tData 0.251 (0.251)\tLoss 1.2002 (1.2002)\tPrec 82.031% (82.031%)\n",
      "Epoch: [38][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.007)\tLoss 1.2219 (1.2272)\tPrec 77.344% (78.071%)\n",
      "Epoch: [38][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 1.0749 (1.2127)\tPrec 80.469% (78.444%)\n",
      "Epoch: [38][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.003)\tLoss 1.4555 (1.2164)\tPrec 71.094% (78.369%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.232 (0.232)\tLoss 1.0456 (1.0456)\tPrec 68.750% (68.750%)\n",
      " * Prec 65.330% \n",
      "best acc: 77.490000\n",
      "Epoch: [39][0/391]\tTime 0.253 (0.253)\tData 0.230 (0.230)\tLoss 1.2431 (1.2431)\tPrec 79.688% (79.688%)\n",
      "Epoch: [39][100/391]\tTime 0.035 (0.037)\tData 0.004 (0.006)\tLoss 1.2962 (1.2486)\tPrec 73.438% (78.450%)\n",
      "Epoch: [39][200/391]\tTime 0.036 (0.036)\tData 0.003 (0.004)\tLoss 1.3611 (1.2359)\tPrec 77.344% (78.568%)\n",
      "Epoch: [39][300/391]\tTime 0.034 (0.035)\tData 0.001 (0.003)\tLoss 1.3692 (1.2323)\tPrec 75.000% (78.421%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.7320 (0.7320)\tPrec 77.344% (77.344%)\n",
      " * Prec 73.480% \n",
      "best acc: 77.490000\n",
      "Epoch: [40][0/391]\tTime 0.258 (0.258)\tData 0.235 (0.235)\tLoss 1.1410 (1.1410)\tPrec 80.469% (80.469%)\n",
      "Epoch: [40][100/391]\tTime 0.035 (0.037)\tData 0.001 (0.006)\tLoss 1.2919 (1.1535)\tPrec 69.531% (78.311%)\n",
      "Epoch: [40][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 1.0808 (1.1734)\tPrec 81.250% (77.767%)\n",
      "Epoch: [40][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.003)\tLoss 1.2247 (1.1674)\tPrec 75.781% (77.967%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.237 (0.237)\tLoss 0.7079 (0.7079)\tPrec 74.219% (74.219%)\n",
      " * Prec 71.370% \n",
      "best acc: 77.490000\n",
      "Epoch: [41][0/391]\tTime 0.277 (0.277)\tData 0.252 (0.252)\tLoss 1.2576 (1.2576)\tPrec 77.344% (77.344%)\n",
      "Epoch: [41][100/391]\tTime 0.035 (0.037)\tData 0.000 (0.006)\tLoss 1.1179 (1.1602)\tPrec 78.125% (78.303%)\n",
      "Epoch: [41][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 1.2013 (1.1608)\tPrec 78.125% (78.137%)\n",
      "Epoch: [41][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.003)\tLoss 1.1276 (1.1759)\tPrec 83.594% (78.037%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.238 (0.238)\tLoss 0.9419 (0.9419)\tPrec 72.656% (72.656%)\n",
      " * Prec 66.180% \n",
      "best acc: 77.490000\n",
      "Epoch: [42][0/391]\tTime 0.258 (0.258)\tData 0.235 (0.235)\tLoss 1.1100 (1.1100)\tPrec 77.344% (77.344%)\n",
      "Epoch: [42][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.005)\tLoss 1.2536 (1.1688)\tPrec 76.562% (77.939%)\n",
      "Epoch: [42][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.003)\tLoss 1.5070 (1.1746)\tPrec 71.094% (77.915%)\n",
      "Epoch: [42][300/391]\tTime 0.035 (0.035)\tData 0.001 (0.003)\tLoss 1.1302 (1.1753)\tPrec 78.125% (77.904%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.6828 (0.6828)\tPrec 73.438% (73.438%)\n",
      " * Prec 74.910% \n",
      "best acc: 77.490000\n",
      "Epoch: [43][0/391]\tTime 0.234 (0.234)\tData 0.210 (0.210)\tLoss 1.2535 (1.2535)\tPrec 75.781% (75.781%)\n",
      "Epoch: [43][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 1.3118 (1.1664)\tPrec 70.312% (78.504%)\n",
      "Epoch: [43][200/391]\tTime 0.035 (0.035)\tData 0.001 (0.004)\tLoss 1.0688 (1.1715)\tPrec 82.812% (78.125%)\n",
      "Epoch: [43][300/391]\tTime 0.034 (0.035)\tData 0.001 (0.003)\tLoss 1.3137 (1.1688)\tPrec 72.656% (78.247%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.7389 (0.7389)\tPrec 74.219% (74.219%)\n",
      " * Prec 71.630% \n",
      "best acc: 77.490000\n",
      "Epoch: [44][0/391]\tTime 0.246 (0.246)\tData 0.223 (0.223)\tLoss 1.1649 (1.1649)\tPrec 78.906% (78.906%)\n",
      "Epoch: [44][100/391]\tTime 0.035 (0.037)\tData 0.001 (0.005)\tLoss 1.1488 (1.1570)\tPrec 77.344% (78.473%)\n",
      "Epoch: [44][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 1.2689 (1.1756)\tPrec 74.219% (78.144%)\n",
      "Epoch: [44][300/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.0364 (1.1729)\tPrec 83.594% (78.154%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.9161 (0.9161)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.980% \n",
      "best acc: 77.490000\n"
     ]
    }
   ],
   "source": [
    "model_name = \"VGG16_customLoss1\"\n",
    "model = VGG16()\n",
    "\n",
    "lr = 0.05\n",
    "weight_decay = 1e-4\n",
    "epochs = 45\n",
    "best_prec = 0\n",
    "\n",
    "gamma = 1\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# weight decay: for regularization to prevent overfitting\n",
    "\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "    \n",
    "fdir = 'result/'+str(model_name)\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(trainloader, model, criterion, optimizer, epoch, gamma)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51905208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.6140 (0.6140)\tPrec 78.906% (78.906%)\n",
      " * Prec 77.490% \n",
      "Weight sum: 0.6382088661193848\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "model_name = \"VGG16_customLoss1\"\n",
    "fdir = 'result/'+str(model_name)+'/model_best.pth.tar'\n",
    "\n",
    "checkpoint = torch.load(fdir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "prec = validate(testloader, model, criterion)\n",
    "print(\"Weight sum:\", model.features[0].weight.abs().sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbd4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.260 (0.260)\tData 0.235 (0.235)\tLoss 10.7380 (10.7380)\tPrec 11.719% (11.719%)\n",
      "Epoch: [0][100/391]\tTime 0.036 (0.037)\tData 0.001 (0.006)\tLoss 48.1520 (19.0180)\tPrec 14.844% (11.231%)\n",
      "Epoch: [0][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 28.7364 (27.6664)\tPrec 14.844% (10.938%)\n",
      "Epoch: [0][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 19.7828 (26.0032)\tPrec 10.938% (10.886%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 2.2918 (2.2918)\tPrec 9.375% (9.375%)\n",
      " * Prec 12.370% \n",
      "best acc: 12.370000\n",
      "Epoch: [1][0/391]\tTime 0.261 (0.261)\tData 0.239 (0.239)\tLoss 11.3565 (11.3565)\tPrec 10.938% (10.938%)\n",
      "Epoch: [1][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 9.6518 (12.3933)\tPrec 17.969% (17.536%)\n",
      "Epoch: [1][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 11.3959 (10.5033)\tPrec 15.625% (18.148%)\n",
      "Epoch: [1][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 5.1671 (9.7693)\tPrec 23.438% (19.770%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.245 (0.245)\tLoss 2.0260 (2.0260)\tPrec 25.781% (25.781%)\n",
      " * Prec 23.280% \n",
      "best acc: 23.280000\n",
      "Epoch: [2][0/391]\tTime 0.281 (0.281)\tData 0.259 (0.259)\tLoss 4.2737 (4.2737)\tPrec 21.094% (21.094%)\n",
      "Epoch: [2][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.007)\tLoss 3.4683 (4.3335)\tPrec 24.219% (25.936%)\n",
      "Epoch: [2][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 3.1764 (4.0716)\tPrec 25.781% (25.750%)\n",
      "Epoch: [2][300/391]\tTime 0.036 (0.036)\tData 0.002 (0.004)\tLoss 3.8547 (3.9064)\tPrec 31.250% (26.417%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 1.9438 (1.9438)\tPrec 28.906% (28.906%)\n",
      " * Prec 26.850% \n",
      "best acc: 26.850000\n",
      "Epoch: [3][0/391]\tTime 0.261 (0.261)\tData 0.241 (0.241)\tLoss 3.2517 (3.2517)\tPrec 35.156% (35.156%)\n",
      "Epoch: [3][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 3.3399 (3.5589)\tPrec 34.375% (31.822%)\n",
      "Epoch: [3][200/391]\tTime 0.034 (0.036)\tData 0.003 (0.004)\tLoss 3.2990 (3.5333)\tPrec 27.344% (32.140%)\n",
      "Epoch: [3][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 3.2294 (3.5095)\tPrec 36.719% (32.475%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 2.2035 (2.2035)\tPrec 23.438% (23.438%)\n",
      " * Prec 20.930% \n",
      "best acc: 26.850000\n",
      "Epoch: [4][0/391]\tTime 0.260 (0.260)\tData 0.237 (0.237)\tLoss 3.2100 (3.2100)\tPrec 25.781% (25.781%)\n",
      "Epoch: [4][100/391]\tTime 0.037 (0.037)\tData 0.001 (0.004)\tLoss 2.6021 (3.3167)\tPrec 40.625% (35.481%)\n",
      "Epoch: [4][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 3.2583 (3.3642)\tPrec 43.750% (36.388%)\n",
      "Epoch: [4][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.003)\tLoss 3.2708 (3.4720)\tPrec 43.750% (37.137%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 1.7979 (1.7979)\tPrec 37.500% (37.500%)\n",
      " * Prec 33.650% \n",
      "best acc: 33.650000\n",
      "Epoch: [5][0/391]\tTime 0.264 (0.264)\tData 0.242 (0.242)\tLoss 2.9642 (2.9642)\tPrec 38.281% (38.281%)\n",
      "Epoch: [5][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 3.3972 (3.2833)\tPrec 39.062% (41.066%)\n",
      "Epoch: [5][200/391]\tTime 0.038 (0.036)\tData 0.019 (0.004)\tLoss 2.6948 (3.1663)\tPrec 49.219% (41.294%)\n",
      "Epoch: [5][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 4.1020 (3.3897)\tPrec 51.562% (42.097%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 1.7525 (1.7525)\tPrec 33.594% (33.594%)\n",
      " * Prec 32.060% \n",
      "best acc: 33.650000\n",
      "Epoch: [6][0/391]\tTime 0.288 (0.288)\tData 0.263 (0.263)\tLoss 2.8660 (2.8660)\tPrec 38.281% (38.281%)\n",
      "Epoch: [6][100/391]\tTime 0.036 (0.037)\tData 0.002 (0.006)\tLoss 2.9247 (3.1853)\tPrec 40.625% (46.364%)\n",
      "Epoch: [6][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 2.6611 (3.0743)\tPrec 48.438% (46.685%)\n",
      "Epoch: [6][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 2.4892 (2.9847)\tPrec 53.906% (47.407%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 1.4690 (1.4690)\tPrec 42.188% (42.188%)\n",
      " * Prec 46.790% \n",
      "best acc: 46.790000\n",
      "Epoch: [7][0/391]\tTime 0.274 (0.274)\tData 0.253 (0.253)\tLoss 2.3368 (2.3368)\tPrec 55.469% (55.469%)\n",
      "Epoch: [7][100/391]\tTime 0.035 (0.038)\tData 0.005 (0.006)\tLoss 2.6103 (2.6966)\tPrec 50.781% (52.862%)\n",
      "Epoch: [7][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 2.7368 (2.6242)\tPrec 49.219% (53.284%)\n",
      "Epoch: [7][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.003)\tLoss 2.5033 (2.6081)\tPrec 56.250% (53.473%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 1.5467 (1.5467)\tPrec 48.438% (48.438%)\n",
      " * Prec 47.540% \n",
      "best acc: 47.540000\n",
      "Epoch: [8][0/391]\tTime 0.294 (0.294)\tData 0.271 (0.271)\tLoss 3.4474 (3.4474)\tPrec 56.250% (56.250%)\n",
      "Epoch: [8][100/391]\tTime 0.035 (0.038)\tData 0.004 (0.009)\tLoss 2.4046 (2.6613)\tPrec 57.812% (58.207%)\n",
      "Epoch: [8][200/391]\tTime 0.033 (0.036)\tData 0.002 (0.006)\tLoss 2.2821 (2.4870)\tPrec 56.250% (58.427%)\n",
      "Epoch: [8][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 2.3727 (2.4652)\tPrec 59.375% (59.180%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 1.1503 (1.1503)\tPrec 58.594% (58.594%)\n",
      " * Prec 56.210% \n",
      "best acc: 56.210000\n",
      "Epoch: [9][0/391]\tTime 0.268 (0.268)\tData 0.245 (0.245)\tLoss 3.0895 (3.0895)\tPrec 60.938% (60.938%)\n",
      "Epoch: [9][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 2.0107 (2.2878)\tPrec 64.062% (63.111%)\n",
      "Epoch: [9][200/391]\tTime 0.036 (0.036)\tData 0.002 (0.004)\tLoss 2.2019 (2.1983)\tPrec 64.062% (63.448%)\n",
      "Epoch: [9][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 2.2505 (2.1944)\tPrec 62.500% (63.964%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 1.3004 (1.3004)\tPrec 58.594% (58.594%)\n",
      " * Prec 57.320% \n",
      "best acc: 57.320000\n",
      "Epoch: [10][0/391]\tTime 0.276 (0.276)\tData 0.253 (0.253)\tLoss 1.9697 (1.9697)\tPrec 70.312% (70.312%)\n",
      "Epoch: [10][100/391]\tTime 0.036 (0.037)\tData 0.002 (0.006)\tLoss 1.7707 (2.0717)\tPrec 71.875% (67.358%)\n",
      "Epoch: [10][200/391]\tTime 0.035 (0.036)\tData 0.004 (0.004)\tLoss 2.5585 (2.0225)\tPrec 68.750% (67.596%)\n",
      "Epoch: [10][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 2.0206 (2.0247)\tPrec 67.188% (68.223%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 1.0612 (1.0612)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.000% \n",
      "best acc: 63.000000\n",
      "Epoch: [11][0/391]\tTime 0.299 (0.299)\tData 0.276 (0.276)\tLoss 1.7030 (1.7030)\tPrec 80.469% (80.469%)\n",
      "Epoch: [11][100/391]\tTime 0.036 (0.038)\tData 0.002 (0.007)\tLoss 2.3073 (2.3193)\tPrec 73.438% (70.552%)\n",
      "Epoch: [11][200/391]\tTime 0.033 (0.037)\tData 0.002 (0.005)\tLoss 1.7879 (2.1242)\tPrec 72.656% (71.152%)\n",
      "Epoch: [11][300/391]\tTime 0.036 (0.036)\tData 0.002 (0.004)\tLoss 1.9400 (2.0054)\tPrec 66.406% (71.639%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.9250 (0.9250)\tPrec 68.750% (68.750%)\n",
      " * Prec 67.500% \n",
      "best acc: 67.500000\n",
      "Epoch: [12][0/391]\tTime 0.275 (0.275)\tData 0.254 (0.254)\tLoss 1.4795 (1.4795)\tPrec 77.344% (77.344%)\n",
      "Epoch: [12][100/391]\tTime 0.033 (0.037)\tData 0.002 (0.006)\tLoss 1.6409 (1.6853)\tPrec 78.906% (73.755%)\n",
      "Epoch: [12][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 1.5731 (1.6807)\tPrec 79.688% (73.931%)\n",
      "Epoch: [12][300/391]\tTime 0.033 (0.036)\tData 0.002 (0.004)\tLoss 1.4870 (1.6743)\tPrec 78.125% (74.128%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.8246 (0.8246)\tPrec 71.094% (71.094%)\n",
      " * Prec 68.820% \n",
      "best acc: 68.820000\n",
      "Epoch: [13][0/391]\tTime 0.259 (0.259)\tData 0.237 (0.237)\tLoss 1.6156 (1.6156)\tPrec 76.562% (76.562%)\n",
      "Epoch: [13][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 1.4532 (1.6552)\tPrec 78.906% (75.990%)\n",
      "Epoch: [13][200/391]\tTime 0.035 (0.036)\tData 0.000 (0.003)\tLoss 1.6003 (1.6481)\tPrec 76.562% (75.731%)\n",
      "Epoch: [13][300/391]\tTime 0.036 (0.036)\tData 0.005 (0.005)\tLoss 1.4778 (1.6274)\tPrec 75.000% (75.779%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 1.4805 (1.4805)\tPrec 48.438% (48.438%)\n",
      " * Prec 48.190% \n",
      "best acc: 68.820000\n",
      "Epoch: [14][0/391]\tTime 0.273 (0.273)\tData 0.251 (0.251)\tLoss 2.0378 (2.0378)\tPrec 73.438% (73.438%)\n",
      "Epoch: [14][100/391]\tTime 0.034 (0.039)\tData 0.000 (0.009)\tLoss 1.3559 (1.5562)\tPrec 82.812% (76.702%)\n",
      "Epoch: [14][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 1.4026 (1.5221)\tPrec 75.000% (76.994%)\n",
      "Epoch: [14][300/391]\tTime 0.036 (0.036)\tData 0.003 (0.004)\tLoss 1.5709 (1.5019)\tPrec 72.656% (77.289%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 1.5599 (1.5599)\tPrec 57.812% (57.812%)\n",
      " * Prec 53.060% \n",
      "best acc: 68.820000\n",
      "Epoch: [15][0/391]\tTime 0.284 (0.284)\tData 0.260 (0.260)\tLoss 1.4766 (1.4766)\tPrec 82.031% (82.031%)\n",
      "Epoch: [15][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.007)\tLoss 1.3834 (1.4411)\tPrec 78.125% (79.146%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.035 (0.036)\tData 0.004 (0.005)\tLoss 1.4816 (1.4348)\tPrec 84.375% (79.046%)\n",
      "Epoch: [15][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 1.4645 (1.4362)\tPrec 78.125% (79.202%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.8809 (0.8809)\tPrec 74.219% (74.219%)\n",
      " * Prec 65.260% \n",
      "best acc: 68.820000\n",
      "Epoch: [16][0/391]\tTime 0.270 (0.270)\tData 0.247 (0.247)\tLoss 1.3499 (1.3499)\tPrec 81.250% (81.250%)\n",
      "Epoch: [16][100/391]\tTime 0.035 (0.041)\tData 0.004 (0.015)\tLoss 1.3724 (1.4254)\tPrec 83.594% (80.577%)\n",
      "Epoch: [16][200/391]\tTime 0.035 (0.038)\tData 0.002 (0.010)\tLoss 1.4562 (1.4406)\tPrec 80.469% (80.154%)\n",
      "Epoch: [16][300/391]\tTime 0.034 (0.037)\tData 0.002 (0.008)\tLoss 2.1962 (1.4559)\tPrec 77.344% (79.911%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 0.9993 (0.9993)\tPrec 70.312% (70.312%)\n",
      " * Prec 66.890% \n",
      "best acc: 68.820000\n",
      "Epoch: [17][0/391]\tTime 0.267 (0.267)\tData 0.244 (0.244)\tLoss 1.2806 (1.2806)\tPrec 85.156% (85.156%)\n",
      "Epoch: [17][100/391]\tTime 0.036 (0.037)\tData 0.002 (0.006)\tLoss 1.3797 (1.3725)\tPrec 79.688% (81.668%)\n",
      "Epoch: [17][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 1.5166 (1.4029)\tPrec 75.781% (81.184%)\n",
      "Epoch: [17][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 1.2215 (1.3777)\tPrec 83.594% (81.167%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.7623 (0.7623)\tPrec 70.312% (70.312%)\n",
      " * Prec 71.520% \n",
      "best acc: 71.520000\n",
      "Epoch: [18][0/391]\tTime 0.300 (0.300)\tData 0.278 (0.278)\tLoss 1.1126 (1.1126)\tPrec 87.500% (87.500%)\n",
      "Epoch: [18][100/391]\tTime 0.035 (0.039)\tData 0.001 (0.010)\tLoss 1.5446 (1.3065)\tPrec 75.000% (82.039%)\n",
      "Epoch: [18][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 1.1723 (1.3494)\tPrec 82.031% (82.043%)\n",
      "Epoch: [18][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.005)\tLoss 1.3835 (1.3312)\tPrec 80.469% (82.091%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 1.0366 (1.0366)\tPrec 62.500% (62.500%)\n",
      " * Prec 64.510% \n",
      "best acc: 71.520000\n",
      "Epoch: [19][0/391]\tTime 0.256 (0.256)\tData 0.233 (0.233)\tLoss 1.4416 (1.4416)\tPrec 80.469% (80.469%)\n",
      "Epoch: [19][100/391]\tTime 0.034 (0.039)\tData 0.003 (0.010)\tLoss 1.4524 (1.3072)\tPrec 76.562% (83.261%)\n",
      "Epoch: [19][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 1.4479 (1.4634)\tPrec 79.688% (82.416%)\n",
      "Epoch: [19][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 1.1290 (1.3967)\tPrec 85.156% (82.613%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.6489 (0.6489)\tPrec 78.125% (78.125%)\n",
      " * Prec 75.670% \n",
      "best acc: 75.670000\n",
      "Epoch: [20][0/391]\tTime 0.281 (0.281)\tData 0.257 (0.257)\tLoss 1.2994 (1.2994)\tPrec 87.500% (87.500%)\n",
      "Epoch: [20][100/391]\tTime 0.035 (0.038)\tData 0.001 (0.009)\tLoss 0.5920 (0.6971)\tPrec 88.281% (86.819%)\n",
      "Epoch: [20][200/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.6222 (0.6417)\tPrec 86.719% (87.286%)\n",
      "Epoch: [20][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.005)\tLoss 0.5369 (0.6227)\tPrec 88.281% (87.560%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.4032 (0.4032)\tPrec 88.281% (88.281%)\n",
      " * Prec 81.430% \n",
      "best acc: 81.430000\n",
      "Epoch: [21][0/391]\tTime 0.282 (0.282)\tData 0.256 (0.256)\tLoss 0.5122 (0.5122)\tPrec 89.062% (89.062%)\n",
      "Epoch: [21][100/391]\tTime 0.034 (0.038)\tData 0.002 (0.008)\tLoss 0.5324 (0.5518)\tPrec 90.625% (88.838%)\n",
      "Epoch: [21][200/391]\tTime 0.046 (0.037)\tData 0.026 (0.006)\tLoss 0.5850 (0.5459)\tPrec 89.062% (88.919%)\n",
      "Epoch: [21][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.005)\tLoss 0.4743 (0.5525)\tPrec 91.406% (88.881%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.3336 (0.3336)\tPrec 90.625% (90.625%)\n",
      " * Prec 85.060% \n",
      "best acc: 85.060000\n",
      "Epoch: [22][0/391]\tTime 0.276 (0.276)\tData 0.251 (0.251)\tLoss 0.4892 (0.4892)\tPrec 91.406% (91.406%)\n",
      "Epoch: [22][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.5976 (0.5464)\tPrec 87.500% (88.885%)\n",
      "Epoch: [22][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.5258 (0.5498)\tPrec 90.625% (89.074%)\n",
      "Epoch: [22][300/391]\tTime 0.034 (0.036)\tData 0.001 (0.004)\tLoss 0.5902 (0.5453)\tPrec 87.500% (89.088%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.5186 (0.5186)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.910% \n",
      "best acc: 85.060000\n",
      "Epoch: [23][0/391]\tTime 0.260 (0.260)\tData 0.240 (0.240)\tLoss 0.6031 (0.6031)\tPrec 86.719% (86.719%)\n",
      "Epoch: [23][100/391]\tTime 0.036 (0.037)\tData 0.002 (0.006)\tLoss 0.5026 (0.5246)\tPrec 88.281% (89.588%)\n",
      "Epoch: [23][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.006)\tLoss 0.5826 (0.5257)\tPrec 91.406% (89.731%)\n",
      "Epoch: [23][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 0.5452 (0.5244)\tPrec 90.625% (89.704%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.3962 (0.3962)\tPrec 88.281% (88.281%)\n",
      " * Prec 83.790% \n",
      "best acc: 85.060000\n",
      "Epoch: [24][0/391]\tTime 0.255 (0.255)\tData 0.231 (0.231)\tLoss 0.5684 (0.5684)\tPrec 89.062% (89.062%)\n",
      "Epoch: [24][100/391]\tTime 0.034 (0.037)\tData 0.002 (0.006)\tLoss 0.5248 (0.5166)\tPrec 89.062% (89.674%)\n",
      "Epoch: [24][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.6028 (0.5175)\tPrec 82.812% (89.684%)\n",
      "Epoch: [24][300/391]\tTime 0.034 (0.036)\tData 0.005 (0.004)\tLoss 0.4373 (0.5148)\tPrec 90.625% (89.787%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.4315 (0.4315)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.630% \n",
      "best acc: 85.060000\n",
      "Epoch: [25][0/391]\tTime 0.282 (0.282)\tData 0.258 (0.258)\tLoss 0.4219 (0.4219)\tPrec 94.531% (94.531%)\n",
      "Epoch: [25][100/391]\tTime 0.035 (0.037)\tData 0.001 (0.006)\tLoss 0.2816 (0.3744)\tPrec 92.969% (90.934%)\n",
      "Epoch: [25][200/391]\tTime 0.034 (0.036)\tData 0.001 (0.005)\tLoss 0.3480 (0.3692)\tPrec 91.406% (90.742%)\n",
      "Epoch: [25][300/391]\tTime 0.035 (0.036)\tData 0.000 (0.005)\tLoss 0.4004 (0.3707)\tPrec 88.281% (90.729%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.5012 (0.5012)\tPrec 83.594% (83.594%)\n",
      " * Prec 82.690% \n",
      "best acc: 85.060000\n",
      "Epoch: [26][0/391]\tTime 0.252 (0.252)\tData 0.230 (0.230)\tLoss 0.3233 (0.3233)\tPrec 92.969% (92.969%)\n",
      "Epoch: [26][100/391]\tTime 0.036 (0.038)\tData 0.002 (0.008)\tLoss 0.3525 (0.3632)\tPrec 90.625% (90.927%)\n",
      "Epoch: [26][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 0.2915 (0.3574)\tPrec 92.969% (91.111%)\n",
      "Epoch: [26][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.3745 (0.3644)\tPrec 90.625% (90.916%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.6577 (0.6577)\tPrec 79.688% (79.688%)\n",
      " * Prec 76.050% \n",
      "best acc: 85.060000\n",
      "Epoch: [27][0/391]\tTime 0.260 (0.260)\tData 0.238 (0.238)\tLoss 0.3543 (0.3543)\tPrec 92.969% (92.969%)\n",
      "Epoch: [27][100/391]\tTime 0.034 (0.037)\tData 0.001 (0.005)\tLoss 0.3783 (0.3566)\tPrec 85.938% (90.996%)\n",
      "Epoch: [27][200/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 0.3294 (0.3579)\tPrec 93.750% (90.959%)\n",
      "Epoch: [27][300/391]\tTime 0.036 (0.036)\tData 0.001 (0.004)\tLoss 0.3621 (0.3595)\tPrec 89.844% (90.975%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.3153 (0.3153)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.940% \n",
      "best acc: 85.060000\n",
      "Epoch: [28][0/391]\tTime 0.295 (0.295)\tData 0.272 (0.272)\tLoss 0.4068 (0.4068)\tPrec 91.406% (91.406%)\n",
      "Epoch: [28][100/391]\tTime 0.035 (0.038)\tData 0.018 (0.008)\tLoss 0.3418 (0.3498)\tPrec 92.969% (91.267%)\n",
      "Epoch: [28][200/391]\tTime 0.035 (0.037)\tData 0.000 (0.008)\tLoss 0.3943 (0.3527)\tPrec 88.281% (91.154%)\n",
      "Epoch: [28][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.006)\tLoss 0.3885 (0.3512)\tPrec 89.844% (91.235%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.243 (0.243)\tLoss 0.3827 (0.3827)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.710% \n",
      "best acc: 85.060000\n",
      "Epoch: [29][0/391]\tTime 0.289 (0.289)\tData 0.266 (0.266)\tLoss 0.3003 (0.3003)\tPrec 91.406% (91.406%)\n",
      "Epoch: [29][100/391]\tTime 0.035 (0.038)\tData 0.001 (0.007)\tLoss 0.3477 (0.3508)\tPrec 91.406% (91.375%)\n",
      "Epoch: [29][200/391]\tTime 0.034 (0.036)\tData 0.006 (0.006)\tLoss 0.3883 (0.3524)\tPrec 89.062% (91.192%)\n",
      "Epoch: [29][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.006)\tLoss 0.3732 (0.3515)\tPrec 89.062% (91.217%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.3312 (0.3312)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.040% \n",
      "best acc: 86.040000\n",
      "Epoch: [30][0/391]\tTime 0.304 (0.304)\tData 0.280 (0.280)\tLoss 0.2876 (0.2876)\tPrec 90.625% (90.625%)\n",
      "Epoch: [30][100/391]\tTime 0.035 (0.038)\tData 0.003 (0.006)\tLoss 0.2920 (0.2901)\tPrec 92.188% (91.545%)\n",
      "Epoch: [30][200/391]\tTime 0.037 (0.036)\tData 0.018 (0.005)\tLoss 0.2777 (0.2822)\tPrec 92.969% (91.655%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.035 (0.036)\tData 0.007 (0.005)\tLoss 0.1907 (0.2786)\tPrec 95.312% (91.741%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.3026 (0.3026)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.640% \n",
      "best acc: 86.640000\n",
      "Epoch: [31][0/391]\tTime 0.269 (0.269)\tData 0.246 (0.246)\tLoss 0.3485 (0.3485)\tPrec 88.281% (88.281%)\n",
      "Epoch: [31][100/391]\tTime 0.037 (0.037)\tData 0.007 (0.006)\tLoss 0.2240 (0.2673)\tPrec 93.750% (91.754%)\n",
      "Epoch: [31][200/391]\tTime 0.036 (0.036)\tData 0.003 (0.005)\tLoss 0.3584 (0.2730)\tPrec 87.500% (91.496%)\n",
      "Epoch: [31][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.2452 (0.2737)\tPrec 93.750% (91.523%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.240 (0.240)\tLoss 0.3460 (0.3460)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.330% \n",
      "best acc: 86.640000\n",
      "Epoch: [32][0/391]\tTime 0.257 (0.257)\tData 0.234 (0.234)\tLoss 0.2831 (0.2831)\tPrec 90.625% (90.625%)\n",
      "Epoch: [32][100/391]\tTime 0.035 (0.038)\tData 0.003 (0.008)\tLoss 0.2215 (0.2694)\tPrec 92.188% (91.538%)\n",
      "Epoch: [32][200/391]\tTime 0.033 (0.037)\tData 0.011 (0.007)\tLoss 0.2740 (0.2708)\tPrec 91.406% (91.457%)\n",
      "Epoch: [32][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.007)\tLoss 0.2174 (0.2728)\tPrec 92.969% (91.354%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.2876 (0.2876)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.120% \n",
      "best acc: 87.120000\n",
      "Epoch: [33][0/391]\tTime 0.283 (0.283)\tData 0.261 (0.261)\tLoss 0.2112 (0.2112)\tPrec 92.969% (92.969%)\n",
      "Epoch: [33][100/391]\tTime 0.034 (0.038)\tData 0.005 (0.007)\tLoss 0.2582 (0.2692)\tPrec 93.750% (91.654%)\n",
      "Epoch: [33][200/391]\tTime 0.034 (0.036)\tData 0.002 (0.005)\tLoss 0.2302 (0.2767)\tPrec 92.969% (91.391%)\n",
      "Epoch: [33][300/391]\tTime 0.054 (0.036)\tData 0.034 (0.004)\tLoss 0.2526 (0.2734)\tPrec 91.406% (91.554%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.4006 (0.4006)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.940% \n",
      "best acc: 87.120000\n",
      "Epoch: [34][0/391]\tTime 0.264 (0.264)\tData 0.241 (0.241)\tLoss 0.1795 (0.1795)\tPrec 95.312% (95.312%)\n",
      "Epoch: [34][100/391]\tTime 0.034 (0.037)\tData 0.008 (0.006)\tLoss 0.3520 (0.2658)\tPrec 87.500% (91.723%)\n",
      "Epoch: [34][200/391]\tTime 0.034 (0.036)\tData 0.001 (0.005)\tLoss 0.1937 (0.2680)\tPrec 95.312% (91.604%)\n",
      "Epoch: [34][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.2409 (0.2717)\tPrec 92.969% (91.510%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.3112 (0.3112)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.560% \n",
      "best acc: 87.120000\n",
      "Epoch: [35][0/391]\tTime 0.265 (0.265)\tData 0.238 (0.238)\tLoss 0.4001 (0.4001)\tPrec 89.844% (89.844%)\n",
      "Epoch: [35][100/391]\tTime 0.035 (0.037)\tData 0.001 (0.007)\tLoss 0.2190 (0.2682)\tPrec 92.969% (91.460%)\n",
      "Epoch: [35][200/391]\tTime 0.037 (0.037)\tData 0.016 (0.006)\tLoss 0.2669 (0.2713)\tPrec 92.188% (91.546%)\n",
      "Epoch: [35][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.006)\tLoss 0.2553 (0.2680)\tPrec 91.406% (91.642%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.3114 (0.3114)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.650% \n",
      "best acc: 87.120000\n",
      "Epoch: [36][0/391]\tTime 0.303 (0.303)\tData 0.279 (0.279)\tLoss 0.2975 (0.2975)\tPrec 89.062% (89.062%)\n",
      "Epoch: [36][100/391]\tTime 0.036 (0.038)\tData 0.000 (0.007)\tLoss 0.3006 (0.2704)\tPrec 90.625% (91.429%)\n",
      "Epoch: [36][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 0.2493 (0.2749)\tPrec 93.750% (91.294%)\n",
      "Epoch: [36][300/391]\tTime 0.034 (0.036)\tData 0.008 (0.005)\tLoss 0.4483 (0.2746)\tPrec 88.281% (91.354%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.2592 (0.2592)\tPrec 93.750% (93.750%)\n",
      " * Prec 86.970% \n",
      "best acc: 87.120000\n",
      "Epoch: [37][0/391]\tTime 0.386 (0.386)\tData 0.362 (0.362)\tLoss 0.2275 (0.2275)\tPrec 92.969% (92.969%)\n",
      "Epoch: [37][100/391]\tTime 0.035 (0.040)\tData 0.001 (0.013)\tLoss 0.3798 (0.2608)\tPrec 85.938% (91.955%)\n",
      "Epoch: [37][200/391]\tTime 0.035 (0.038)\tData 0.003 (0.008)\tLoss 0.3682 (0.2654)\tPrec 87.500% (91.667%)\n",
      "Epoch: [37][300/391]\tTime 0.035 (0.037)\tData 0.002 (0.006)\tLoss 0.2782 (0.2646)\tPrec 91.406% (91.645%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.2805 (0.2805)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.130% \n",
      "best acc: 87.120000\n",
      "Epoch: [38][0/391]\tTime 0.268 (0.268)\tData 0.244 (0.244)\tLoss 0.2899 (0.2899)\tPrec 89.062% (89.062%)\n",
      "Epoch: [38][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.008)\tLoss 0.2567 (0.2654)\tPrec 91.406% (91.669%)\n",
      "Epoch: [38][200/391]\tTime 0.036 (0.036)\tData 0.002 (0.005)\tLoss 0.1956 (0.2659)\tPrec 93.750% (91.577%)\n",
      "Epoch: [38][300/391]\tTime 0.035 (0.036)\tData 0.003 (0.004)\tLoss 0.2161 (0.2704)\tPrec 93.750% (91.492%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3262 (0.3262)\tPrec 89.844% (89.844%)\n",
      " * Prec 84.930% \n",
      "best acc: 87.120000\n",
      "Epoch: [39][0/391]\tTime 0.263 (0.263)\tData 0.240 (0.240)\tLoss 0.2068 (0.2068)\tPrec 94.531% (94.531%)\n",
      "Epoch: [39][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.008)\tLoss 0.2492 (0.2661)\tPrec 92.188% (91.700%)\n",
      "Epoch: [39][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.005)\tLoss 0.2689 (0.2643)\tPrec 91.406% (91.795%)\n",
      "Epoch: [39][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.004)\tLoss 0.3730 (0.2662)\tPrec 90.625% (91.788%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.2841 (0.2841)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.390% \n",
      "best acc: 87.120000\n",
      "Epoch: [40][0/391]\tTime 0.270 (0.270)\tData 0.251 (0.251)\tLoss 0.1820 (0.1820)\tPrec 96.875% (96.875%)\n",
      "Epoch: [40][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 0.2410 (0.2606)\tPrec 93.750% (91.808%)\n",
      "Epoch: [40][200/391]\tTime 0.035 (0.036)\tData 0.003 (0.003)\tLoss 0.1855 (0.2592)\tPrec 96.875% (91.807%)\n",
      "Epoch: [40][300/391]\tTime 0.035 (0.036)\tData 0.001 (0.003)\tLoss 0.2496 (0.2592)\tPrec 90.625% (91.850%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.3005 (0.3005)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.710% \n",
      "best acc: 87.120000\n",
      "Epoch: [41][0/391]\tTime 0.294 (0.294)\tData 0.269 (0.269)\tLoss 0.2757 (0.2757)\tPrec 90.625% (90.625%)\n",
      "Epoch: [41][100/391]\tTime 0.035 (0.037)\tData 0.002 (0.005)\tLoss 0.2147 (0.2665)\tPrec 93.750% (91.770%)\n",
      "Epoch: [41][200/391]\tTime 0.036 (0.036)\tData 0.002 (0.003)\tLoss 0.2178 (0.2619)\tPrec 92.969% (91.845%)\n",
      "Epoch: [41][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 0.2454 (0.2598)\tPrec 94.531% (91.944%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.2931 (0.2931)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.910% \n",
      "best acc: 87.120000\n",
      "Epoch: [42][0/391]\tTime 0.265 (0.265)\tData 0.241 (0.241)\tLoss 0.3259 (0.3259)\tPrec 89.844% (89.844%)\n",
      "Epoch: [42][100/391]\tTime 0.035 (0.038)\tData 0.001 (0.008)\tLoss 0.2198 (0.2582)\tPrec 92.969% (91.747%)\n",
      "Epoch: [42][200/391]\tTime 0.035 (0.036)\tData 0.002 (0.006)\tLoss 0.2815 (0.2615)\tPrec 91.406% (91.725%)\n",
      "Epoch: [42][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.2137 (0.2615)\tPrec 92.188% (91.736%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.3354 (0.3354)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.710% \n",
      "best acc: 87.120000\n",
      "Epoch: [43][0/391]\tTime 0.281 (0.281)\tData 0.257 (0.257)\tLoss 0.1976 (0.1976)\tPrec 92.188% (92.188%)\n",
      "Epoch: [43][100/391]\tTime 0.035 (0.039)\tData 0.002 (0.008)\tLoss 0.3123 (0.2620)\tPrec 92.188% (91.716%)\n",
      "Epoch: [43][200/391]\tTime 0.036 (0.037)\tData 0.002 (0.005)\tLoss 0.4226 (0.2685)\tPrec 87.500% (91.387%)\n",
      "Epoch: [43][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 0.1947 (0.2660)\tPrec 94.531% (91.554%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.259 (0.259)\tLoss 0.2892 (0.2892)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.700% \n",
      "best acc: 87.120000\n",
      "Epoch: [44][0/391]\tTime 0.293 (0.293)\tData 0.269 (0.269)\tLoss 0.2895 (0.2895)\tPrec 89.844% (89.844%)\n",
      "Epoch: [44][100/391]\tTime 0.035 (0.038)\tData 0.002 (0.006)\tLoss 0.2237 (0.2646)\tPrec 94.531% (91.484%)\n",
      "Epoch: [44][200/391]\tTime 0.036 (0.036)\tData 0.004 (0.005)\tLoss 0.1774 (0.2647)\tPrec 95.312% (91.612%)\n",
      "Epoch: [44][300/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 0.2304 (0.2622)\tPrec 92.188% (91.718%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.2918 (0.2918)\tPrec 89.844% (89.844%)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"VGG16_customLoss2\"\n",
    "model = VGG16()\n",
    "\n",
    "lr = 0.05\n",
    "weight_decay = 1e-4\n",
    "epochs = 45\n",
    "best_prec = 0\n",
    "\n",
    "gamma = 0.05\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# weight decay: for regularization to prevent overfitting\n",
    "\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "    \n",
    "fdir = 'result/'+str(model_name)\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(trainloader, model, criterion, optimizer, epoch, gamma)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cacea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "model_name = \"VGG16_customLoss2\"\n",
    "fdir = 'result/'+str(model_name)+'/model_best.pth.tar'\n",
    "\n",
    "checkpoint = torch.load(fdir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "prec = validate(testloader, model, criterion)\n",
    "print(\"Weight sum:\", model.features[0].weight.abs().sum().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
