{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorboardX import SummaryWriter      \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant\"\n",
    "model = VGG16_quant()\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9219/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "present-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prune all the QuantConv2D layers' 90% weights with 1) unstructured, and 2) structured manner.\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "for i in range(len(model.features)):\n",
    "\n",
    "    if isinstance(model.features[i], QuantConv2d):\n",
    "            prune.ln_structured(model.features[i], name = 'weight', amount = 0.9,dim =0, n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fourth-owner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('act_alpha', Parameter containing:\n",
      "tensor(2.5205, device='cuda:0', requires_grad=True)), ('weight_q', Parameter containing:\n",
      "tensor([[[[-0.8155, -0.8155, -0.4077],\n",
      "          [-0.8155,  0.4077, -2.0387],\n",
      "          [-1.2232,  0.4077, -0.8155]],\n",
      "\n",
      "         [[ 0.4077,  0.0000, -1.2232],\n",
      "          [-0.0000, -0.4077,  0.4077],\n",
      "          [ 0.4077, -1.2232, -0.4077]],\n",
      "\n",
      "         [[-0.4077, -0.8155,  0.4077],\n",
      "          [-0.8155, -0.4077,  0.4077],\n",
      "          [-0.4077, -0.8155, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8155,  0.8155,  0.0000],\n",
      "          [ 0.4077,  0.4077,  1.2232],\n",
      "          [-1.2232, -1.6310, -0.8155]],\n",
      "\n",
      "         [[-0.8155,  0.4077,  0.8155],\n",
      "          [-1.2232, -2.4465,  0.4077],\n",
      "          [-1.2232, -1.6310, -0.8155]],\n",
      "\n",
      "         [[-0.4077, -0.8155, -2.4465],\n",
      "          [ 0.4077,  0.8155, -0.8155],\n",
      "          [-1.2232, -1.2232,  0.4077]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.8155, -1.2232],\n",
      "          [-1.6310, -0.8155,  0.4077],\n",
      "          [-0.4077, -0.4077,  0.4077]],\n",
      "\n",
      "         [[-0.0000, -1.6310, -0.4077],\n",
      "          [-0.8155, -0.4077,  0.8155],\n",
      "          [-0.0000,  0.0000, -0.8155]],\n",
      "\n",
      "         [[-0.4077,  0.0000, -0.4077],\n",
      "          [-0.8155, -0.8155,  1.2232],\n",
      "          [-0.8155, -0.8155, -0.8155]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8155, -1.2232, -1.2232],\n",
      "          [-0.4077,  0.0000,  0.4077],\n",
      "          [-1.2232, -0.8155,  0.0000]],\n",
      "\n",
      "         [[-0.8155, -1.6310, -2.8542],\n",
      "          [-1.6310, -2.4465, -1.2232],\n",
      "          [ 0.4077, -0.4077,  0.0000]],\n",
      "\n",
      "         [[-0.8155,  0.8155, -0.4077],\n",
      "          [-0.8155,  0.4077, -1.2232],\n",
      "          [-0.8155,  0.0000,  0.4077]]],\n",
      "\n",
      "\n",
      "        [[[-0.8155, -0.8155, -0.8155],\n",
      "          [-2.0387, -2.4465, -0.0000],\n",
      "          [-0.4077, -1.6310, -0.4077]],\n",
      "\n",
      "         [[-0.4077, -0.4077, -0.8155],\n",
      "          [ 0.8155, -1.6310, -0.8155],\n",
      "          [ 0.8155,  0.4077,  0.8155]],\n",
      "\n",
      "         [[ 0.8155, -1.2232,  0.8155],\n",
      "          [-1.2232, -1.6310, -0.4077],\n",
      "          [ 0.4077,  1.2232,  1.2232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4077, -0.4077,  0.8155],\n",
      "          [ 1.6310, -0.8155, -0.0000],\n",
      "          [ 0.8155,  1.2232,  0.4077]],\n",
      "\n",
      "         [[-1.2232, -0.0000,  0.0000],\n",
      "          [ 0.0000,  2.8542,  2.8542],\n",
      "          [-0.4077,  0.8155,  2.8542]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-1.2232,  0.4077,  0.0000],\n",
      "          [-0.0000,  0.8155, -2.4465]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.8155, -0.4077,  0.4077],\n",
      "          [ 1.2232, -0.0000,  0.4077],\n",
      "          [ 0.8155,  0.4077, -0.4077]],\n",
      "\n",
      "         [[ 0.4077,  0.8155,  0.8155],\n",
      "          [ 0.0000,  0.4077,  0.4077],\n",
      "          [ 0.4077,  0.4077,  0.8155]],\n",
      "\n",
      "         [[-0.8155, -0.4077,  0.0000],\n",
      "          [-0.4077, -0.0000, -0.0000],\n",
      "          [ 0.8155,  0.4077, -0.4077]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.4077,  1.2232],\n",
      "          [ 0.0000,  0.4077,  1.2232],\n",
      "          [-0.4077, -0.0000,  0.8155]],\n",
      "\n",
      "         [[-0.4077,  0.8155,  0.4077],\n",
      "          [ 0.8155,  0.4077,  0.4077],\n",
      "          [-0.4077,  0.0000,  0.4077]],\n",
      "\n",
      "         [[-0.4077, -0.8155,  0.8155],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.8155, -0.4077, -0.8155]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4077,  1.6310, -0.8155],\n",
      "          [-0.8155,  0.0000, -1.2232],\n",
      "          [-0.8155, -2.0387, -0.4077]],\n",
      "\n",
      "         [[ 1.2232,  0.4077, -0.0000],\n",
      "          [ 0.0000, -0.8155,  0.4077],\n",
      "          [-0.0000,  0.4077, -0.8155]],\n",
      "\n",
      "         [[ 1.2232,  0.4077,  0.8155],\n",
      "          [ 1.2232, -0.8155, -0.4077],\n",
      "          [-0.8155, -0.0000, -1.2232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8155, -0.0000,  0.4077],\n",
      "          [-2.0387, -2.0387, -0.8155],\n",
      "          [ 0.4077, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  1.2232, -0.4077],\n",
      "          [-0.4077,  0.4077, -1.2232],\n",
      "          [-0.8155,  0.0000, -0.4077]],\n",
      "\n",
      "         [[ 1.6310, -0.4077,  1.2232],\n",
      "          [-1.2232,  0.4077,  0.4077],\n",
      "          [ 0.4077, -0.4077,  0.4077]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8542,  2.4465,  0.8155],\n",
      "          [ 2.8542,  2.4465, -0.4077],\n",
      "          [-0.4077, -0.0000,  0.4077]],\n",
      "\n",
      "         [[ 2.0387, -0.8155, -0.4077],\n",
      "          [ 1.2232, -0.4077,  0.4077],\n",
      "          [ 0.4077, -1.6310, -0.0000]],\n",
      "\n",
      "         [[ 2.0387, -0.8155,  0.4077],\n",
      "          [-1.2232, -1.6310,  0.8155],\n",
      "          [-0.8155, -0.8155, -1.6310]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4077, -0.8155,  0.8155],\n",
      "          [-2.0387, -1.2232, -0.0000],\n",
      "          [-0.8155, -0.8155,  0.4077]],\n",
      "\n",
      "         [[-0.4077,  0.4077,  0.8155],\n",
      "          [ 0.4077, -0.4077, -0.8155],\n",
      "          [-0.8155, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.8155, -0.4077],\n",
      "          [-0.8155,  2.8542,  1.2232],\n",
      "          [-0.8155, -1.6310, -0.8155]]]], device='cuda:0', requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[-3.6377e-03, -4.4539e-03, -1.7814e-03],\n",
      "          [-4.6403e-03,  8.7887e-04, -1.0555e-02],\n",
      "          [-5.1756e-03,  1.1675e-03, -3.1069e-03]],\n",
      "\n",
      "         [[ 2.2784e-03,  1.0112e-04, -5.2303e-03],\n",
      "          [-1.1342e-03, -1.7311e-03,  9.9373e-04],\n",
      "          [ 2.2654e-03, -6.6377e-03, -1.5665e-03]],\n",
      "\n",
      "         [[-2.8758e-03, -4.3727e-03,  1.3270e-03],\n",
      "          [-4.6607e-03, -2.4416e-03,  2.0307e-03],\n",
      "          [-1.9191e-03, -4.8547e-03, -4.8855e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9823e-03,  3.1243e-03,  3.4154e-04],\n",
      "          [ 1.3774e-03,  2.5710e-03,  5.0449e-03],\n",
      "          [-5.9731e-03, -8.7352e-03, -4.1574e-03]],\n",
      "\n",
      "         [[-3.6212e-03,  8.3630e-04,  3.8674e-03],\n",
      "          [-5.4740e-03, -1.1940e-02,  1.2041e-03],\n",
      "          [-5.6720e-03, -6.9491e-03, -3.1309e-03]],\n",
      "\n",
      "         [[-1.6236e-03, -4.6708e-03, -1.0887e-02],\n",
      "          [ 1.3062e-03,  3.1126e-03, -4.3153e-03],\n",
      "          [-6.5984e-03, -5.9211e-03,  2.5426e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.6850e-04, -4.4197e-03, -5.7378e-03],\n",
      "          [-8.4775e-03, -4.6120e-03,  1.3160e-03],\n",
      "          [-1.5002e-03, -2.4576e-03,  9.7168e-04]],\n",
      "\n",
      "         [[-1.1367e-03, -7.7571e-03, -2.3387e-03],\n",
      "          [-3.3866e-03, -2.0571e-03,  2.8441e-03],\n",
      "          [-2.9879e-04,  5.9407e-04, -4.5852e-03]],\n",
      "\n",
      "         [[-2.9653e-03,  6.9932e-04, -1.5889e-03],\n",
      "          [-4.7899e-03, -3.2896e-03,  6.4847e-03],\n",
      "          [-3.3506e-03, -3.9946e-03, -4.4938e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7503e-03, -5.7297e-03, -5.8955e-03],\n",
      "          [-2.6284e-03, -1.2221e-04,  2.3681e-03],\n",
      "          [-5.4958e-03, -4.1004e-03, -3.2364e-05]],\n",
      "\n",
      "         [[-3.8269e-03, -7.3797e-03, -1.4118e-02],\n",
      "          [-7.3011e-03, -1.1912e-02, -5.8083e-03],\n",
      "          [ 1.5961e-03, -1.5413e-03,  2.1515e-04]],\n",
      "\n",
      "         [[-3.6701e-03,  3.9195e-03, -1.3627e-03],\n",
      "          [-4.5650e-03,  2.2382e-03, -5.6503e-03],\n",
      "          [-3.7451e-03, -1.1801e-04,  1.2891e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.9278e-03, -4.2838e-03, -3.8099e-03],\n",
      "          [-9.1139e-03, -1.1763e-02, -1.0142e-03],\n",
      "          [-2.5516e-03, -8.2156e-03, -1.4164e-03]],\n",
      "\n",
      "         [[-3.0488e-03, -1.6833e-03, -3.2626e-03],\n",
      "          [ 3.5721e-03, -7.0500e-03, -3.1697e-03],\n",
      "          [ 2.7142e-03,  1.1777e-03,  4.5592e-03]],\n",
      "\n",
      "         [[ 2.8662e-03, -5.8667e-03,  4.0444e-03],\n",
      "          [-6.3789e-03, -8.0645e-03, -2.2781e-03],\n",
      "          [ 1.1504e-03,  5.0532e-03,  6.2443e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7039e-03, -2.5950e-03,  2.9246e-03],\n",
      "          [ 6.5516e-03, -3.2156e-03, -9.4878e-04],\n",
      "          [ 2.8633e-03,  5.9726e-03,  1.0614e-03]],\n",
      "\n",
      "         [[-5.7725e-03, -1.0524e-03, -1.6162e-04],\n",
      "          [ 2.1525e-05,  1.3548e-02,  1.3512e-02],\n",
      "          [-2.4842e-03,  4.1444e-03,  1.3501e-02]],\n",
      "\n",
      "         [[ 4.8420e-05, -2.5561e-05,  7.0765e-04],\n",
      "          [-6.2836e-03,  8.2122e-04,  5.9427e-04],\n",
      "          [-5.0640e-04,  3.0836e-03, -1.2249e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.2704e-03, -2.7019e-03,  1.8175e-03],\n",
      "          [ 5.0250e-03, -1.0704e-03,  1.6716e-03],\n",
      "          [ 3.5896e-03,  1.7458e-03, -1.7560e-03]],\n",
      "\n",
      "         [[ 2.6730e-03,  2.7729e-03,  3.8285e-03],\n",
      "          [-1.4788e-04,  1.4016e-03,  2.5236e-03],\n",
      "          [ 1.0742e-03,  2.6002e-03,  3.9280e-03]],\n",
      "\n",
      "         [[-4.5210e-03, -2.9374e-03,  1.9009e-06],\n",
      "          [-2.9982e-03, -3.6475e-04, -6.8780e-04],\n",
      "          [ 3.0381e-03,  1.7126e-03, -1.7119e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0865e-04,  2.0685e-03,  4.7996e-03],\n",
      "          [ 7.6576e-04,  1.0980e-03,  5.9655e-03],\n",
      "          [-2.2554e-03, -3.2099e-04,  3.1266e-03]],\n",
      "\n",
      "         [[-1.3395e-03,  3.9066e-03,  2.1005e-03],\n",
      "          [ 4.1479e-03,  2.6399e-03,  1.7114e-03],\n",
      "          [-2.0240e-03,  3.8877e-04,  2.5079e-03]],\n",
      "\n",
      "         [[-1.3821e-03, -3.3100e-03,  3.6153e-03],\n",
      "          [-5.8718e-04, -5.9998e-04, -9.5183e-04],\n",
      "          [ 3.3422e-03, -2.2199e-03, -3.3961e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7187e-03,  8.2921e-03, -3.6983e-03],\n",
      "          [-3.8811e-03, -1.5949e-04, -6.4129e-03],\n",
      "          [-3.7844e-03, -1.0490e-02, -1.2026e-03]],\n",
      "\n",
      "         [[ 5.0829e-03,  2.1671e-03, -4.2329e-04],\n",
      "          [ 2.5169e-04, -4.4735e-03,  8.0458e-04],\n",
      "          [-9.6421e-04,  2.3963e-03, -3.0774e-03]],\n",
      "\n",
      "         [[ 5.9445e-03,  7.9307e-04,  2.9750e-03],\n",
      "          [ 5.8450e-03, -4.5214e-03, -1.3756e-03],\n",
      "          [-3.8038e-03, -5.2648e-04, -5.0105e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7256e-03, -7.6691e-04,  1.3401e-03],\n",
      "          [-1.0001e-02, -9.1732e-03, -3.7823e-03],\n",
      "          [ 1.8410e-03, -6.6252e-04, -1.7147e-04]],\n",
      "\n",
      "         [[ 5.3717e-04,  5.0472e-03, -2.9439e-03],\n",
      "          [-1.4851e-03,  1.4483e-03, -5.4993e-03],\n",
      "          [-4.6626e-03,  6.8279e-05, -2.6452e-03]],\n",
      "\n",
      "         [[ 8.1883e-03, -3.0309e-03,  5.2937e-03],\n",
      "          [-5.5299e-03,  9.8097e-04,  1.3240e-03],\n",
      "          [ 2.5156e-03, -2.4635e-03,  1.7421e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3528e-02,  1.2017e-02,  2.7302e-03],\n",
      "          [ 1.3589e-02,  1.2081e-02, -2.0067e-03],\n",
      "          [-2.9872e-03, -2.8312e-04,  9.1977e-04]],\n",
      "\n",
      "         [[ 8.9668e-03, -3.7227e-03, -1.3894e-03],\n",
      "          [ 5.2677e-03, -2.3395e-03,  1.3031e-03],\n",
      "          [ 9.8693e-04, -7.6891e-03, -3.1145e-04]],\n",
      "\n",
      "         [[ 8.7448e-03, -4.2297e-03,  1.8630e-03],\n",
      "          [-5.8799e-03, -8.3543e-03,  3.6405e-03],\n",
      "          [-3.2431e-03, -4.1500e-03, -8.6668e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0794e-03, -4.1405e-03,  4.0049e-03],\n",
      "          [-1.0418e-02, -5.9686e-03, -1.0379e-03],\n",
      "          [-4.6714e-03, -4.3934e-03,  1.6829e-03]],\n",
      "\n",
      "         [[-1.1578e-03,  1.5651e-03,  4.4323e-03],\n",
      "          [ 8.3257e-04, -1.1899e-03, -3.7308e-03],\n",
      "          [-4.9163e-03, -9.8292e-04, -2.1164e-04]],\n",
      "\n",
      "         [[-2.7770e-04,  2.7971e-03, -1.7853e-03],\n",
      "          [-4.3770e-03,  1.3928e-02,  4.6590e-03],\n",
      "          [-3.6116e-03, -8.7510e-03, -4.5692e-03]]]], device='cuda:0',\n",
      "       requires_grad=True)), ('weight_quant.wgt_alpha', Parameter containing:\n",
      "tensor(2.8542, device='cuda:0', requires_grad=True))]\n",
      "tensor([[[[-0., -0., -0.],\n",
      "          [-0., 0., -0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         [[-0., -0., 0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         [[-0., 0., 0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [0., 0., -0.],\n",
      "          [-0., -0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[-0., -0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[-0., 0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [-0., -0., -0.],\n",
      "          [0., -0., 0.]],\n",
      "\n",
      "         [[-0., 0., -0.],\n",
      "          [-0., 0., -0.],\n",
      "          [-0., -0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[-0., -0., -0.],\n",
      "          [-0., -0., -0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [0., -0., -0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., -0., 0.],\n",
      "          [-0., -0., -0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., -0., 0.],\n",
      "          [0., -0., -0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.],\n",
      "          [0., 0., 0.],\n",
      "          [-0., 0., 0.]],\n",
      "\n",
      "         [[0., -0., 0.],\n",
      "          [-0., 0., 0.],\n",
      "          [-0., 0., -0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., -0., 0.],\n",
      "          [0., -0., 0.],\n",
      "          [0., 0., -0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [-0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., 0.],\n",
      "          [-0., -0., -0.],\n",
      "          [0., 0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[-0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [-0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., 0.],\n",
      "          [-0., -0., -0.],\n",
      "          [0., -0., -0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., -0.],\n",
      "          [-0., -0., -0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [0., -0., 0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., -0., -0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0., -0., 0.],\n",
      "          [-0., -0., -0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         [[0., 0., -0.],\n",
      "          [-0., 0., -0.],\n",
      "          [-0., 0., -0.]],\n",
      "\n",
      "         [[0., -0., 0.],\n",
      "          [-0., 0., 0.],\n",
      "          [0., -0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., -0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[0., -0., -0.],\n",
      "          [0., -0., 0.],\n",
      "          [0., -0., -0.]],\n",
      "\n",
      "         [[0., -0., 0.],\n",
      "          [-0., -0., 0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., -0., 0.],\n",
      "          [-0., -0., -0.],\n",
      "          [-0., -0., 0.]],\n",
      "\n",
      "         [[-0., 0., 0.],\n",
      "          [0., -0., -0.],\n",
      "          [-0., -0., -0.]],\n",
      "\n",
      "         [[-0., 0., -0.],\n",
      "          [-0., 0., 0.],\n",
      "          [-0., -0., -0.]]]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(list(model.features[40].named_parameters())) # check whether there is mask, weight_org, ...\n",
    "print(model.features[40].weight) # check whether there are many zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.9004, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### Check sparsity ###\n",
    "mask1 = model.features[40].weight_mask\n",
    "sparsity_mask1 = (mask1 == 0).sum() / mask1.nelement()\n",
    "\n",
    "print(\"Sparsity level: \", sparsity_mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acquired-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 1000/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check accuracy after pruning\n",
    "model.cuda()\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.620 (0.620)\tData 0.306 (0.306)\tLoss 3.0780 (3.0780)\tPrec 7.812% (7.812%)\n",
      "Epoch: [0][100/391]\tTime 0.049 (0.060)\tData 0.003 (0.008)\tLoss 1.7210 (1.9627)\tPrec 35.938% (24.899%)\n",
      "Epoch: [0][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.005)\tLoss 1.7438 (1.8629)\tPrec 31.250% (28.226%)\n",
      "Epoch: [0][300/391]\tTime 0.059 (0.056)\tData 0.002 (0.004)\tLoss 1.8330 (1.8130)\tPrec 30.469% (30.015%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.365 (0.365)\tLoss 1.7083 (1.7083)\tPrec 37.500% (37.500%)\n",
      " * Prec 33.000% \n",
      "best acc: 33.000000\n",
      "Epoch: [1][0/391]\tTime 0.449 (0.449)\tData 0.407 (0.407)\tLoss 1.7619 (1.7619)\tPrec 30.469% (30.469%)\n",
      "Epoch: [1][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.006)\tLoss 1.6597 (1.6544)\tPrec 34.375% (35.048%)\n",
      "Epoch: [1][200/391]\tTime 0.049 (0.056)\tData 0.002 (0.004)\tLoss 1.7291 (1.6535)\tPrec 35.156% (36.011%)\n",
      "Epoch: [1][300/391]\tTime 0.044 (0.055)\tData 0.002 (0.004)\tLoss 1.5036 (1.6472)\tPrec 36.719% (36.651%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.493 (0.493)\tLoss 1.5399 (1.5399)\tPrec 44.531% (44.531%)\n",
      " * Prec 38.670% \n",
      "best acc: 38.670000\n",
      "Epoch: [2][0/391]\tTime 0.374 (0.374)\tData 0.328 (0.328)\tLoss 1.5758 (1.5758)\tPrec 39.062% (39.062%)\n",
      "Epoch: [2][100/391]\tTime 0.050 (0.057)\tData 0.003 (0.005)\tLoss 1.6280 (1.6142)\tPrec 41.406% (38.320%)\n",
      "Epoch: [2][200/391]\tTime 0.050 (0.055)\tData 0.002 (0.004)\tLoss 1.6174 (1.6085)\tPrec 32.031% (38.775%)\n",
      "Epoch: [2][300/391]\tTime 0.054 (0.055)\tData 0.002 (0.003)\tLoss 1.5288 (1.6053)\tPrec 39.062% (39.013%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.314 (0.314)\tLoss 1.6101 (1.6101)\tPrec 40.625% (40.625%)\n",
      " * Prec 39.290% \n",
      "best acc: 39.290000\n",
      "Epoch: [3][0/391]\tTime 0.333 (0.333)\tData 0.293 (0.293)\tLoss 1.7689 (1.7689)\tPrec 32.812% (32.812%)\n",
      "Epoch: [3][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.005)\tLoss 1.5318 (1.5698)\tPrec 47.656% (41.399%)\n",
      "Epoch: [3][200/391]\tTime 0.058 (0.055)\tData 0.002 (0.003)\tLoss 1.7056 (1.5736)\tPrec 39.062% (40.769%)\n",
      "Epoch: [3][300/391]\tTime 0.054 (0.055)\tData 0.002 (0.003)\tLoss 1.5643 (1.5743)\tPrec 40.625% (40.747%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.326 (0.326)\tLoss 1.5945 (1.5945)\tPrec 46.094% (46.094%)\n",
      " * Prec 40.960% \n",
      "best acc: 40.960000\n",
      "Epoch: [4][0/391]\tTime 0.415 (0.415)\tData 0.374 (0.374)\tLoss 1.4282 (1.4282)\tPrec 44.531% (44.531%)\n",
      "Epoch: [4][100/391]\tTime 0.052 (0.057)\tData 0.005 (0.006)\tLoss 1.4984 (1.5542)\tPrec 49.219% (41.561%)\n",
      "Epoch: [4][200/391]\tTime 0.061 (0.056)\tData 0.002 (0.005)\tLoss 1.4851 (1.5542)\tPrec 41.406% (41.865%)\n",
      "Epoch: [4][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.005)\tLoss 1.6056 (1.5528)\tPrec 41.406% (41.938%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.306 (0.306)\tLoss 1.5782 (1.5782)\tPrec 41.406% (41.406%)\n",
      " * Prec 41.280% \n",
      "best acc: 41.280000\n",
      "Epoch: [5][0/391]\tTime 0.381 (0.381)\tData 0.327 (0.327)\tLoss 1.6242 (1.6242)\tPrec 37.500% (37.500%)\n",
      "Epoch: [5][100/391]\tTime 0.068 (0.057)\tData 0.003 (0.005)\tLoss 1.5697 (1.5318)\tPrec 36.719% (42.249%)\n",
      "Epoch: [5][200/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 1.6324 (1.5373)\tPrec 40.625% (42.541%)\n",
      "Epoch: [5][300/391]\tTime 0.053 (0.055)\tData 0.002 (0.003)\tLoss 1.3689 (1.5395)\tPrec 48.438% (42.611%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.269 (0.269)\tLoss 1.5681 (1.5681)\tPrec 42.969% (42.969%)\n",
      " * Prec 42.470% \n",
      "best acc: 42.470000\n",
      "Epoch: [6][0/391]\tTime 0.408 (0.408)\tData 0.368 (0.368)\tLoss 1.5639 (1.5639)\tPrec 38.281% (38.281%)\n",
      "Epoch: [6][100/391]\tTime 0.054 (0.057)\tData 0.002 (0.006)\tLoss 1.4807 (1.5179)\tPrec 43.750% (43.912%)\n",
      "Epoch: [6][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.5285 (1.5229)\tPrec 39.844% (43.482%)\n",
      "Epoch: [6][300/391]\tTime 0.055 (0.056)\tData 0.003 (0.004)\tLoss 1.6157 (1.5207)\tPrec 44.531% (43.768%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.334 (0.334)\tLoss 1.6548 (1.6548)\tPrec 32.812% (32.812%)\n",
      " * Prec 42.610% \n",
      "best acc: 42.610000\n",
      "Epoch: [7][0/391]\tTime 0.479 (0.479)\tData 0.438 (0.438)\tLoss 1.5112 (1.5112)\tPrec 44.531% (44.531%)\n",
      "Epoch: [7][100/391]\tTime 0.053 (0.059)\tData 0.002 (0.008)\tLoss 1.5458 (1.5143)\tPrec 42.969% (43.704%)\n",
      "Epoch: [7][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.6283 (1.5159)\tPrec 39.062% (43.420%)\n",
      "Epoch: [7][300/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 1.5199 (1.5110)\tPrec 39.844% (43.781%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.346 (0.346)\tLoss 1.5958 (1.5958)\tPrec 34.375% (34.375%)\n",
      " * Prec 43.370% \n",
      "best acc: 43.370000\n",
      "Epoch: [8][0/391]\tTime 0.404 (0.404)\tData 0.364 (0.364)\tLoss 1.4754 (1.4754)\tPrec 50.781% (50.781%)\n",
      "Epoch: [8][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.5104 (1.5068)\tPrec 46.094% (43.765%)\n",
      "Epoch: [8][200/391]\tTime 0.054 (0.056)\tData 0.004 (0.004)\tLoss 1.5871 (1.5091)\tPrec 44.531% (43.925%)\n",
      "Epoch: [8][300/391]\tTime 0.055 (0.056)\tData 0.003 (0.004)\tLoss 1.3889 (1.5052)\tPrec 51.562% (44.313%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.487 (0.487)\tLoss 1.4959 (1.4959)\tPrec 42.969% (42.969%)\n",
      " * Prec 47.210% \n",
      "best acc: 47.210000\n",
      "Epoch: [9][0/391]\tTime 0.378 (0.378)\tData 0.337 (0.337)\tLoss 1.4304 (1.4304)\tPrec 46.094% (46.094%)\n",
      "Epoch: [9][100/391]\tTime 0.054 (0.057)\tData 0.004 (0.006)\tLoss 1.5031 (1.4999)\tPrec 44.531% (44.407%)\n",
      "Epoch: [9][200/391]\tTime 0.051 (0.056)\tData 0.002 (0.004)\tLoss 1.5225 (1.4968)\tPrec 42.969% (44.372%)\n",
      "Epoch: [9][300/391]\tTime 0.068 (0.056)\tData 0.015 (0.004)\tLoss 1.4729 (1.4964)\tPrec 38.281% (44.373%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.380 (0.380)\tLoss 1.4977 (1.4977)\tPrec 49.219% (49.219%)\n",
      " * Prec 46.070% \n",
      "best acc: 47.210000\n",
      "Epoch: [10][0/391]\tTime 0.475 (0.475)\tData 0.435 (0.435)\tLoss 1.4072 (1.4072)\tPrec 48.438% (48.438%)\n",
      "Epoch: [10][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.007)\tLoss 1.5891 (1.5018)\tPrec 42.969% (44.361%)\n",
      "Epoch: [10][200/391]\tTime 0.052 (0.057)\tData 0.002 (0.005)\tLoss 1.5438 (1.4972)\tPrec 42.188% (44.349%)\n",
      "Epoch: [10][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.5986 (1.4990)\tPrec 33.594% (44.363%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.424 (0.424)\tLoss 1.5644 (1.5644)\tPrec 39.062% (39.062%)\n",
      " * Prec 44.830% \n",
      "best acc: 47.210000\n",
      "Epoch: [11][0/391]\tTime 0.398 (0.398)\tData 0.358 (0.358)\tLoss 1.5002 (1.5002)\tPrec 42.188% (42.188%)\n",
      "Epoch: [11][100/391]\tTime 0.041 (0.058)\tData 0.002 (0.007)\tLoss 1.4971 (1.5075)\tPrec 49.219% (44.137%)\n",
      "Epoch: [11][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.004)\tLoss 1.5757 (1.5015)\tPrec 39.844% (44.042%)\n",
      "Epoch: [11][300/391]\tTime 0.060 (0.056)\tData 0.002 (0.004)\tLoss 1.5074 (1.5034)\tPrec 44.531% (43.932%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.359 (0.359)\tLoss 1.5604 (1.5604)\tPrec 44.531% (44.531%)\n",
      " * Prec 45.090% \n",
      "best acc: 47.210000\n",
      "Epoch: [12][0/391]\tTime 0.425 (0.425)\tData 0.364 (0.364)\tLoss 1.4960 (1.4960)\tPrec 42.188% (42.188%)\n",
      "Epoch: [12][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.006)\tLoss 1.3817 (1.4927)\tPrec 45.312% (44.647%)\n",
      "Epoch: [12][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.004)\tLoss 1.5972 (1.4922)\tPrec 40.625% (44.687%)\n",
      "Epoch: [12][300/391]\tTime 0.051 (0.055)\tData 0.002 (0.004)\tLoss 1.5631 (1.4913)\tPrec 42.188% (44.848%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.450 (0.450)\tLoss 1.4398 (1.4398)\tPrec 42.969% (42.969%)\n",
      " * Prec 46.490% \n",
      "best acc: 47.210000\n",
      "Epoch: [13][0/391]\tTime 0.499 (0.499)\tData 0.459 (0.459)\tLoss 1.4465 (1.4465)\tPrec 46.094% (46.094%)\n",
      "Epoch: [13][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.007)\tLoss 1.5775 (1.4877)\tPrec 42.969% (45.019%)\n",
      "Epoch: [13][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.6458 (1.4900)\tPrec 38.281% (45.091%)\n",
      "Epoch: [13][300/391]\tTime 0.040 (0.056)\tData 0.002 (0.004)\tLoss 1.4025 (1.4851)\tPrec 46.094% (45.097%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.476 (0.476)\tLoss 1.5565 (1.5565)\tPrec 39.062% (39.062%)\n",
      " * Prec 45.350% \n",
      "best acc: 47.210000\n",
      "Epoch: [14][0/391]\tTime 0.422 (0.422)\tData 0.380 (0.380)\tLoss 1.4887 (1.4887)\tPrec 43.750% (43.750%)\n",
      "Epoch: [14][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.007)\tLoss 1.3692 (1.4898)\tPrec 43.750% (44.964%)\n",
      "Epoch: [14][200/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 1.6145 (1.4845)\tPrec 43.750% (45.110%)\n",
      "Epoch: [14][300/391]\tTime 0.057 (0.055)\tData 0.002 (0.004)\tLoss 1.3623 (1.4860)\tPrec 54.688% (45.004%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.368 (0.368)\tLoss 1.5537 (1.5537)\tPrec 42.188% (42.188%)\n",
      " * Prec 45.430% \n",
      "best acc: 47.210000\n",
      "Epoch: [15][0/391]\tTime 0.376 (0.376)\tData 0.305 (0.305)\tLoss 1.3267 (1.3267)\tPrec 50.000% (50.000%)\n",
      "Epoch: [15][100/391]\tTime 0.053 (0.060)\tData 0.002 (0.006)\tLoss 1.4928 (1.4872)\tPrec 46.875% (44.964%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.058 (0.057)\tData 0.002 (0.004)\tLoss 1.4857 (1.4839)\tPrec 47.656% (44.850%)\n",
      "Epoch: [15][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 1.7088 (1.4864)\tPrec 37.500% (44.884%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.377 (0.377)\tLoss 1.4847 (1.4847)\tPrec 48.438% (48.438%)\n",
      " * Prec 45.060% \n",
      "best acc: 47.210000\n",
      "Epoch: [16][0/391]\tTime 0.382 (0.382)\tData 0.342 (0.342)\tLoss 1.4197 (1.4197)\tPrec 43.750% (43.750%)\n",
      "Epoch: [16][100/391]\tTime 0.046 (0.057)\tData 0.002 (0.006)\tLoss 1.5512 (1.4770)\tPrec 41.406% (44.833%)\n",
      "Epoch: [16][200/391]\tTime 0.060 (0.055)\tData 0.012 (0.004)\tLoss 1.3584 (1.4842)\tPrec 50.000% (44.912%)\n",
      "Epoch: [16][300/391]\tTime 0.049 (0.055)\tData 0.002 (0.003)\tLoss 1.5789 (1.4842)\tPrec 43.750% (44.866%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.276 (0.276)\tLoss 1.4709 (1.4709)\tPrec 46.875% (46.875%)\n",
      " * Prec 45.210% \n",
      "best acc: 47.210000\n",
      "Epoch: [17][0/391]\tTime 0.338 (0.338)\tData 0.291 (0.291)\tLoss 1.4062 (1.4062)\tPrec 43.750% (43.750%)\n",
      "Epoch: [17][100/391]\tTime 0.065 (0.057)\tData 0.002 (0.005)\tLoss 1.3972 (1.4514)\tPrec 47.656% (46.434%)\n",
      "Epoch: [17][200/391]\tTime 0.043 (0.055)\tData 0.002 (0.004)\tLoss 1.5414 (1.4704)\tPrec 43.750% (45.670%)\n",
      "Epoch: [17][300/391]\tTime 0.051 (0.055)\tData 0.002 (0.003)\tLoss 1.5844 (1.4790)\tPrec 34.375% (45.224%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.311 (0.311)\tLoss 1.5709 (1.5709)\tPrec 39.844% (39.844%)\n",
      " * Prec 44.550% \n",
      "best acc: 47.210000\n",
      "Epoch: [18][0/391]\tTime 0.326 (0.326)\tData 0.286 (0.286)\tLoss 1.3939 (1.3939)\tPrec 47.656% (47.656%)\n",
      "Epoch: [18][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.005)\tLoss 1.3143 (1.4668)\tPrec 47.656% (45.784%)\n",
      "Epoch: [18][200/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 1.4699 (1.4728)\tPrec 45.312% (45.604%)\n",
      "Epoch: [18][300/391]\tTime 0.055 (0.055)\tData 0.002 (0.003)\tLoss 1.4988 (1.4800)\tPrec 46.094% (45.331%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.282 (0.282)\tLoss 1.4652 (1.4652)\tPrec 41.406% (41.406%)\n",
      " * Prec 47.330% \n",
      "best acc: 47.330000\n",
      "Epoch: [19][0/391]\tTime 0.506 (0.506)\tData 0.465 (0.465)\tLoss 1.4972 (1.4972)\tPrec 43.750% (43.750%)\n",
      "Epoch: [19][100/391]\tTime 0.054 (0.061)\tData 0.001 (0.009)\tLoss 1.3594 (1.4763)\tPrec 47.656% (45.243%)\n",
      "Epoch: [19][200/391]\tTime 0.064 (0.058)\tData 0.002 (0.006)\tLoss 1.3745 (1.4702)\tPrec 49.219% (45.662%)\n",
      "Epoch: [19][300/391]\tTime 0.058 (0.058)\tData 0.006 (0.005)\tLoss 1.5636 (1.4678)\tPrec 44.531% (45.795%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.345 (0.345)\tLoss 1.5715 (1.5715)\tPrec 41.406% (41.406%)\n",
      " * Prec 40.690% \n",
      "best acc: 47.330000\n",
      "Epoch: [20][0/391]\tTime 0.360 (0.360)\tData 0.319 (0.319)\tLoss 1.4305 (1.4305)\tPrec 47.656% (47.656%)\n",
      "Epoch: [20][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.006)\tLoss 1.4336 (1.4733)\tPrec 46.875% (46.125%)\n",
      "Epoch: [20][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.4296 (1.4703)\tPrec 45.312% (45.919%)\n",
      "Epoch: [20][300/391]\tTime 0.074 (0.055)\tData 0.005 (0.004)\tLoss 1.6038 (1.4712)\tPrec 41.406% (45.912%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.493 (0.493)\tLoss 1.5531 (1.5531)\tPrec 42.969% (42.969%)\n",
      " * Prec 46.890% \n",
      "best acc: 47.330000\n",
      "Epoch: [21][0/391]\tTime 0.440 (0.440)\tData 0.386 (0.386)\tLoss 1.5607 (1.5607)\tPrec 37.500% (37.500%)\n",
      "Epoch: [21][100/391]\tTime 0.054 (0.060)\tData 0.009 (0.007)\tLoss 1.5322 (1.4657)\tPrec 40.625% (46.032%)\n",
      "Epoch: [21][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.005)\tLoss 1.5663 (1.4645)\tPrec 39.062% (45.658%)\n",
      "Epoch: [21][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.5103 (1.4685)\tPrec 44.531% (45.653%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.343 (0.343)\tLoss 1.4494 (1.4494)\tPrec 45.312% (45.312%)\n",
      " * Prec 47.820% \n",
      "best acc: 47.820000\n",
      "Epoch: [22][0/391]\tTime 0.397 (0.397)\tData 0.357 (0.357)\tLoss 1.4276 (1.4276)\tPrec 46.875% (46.875%)\n",
      "Epoch: [22][100/391]\tTime 0.053 (0.058)\tData 0.015 (0.008)\tLoss 1.5902 (1.4737)\tPrec 43.750% (45.529%)\n",
      "Epoch: [22][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.6399 (1.5453)\tPrec 40.625% (43.517%)\n",
      "Epoch: [22][300/391]\tTime 0.054 (0.055)\tData 0.002 (0.004)\tLoss 1.5405 (1.5440)\tPrec 42.188% (43.130%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.367 (0.367)\tLoss 1.4982 (1.4982)\tPrec 47.656% (47.656%)\n",
      " * Prec 46.250% \n",
      "best acc: 47.820000\n",
      "Epoch: [23][0/391]\tTime 0.355 (0.355)\tData 0.311 (0.311)\tLoss 1.3679 (1.3679)\tPrec 49.219% (49.219%)\n",
      "Epoch: [23][100/391]\tTime 0.042 (0.058)\tData 0.002 (0.006)\tLoss 1.4457 (1.4756)\tPrec 47.656% (45.297%)\n",
      "Epoch: [23][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.3519 (1.4778)\tPrec 50.000% (45.429%)\n",
      "Epoch: [23][300/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 1.4438 (1.4733)\tPrec 41.406% (45.694%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.353 (0.353)\tLoss 1.6192 (1.6192)\tPrec 39.062% (39.062%)\n",
      " * Prec 46.450% \n",
      "best acc: 47.820000\n",
      "Epoch: [24][0/391]\tTime 0.575 (0.575)\tData 0.532 (0.532)\tLoss 1.4681 (1.4681)\tPrec 42.188% (42.188%)\n",
      "Epoch: [24][100/391]\tTime 0.054 (0.060)\tData 0.002 (0.009)\tLoss 1.5889 (1.4534)\tPrec 38.281% (46.511%)\n",
      "Epoch: [24][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.006)\tLoss 1.4216 (1.4549)\tPrec 46.094% (46.393%)\n",
      "Epoch: [24][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.005)\tLoss 1.6244 (1.4584)\tPrec 42.969% (46.034%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.397 (0.397)\tLoss 1.4805 (1.4805)\tPrec 44.531% (44.531%)\n",
      " * Prec 47.040% \n",
      "best acc: 47.820000\n",
      "Epoch: [25][0/391]\tTime 0.392 (0.392)\tData 0.351 (0.351)\tLoss 1.5454 (1.5454)\tPrec 39.844% (39.844%)\n",
      "Epoch: [25][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.009)\tLoss 1.4455 (1.4399)\tPrec 46.875% (46.759%)\n",
      "Epoch: [25][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.006)\tLoss 1.4930 (1.4491)\tPrec 44.531% (46.397%)\n",
      "Epoch: [25][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.005)\tLoss 1.5740 (1.4481)\tPrec 40.625% (46.413%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.342 (0.342)\tLoss 1.4769 (1.4769)\tPrec 42.969% (42.969%)\n",
      " * Prec 47.050% \n",
      "best acc: 47.820000\n",
      "Epoch: [26][0/391]\tTime 0.408 (0.408)\tData 0.364 (0.364)\tLoss 1.4610 (1.4610)\tPrec 45.312% (45.312%)\n",
      "Epoch: [26][100/391]\tTime 0.053 (0.059)\tData 0.003 (0.007)\tLoss 1.7139 (1.4466)\tPrec 35.156% (46.465%)\n",
      "Epoch: [26][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.4621 (1.4478)\tPrec 49.219% (46.377%)\n",
      "Epoch: [26][300/391]\tTime 0.053 (0.055)\tData 0.001 (0.004)\tLoss 1.4774 (1.4481)\tPrec 46.094% (46.444%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.388 (0.388)\tLoss 1.4829 (1.4829)\tPrec 41.406% (41.406%)\n",
      " * Prec 48.200% \n",
      "best acc: 48.200000\n",
      "Epoch: [27][0/391]\tTime 0.499 (0.499)\tData 0.459 (0.459)\tLoss 1.4252 (1.4252)\tPrec 44.531% (44.531%)\n",
      "Epoch: [27][100/391]\tTime 0.054 (0.059)\tData 0.003 (0.009)\tLoss 1.4494 (1.4415)\tPrec 51.562% (47.153%)\n",
      "Epoch: [27][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.006)\tLoss 1.4416 (1.4443)\tPrec 47.656% (46.389%)\n",
      "Epoch: [27][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.005)\tLoss 1.5906 (1.4465)\tPrec 41.406% (46.397%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.359 (0.359)\tLoss 1.5620 (1.5620)\tPrec 43.750% (43.750%)\n",
      " * Prec 44.010% \n",
      "best acc: 48.200000\n",
      "Epoch: [28][0/391]\tTime 0.429 (0.429)\tData 0.384 (0.384)\tLoss 1.5000 (1.5000)\tPrec 37.500% (37.500%)\n",
      "Epoch: [28][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.007)\tLoss 1.3694 (1.4534)\tPrec 45.312% (46.078%)\n",
      "Epoch: [28][200/391]\tTime 0.066 (0.057)\tData 0.002 (0.005)\tLoss 1.4085 (1.4493)\tPrec 47.656% (46.428%)\n",
      "Epoch: [28][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.005)\tLoss 1.2267 (1.4484)\tPrec 56.250% (46.460%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.336 (0.336)\tLoss 1.5034 (1.5034)\tPrec 43.750% (43.750%)\n",
      " * Prec 45.190% \n",
      "best acc: 48.200000\n",
      "Epoch: [29][0/391]\tTime 0.511 (0.511)\tData 0.448 (0.448)\tLoss 1.4227 (1.4227)\tPrec 42.969% (42.969%)\n",
      "Epoch: [29][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.007)\tLoss 1.3953 (1.4514)\tPrec 50.781% (46.334%)\n",
      "Epoch: [29][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.5148 (1.4542)\tPrec 46.094% (46.008%)\n",
      "Epoch: [29][300/391]\tTime 0.063 (0.055)\tData 0.014 (0.004)\tLoss 1.4471 (1.4506)\tPrec 53.125% (46.286%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.394 (0.394)\tLoss 1.5703 (1.5703)\tPrec 40.625% (40.625%)\n",
      " * Prec 45.330% \n",
      "best acc: 48.200000\n",
      "Epoch: [30][0/391]\tTime 0.557 (0.557)\tData 0.503 (0.503)\tLoss 1.3356 (1.3356)\tPrec 44.531% (44.531%)\n",
      "Epoch: [30][100/391]\tTime 0.054 (0.062)\tData 0.003 (0.009)\tLoss 1.3842 (1.4465)\tPrec 48.438% (46.542%)\n",
      "Epoch: [30][200/391]\tTime 0.048 (0.061)\tData 0.002 (0.007)\tLoss 1.4370 (1.4446)\tPrec 45.312% (46.486%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.072 (0.059)\tData 0.003 (0.006)\tLoss 1.5631 (1.4513)\tPrec 40.625% (46.255%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.308 (0.308)\tLoss 1.4771 (1.4771)\tPrec 46.094% (46.094%)\n",
      " * Prec 47.910% \n",
      "best acc: 48.200000\n",
      "Epoch: [31][0/391]\tTime 0.425 (0.425)\tData 0.382 (0.382)\tLoss 1.4872 (1.4872)\tPrec 43.750% (43.750%)\n",
      "Epoch: [31][100/391]\tTime 0.046 (0.059)\tData 0.007 (0.007)\tLoss 1.3767 (1.4454)\tPrec 50.000% (46.535%)\n",
      "Epoch: [31][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.005)\tLoss 1.3358 (1.4483)\tPrec 52.344% (46.521%)\n",
      "Epoch: [31][300/391]\tTime 0.041 (0.056)\tData 0.004 (0.005)\tLoss 1.8140 (1.4638)\tPrec 28.125% (46.153%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.384 (0.384)\tLoss 1.5379 (1.5379)\tPrec 39.844% (39.844%)\n",
      " * Prec 44.480% \n",
      "best acc: 48.200000\n",
      "Epoch: [32][0/391]\tTime 0.400 (0.400)\tData 0.358 (0.358)\tLoss 1.3607 (1.3607)\tPrec 49.219% (49.219%)\n",
      "Epoch: [32][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.007)\tLoss 1.3661 (1.4682)\tPrec 53.906% (45.537%)\n",
      "Epoch: [32][200/391]\tTime 0.054 (0.056)\tData 0.003 (0.004)\tLoss 1.5958 (1.4598)\tPrec 41.406% (46.024%)\n",
      "Epoch: [32][300/391]\tTime 0.064 (0.055)\tData 0.002 (0.004)\tLoss 1.3600 (1.4555)\tPrec 47.656% (46.231%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.412 (0.412)\tLoss 1.4669 (1.4669)\tPrec 48.438% (48.438%)\n",
      " * Prec 45.790% \n",
      "best acc: 48.200000\n",
      "Epoch: [33][0/391]\tTime 0.419 (0.419)\tData 0.374 (0.374)\tLoss 1.5709 (1.5709)\tPrec 42.188% (42.188%)\n",
      "Epoch: [33][100/391]\tTime 0.053 (0.059)\tData 0.002 (0.009)\tLoss 1.4363 (1.4413)\tPrec 46.875% (46.689%)\n",
      "Epoch: [33][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.006)\tLoss 1.3240 (1.4452)\tPrec 48.438% (46.265%)\n",
      "Epoch: [33][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.4741 (1.4501)\tPrec 50.000% (46.190%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.363 (0.363)\tLoss 1.5013 (1.5013)\tPrec 46.875% (46.875%)\n",
      " * Prec 46.590% \n",
      "best acc: 48.200000\n",
      "Epoch: [34][0/391]\tTime 0.294 (0.294)\tData 0.254 (0.254)\tLoss 1.3480 (1.3480)\tPrec 50.000% (50.000%)\n",
      "Epoch: [34][100/391]\tTime 0.056 (0.060)\tData 0.002 (0.006)\tLoss 1.4120 (1.4412)\tPrec 46.094% (46.883%)\n",
      "Epoch: [34][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.005)\tLoss 1.4993 (1.4437)\tPrec 42.188% (46.786%)\n",
      "Epoch: [34][300/391]\tTime 0.055 (0.058)\tData 0.003 (0.005)\tLoss 1.4484 (1.4420)\tPrec 46.875% (46.779%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.293 (0.293)\tLoss 1.4926 (1.4926)\tPrec 42.969% (42.969%)\n",
      " * Prec 48.110% \n",
      "best acc: 48.200000\n",
      "Epoch: [35][0/391]\tTime 0.551 (0.551)\tData 0.510 (0.510)\tLoss 1.3298 (1.3298)\tPrec 49.219% (49.219%)\n",
      "Epoch: [35][100/391]\tTime 0.060 (0.062)\tData 0.002 (0.012)\tLoss 1.6472 (1.4396)\tPrec 39.844% (46.852%)\n",
      "Epoch: [35][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.007)\tLoss 1.3441 (1.4429)\tPrec 46.094% (46.335%)\n",
      "Epoch: [35][300/391]\tTime 0.062 (0.057)\tData 0.015 (0.006)\tLoss 1.4380 (1.4414)\tPrec 42.188% (46.597%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.414 (0.414)\tLoss 1.3949 (1.3949)\tPrec 50.000% (50.000%)\n",
      " * Prec 47.550% \n",
      "best acc: 48.200000\n",
      "Epoch: [36][0/391]\tTime 0.378 (0.378)\tData 0.332 (0.332)\tLoss 1.3783 (1.3783)\tPrec 49.219% (49.219%)\n",
      "Epoch: [36][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.4640 (1.4398)\tPrec 47.656% (46.604%)\n",
      "Epoch: [36][200/391]\tTime 0.066 (0.059)\tData 0.002 (0.005)\tLoss 1.4306 (1.4396)\tPrec 43.750% (46.793%)\n",
      "Epoch: [36][300/391]\tTime 0.058 (0.060)\tData 0.004 (0.005)\tLoss 1.2681 (1.4354)\tPrec 47.656% (47.059%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.494 (0.494)\tLoss 1.4505 (1.4505)\tPrec 42.969% (42.969%)\n",
      " * Prec 45.570% \n",
      "best acc: 48.200000\n",
      "Epoch: [37][0/391]\tTime 0.357 (0.357)\tData 0.312 (0.312)\tLoss 1.4394 (1.4394)\tPrec 43.750% (43.750%)\n",
      "Epoch: [37][100/391]\tTime 0.054 (0.059)\tData 0.003 (0.007)\tLoss 1.3885 (1.4264)\tPrec 50.000% (47.153%)\n",
      "Epoch: [37][200/391]\tTime 0.057 (0.057)\tData 0.002 (0.005)\tLoss 1.5325 (1.4423)\tPrec 42.969% (46.541%)\n",
      "Epoch: [37][300/391]\tTime 0.058 (0.056)\tData 0.016 (0.005)\tLoss 1.4793 (1.4349)\tPrec 45.312% (46.966%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.358 (0.358)\tLoss 1.4892 (1.4892)\tPrec 41.406% (41.406%)\n",
      " * Prec 47.140% \n",
      "best acc: 48.200000\n",
      "Epoch: [38][0/391]\tTime 0.537 (0.537)\tData 0.473 (0.473)\tLoss 1.3571 (1.3571)\tPrec 50.781% (50.781%)\n",
      "Epoch: [38][100/391]\tTime 0.055 (0.060)\tData 0.002 (0.009)\tLoss 1.4404 (1.4386)\tPrec 43.750% (47.177%)\n",
      "Epoch: [38][200/391]\tTime 0.054 (0.059)\tData 0.001 (0.007)\tLoss 1.5325 (1.4435)\tPrec 42.188% (46.716%)\n",
      "Epoch: [38][300/391]\tTime 0.053 (0.058)\tData 0.001 (0.007)\tLoss 1.4910 (1.4442)\tPrec 48.438% (46.789%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.451 (0.451)\tLoss 1.4806 (1.4806)\tPrec 45.312% (45.312%)\n",
      " * Prec 46.170% \n",
      "best acc: 48.200000\n",
      "Epoch: [39][0/391]\tTime 0.465 (0.465)\tData 0.421 (0.421)\tLoss 1.4321 (1.4321)\tPrec 52.344% (52.344%)\n",
      "Epoch: [39][100/391]\tTime 0.054 (0.060)\tData 0.001 (0.008)\tLoss 1.5140 (1.4318)\tPrec 49.219% (47.208%)\n",
      "Epoch: [39][200/391]\tTime 0.053 (0.058)\tData 0.001 (0.008)\tLoss 1.5486 (1.4439)\tPrec 45.312% (46.700%)\n",
      "Epoch: [39][300/391]\tTime 0.052 (0.057)\tData 0.002 (0.006)\tLoss 1.4519 (1.4474)\tPrec 46.875% (46.519%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.443 (0.443)\tLoss 1.4315 (1.4315)\tPrec 48.438% (48.438%)\n",
      " * Prec 47.310% \n",
      "best acc: 48.200000\n",
      "Epoch: [40][0/391]\tTime 0.455 (0.455)\tData 0.388 (0.388)\tLoss 1.5200 (1.5200)\tPrec 48.438% (48.438%)\n",
      "Epoch: [40][100/391]\tTime 0.064 (0.060)\tData 0.028 (0.010)\tLoss 1.6208 (1.4406)\tPrec 41.406% (46.666%)\n",
      "Epoch: [40][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.008)\tLoss 1.4619 (1.4486)\tPrec 43.750% (46.354%)\n",
      "Epoch: [40][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.006)\tLoss 1.4140 (1.4437)\tPrec 47.656% (46.647%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.460 (0.460)\tLoss 1.4053 (1.4053)\tPrec 46.875% (46.875%)\n",
      " * Prec 48.950% \n",
      "best acc: 48.950000\n",
      "Epoch: [41][0/391]\tTime 0.452 (0.452)\tData 0.368 (0.368)\tLoss 1.3233 (1.3233)\tPrec 53.125% (53.125%)\n",
      "Epoch: [41][100/391]\tTime 0.053 (0.061)\tData 0.002 (0.010)\tLoss 1.6058 (1.4415)\tPrec 44.531% (47.061%)\n",
      "Epoch: [41][200/391]\tTime 0.053 (0.058)\tData 0.002 (0.006)\tLoss 1.4674 (1.4386)\tPrec 43.750% (46.937%)\n",
      "Epoch: [41][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.4402 (1.4403)\tPrec 46.094% (46.904%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.515 (0.515)\tLoss 1.4060 (1.4060)\tPrec 46.875% (46.875%)\n",
      " * Prec 48.000% \n",
      "best acc: 48.950000\n",
      "Epoch: [42][0/391]\tTime 0.412 (0.412)\tData 0.370 (0.370)\tLoss 1.4837 (1.4837)\tPrec 41.406% (41.406%)\n",
      "Epoch: [42][100/391]\tTime 0.053 (0.063)\tData 0.001 (0.010)\tLoss 1.3579 (1.4419)\tPrec 50.781% (47.014%)\n",
      "Epoch: [42][200/391]\tTime 0.056 (0.059)\tData 0.002 (0.007)\tLoss 1.5770 (1.4380)\tPrec 42.969% (47.104%)\n",
      "Epoch: [42][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.006)\tLoss 1.4940 (1.4366)\tPrec 42.969% (47.041%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.391 (0.391)\tLoss 1.4804 (1.4804)\tPrec 44.531% (44.531%)\n",
      " * Prec 48.110% \n",
      "best acc: 48.950000\n",
      "Epoch: [43][0/391]\tTime 0.521 (0.521)\tData 0.469 (0.469)\tLoss 1.6111 (1.6111)\tPrec 39.844% (39.844%)\n",
      "Epoch: [43][100/391]\tTime 0.055 (0.064)\tData 0.001 (0.010)\tLoss 1.3855 (1.4547)\tPrec 53.906% (46.326%)\n",
      "Epoch: [43][200/391]\tTime 0.050 (0.061)\tData 0.002 (0.007)\tLoss 1.4699 (1.4435)\tPrec 43.750% (46.622%)\n",
      "Epoch: [43][300/391]\tTime 0.050 (0.058)\tData 0.002 (0.006)\tLoss 1.3203 (1.4385)\tPrec 52.344% (46.862%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.297 (0.297)\tLoss 1.3586 (1.3586)\tPrec 48.438% (48.438%)\n",
      " * Prec 48.710% \n",
      "best acc: 48.950000\n",
      "Epoch: [44][0/391]\tTime 0.567 (0.567)\tData 0.523 (0.523)\tLoss 1.3599 (1.3599)\tPrec 48.438% (48.438%)\n",
      "Epoch: [44][100/391]\tTime 0.052 (0.063)\tData 0.002 (0.009)\tLoss 1.3154 (1.4363)\tPrec 48.438% (47.006%)\n",
      "Epoch: [44][200/391]\tTime 0.053 (0.059)\tData 0.002 (0.006)\tLoss 1.5098 (1.4344)\tPrec 46.094% (47.073%)\n",
      "Epoch: [44][300/391]\tTime 0.058 (0.058)\tData 0.001 (0.005)\tLoss 1.5253 (1.4320)\tPrec 44.531% (47.109%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.382 (0.382)\tLoss 1.5065 (1.5065)\tPrec 42.969% (42.969%)\n",
      " * Prec 46.820% \n",
      "best acc: 48.950000\n",
      "Epoch: [45][0/391]\tTime 0.426 (0.426)\tData 0.385 (0.385)\tLoss 1.3804 (1.3804)\tPrec 57.812% (57.812%)\n",
      "Epoch: [45][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.007)\tLoss 1.3094 (1.4372)\tPrec 57.031% (47.030%)\n",
      "Epoch: [45][200/391]\tTime 0.054 (0.056)\tData 0.003 (0.005)\tLoss 1.3675 (1.4349)\tPrec 47.656% (46.964%)\n",
      "Epoch: [45][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.004)\tLoss 1.5446 (1.4298)\tPrec 37.500% (47.077%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.327 (0.327)\tLoss 1.5138 (1.5138)\tPrec 46.094% (46.094%)\n",
      " * Prec 48.920% \n",
      "best acc: 48.950000\n",
      "Epoch: [46][0/391]\tTime 0.445 (0.445)\tData 0.398 (0.398)\tLoss 1.2840 (1.2840)\tPrec 50.781% (50.781%)\n",
      "Epoch: [46][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.007)\tLoss 1.4434 (1.4231)\tPrec 43.750% (47.850%)\n",
      "Epoch: [46][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.006)\tLoss 1.3525 (1.4355)\tPrec 48.438% (47.190%)\n",
      "Epoch: [46][300/391]\tTime 0.053 (0.056)\tData 0.004 (0.005)\tLoss 1.5156 (1.4368)\tPrec 42.188% (47.197%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.371 (0.371)\tLoss 1.4386 (1.4386)\tPrec 44.531% (44.531%)\n",
      " * Prec 48.630% \n",
      "best acc: 48.950000\n",
      "Epoch: [47][0/391]\tTime 0.370 (0.370)\tData 0.328 (0.328)\tLoss 1.5556 (1.5556)\tPrec 43.750% (43.750%)\n",
      "Epoch: [47][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.006)\tLoss 1.3561 (1.4271)\tPrec 50.000% (47.308%)\n",
      "Epoch: [47][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.5391 (1.4377)\tPrec 40.625% (47.065%)\n",
      "Epoch: [47][300/391]\tTime 0.064 (0.056)\tData 0.003 (0.004)\tLoss 1.5627 (1.4367)\tPrec 39.844% (47.044%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.413 (0.413)\tLoss 1.4714 (1.4714)\tPrec 46.094% (46.094%)\n",
      " * Prec 47.320% \n",
      "best acc: 48.950000\n",
      "Epoch: [48][0/391]\tTime 0.424 (0.424)\tData 0.379 (0.379)\tLoss 1.4659 (1.4659)\tPrec 43.750% (43.750%)\n",
      "Epoch: [48][100/391]\tTime 0.044 (0.058)\tData 0.003 (0.007)\tLoss 1.3221 (1.4385)\tPrec 50.000% (46.836%)\n",
      "Epoch: [48][200/391]\tTime 0.061 (0.056)\tData 0.002 (0.004)\tLoss 1.4350 (1.4294)\tPrec 46.094% (47.283%)\n",
      "Epoch: [48][300/391]\tTime 0.060 (0.055)\tData 0.002 (0.004)\tLoss 1.4219 (1.4266)\tPrec 48.438% (47.350%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.336 (0.336)\tLoss 1.9821 (1.9821)\tPrec 30.469% (30.469%)\n",
      " * Prec 37.430% \n",
      "best acc: 48.950000\n",
      "Epoch: [49][0/391]\tTime 0.446 (0.446)\tData 0.391 (0.391)\tLoss 1.5273 (1.5273)\tPrec 43.750% (43.750%)\n",
      "Epoch: [49][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.007)\tLoss 1.5470 (1.4293)\tPrec 44.531% (47.130%)\n",
      "Epoch: [49][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.4974 (1.4269)\tPrec 45.312% (47.003%)\n",
      "Epoch: [49][300/391]\tTime 0.052 (0.056)\tData 0.002 (0.004)\tLoss 1.5873 (1.4273)\tPrec 44.531% (47.155%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.258 (0.258)\tLoss 1.3868 (1.3868)\tPrec 47.656% (47.656%)\n",
      " * Prec 49.040% \n",
      "best acc: 49.040000\n",
      "Epoch: [50][0/391]\tTime 0.397 (0.397)\tData 0.356 (0.356)\tLoss 1.2966 (1.2966)\tPrec 52.344% (52.344%)\n",
      "Epoch: [50][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.006)\tLoss 1.4754 (1.4200)\tPrec 44.531% (47.881%)\n",
      "Epoch: [50][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.004)\tLoss 1.5094 (1.4270)\tPrec 46.875% (47.544%)\n",
      "Epoch: [50][300/391]\tTime 0.044 (0.056)\tData 0.004 (0.004)\tLoss 1.2522 (1.4258)\tPrec 57.031% (47.646%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.378 (0.378)\tLoss 1.3980 (1.3980)\tPrec 49.219% (49.219%)\n",
      " * Prec 48.930% \n",
      "best acc: 49.040000\n",
      "Epoch: [51][0/391]\tTime 0.524 (0.524)\tData 0.483 (0.483)\tLoss 1.4148 (1.4148)\tPrec 44.531% (44.531%)\n",
      "Epoch: [51][100/391]\tTime 0.064 (0.061)\tData 0.001 (0.011)\tLoss 1.4107 (1.4259)\tPrec 53.125% (47.502%)\n",
      "Epoch: [51][200/391]\tTime 0.046 (0.057)\tData 0.002 (0.006)\tLoss 1.4461 (1.4309)\tPrec 42.188% (47.248%)\n",
      "Epoch: [51][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.5958 (1.4301)\tPrec 42.969% (47.207%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.551 (0.551)\tLoss 1.5208 (1.5208)\tPrec 47.656% (47.656%)\n",
      " * Prec 45.490% \n",
      "best acc: 49.040000\n",
      "Epoch: [52][0/391]\tTime 0.461 (0.461)\tData 0.417 (0.417)\tLoss 1.3987 (1.3987)\tPrec 45.312% (45.312%)\n",
      "Epoch: [52][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.007)\tLoss 1.4210 (1.4299)\tPrec 47.656% (46.914%)\n",
      "Epoch: [52][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.005)\tLoss 1.3634 (1.4293)\tPrec 56.250% (47.221%)\n",
      "Epoch: [52][300/391]\tTime 0.065 (0.056)\tData 0.001 (0.005)\tLoss 1.3933 (1.4254)\tPrec 46.094% (47.436%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.341 (0.341)\tLoss 1.8133 (1.8133)\tPrec 37.500% (37.500%)\n",
      " * Prec 35.170% \n",
      "best acc: 49.040000\n",
      "Epoch: [53][0/391]\tTime 0.511 (0.511)\tData 0.463 (0.463)\tLoss 1.4811 (1.4811)\tPrec 42.188% (42.188%)\n",
      "Epoch: [53][100/391]\tTime 0.078 (0.060)\tData 0.005 (0.009)\tLoss 1.5005 (1.4729)\tPrec 47.656% (45.096%)\n",
      "Epoch: [53][200/391]\tTime 0.052 (0.060)\tData 0.002 (0.006)\tLoss 1.3281 (1.4713)\tPrec 46.875% (45.375%)\n",
      "Epoch: [53][300/391]\tTime 0.046 (0.058)\tData 0.002 (0.006)\tLoss 1.4109 (1.4667)\tPrec 49.219% (45.736%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.357 (0.357)\tLoss 1.4195 (1.4195)\tPrec 47.656% (47.656%)\n",
      " * Prec 48.060% \n",
      "best acc: 49.040000\n",
      "Epoch: [54][0/391]\tTime 0.563 (0.563)\tData 0.491 (0.491)\tLoss 1.4738 (1.4738)\tPrec 51.562% (51.562%)\n",
      "Epoch: [54][100/391]\tTime 0.053 (0.062)\tData 0.002 (0.010)\tLoss 1.4260 (1.4464)\tPrec 48.438% (47.084%)\n",
      "Epoch: [54][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.006)\tLoss 1.4208 (1.4410)\tPrec 44.531% (46.576%)\n",
      "Epoch: [54][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.5796 (1.4445)\tPrec 39.844% (46.665%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.372 (0.372)\tLoss 1.4501 (1.4501)\tPrec 48.438% (48.438%)\n",
      " * Prec 49.140% \n",
      "best acc: 49.140000\n",
      "Epoch: [55][0/391]\tTime 0.600 (0.600)\tData 0.560 (0.560)\tLoss 1.3398 (1.3398)\tPrec 45.312% (45.312%)\n",
      "Epoch: [55][100/391]\tTime 0.053 (0.061)\tData 0.002 (0.009)\tLoss 1.3641 (1.4494)\tPrec 52.344% (46.589%)\n",
      "Epoch: [55][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.5956 (1.4417)\tPrec 42.188% (47.069%)\n",
      "Epoch: [55][300/391]\tTime 0.053 (0.056)\tData 0.001 (0.005)\tLoss 1.3314 (1.4416)\tPrec 51.562% (47.249%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.391 (0.391)\tLoss 1.5686 (1.5686)\tPrec 42.188% (42.188%)\n",
      " * Prec 46.570% \n",
      "best acc: 49.140000\n",
      "Epoch: [56][0/391]\tTime 0.374 (0.374)\tData 0.321 (0.321)\tLoss 1.3652 (1.3652)\tPrec 50.781% (50.781%)\n",
      "Epoch: [56][100/391]\tTime 0.073 (0.059)\tData 0.002 (0.008)\tLoss 1.4807 (1.4356)\tPrec 46.875% (47.092%)\n",
      "Epoch: [56][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.3821 (1.4343)\tPrec 50.000% (47.314%)\n",
      "Epoch: [56][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.4169 (1.4335)\tPrec 42.188% (47.241%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.309 (0.309)\tLoss 1.4717 (1.4717)\tPrec 46.094% (46.094%)\n",
      " * Prec 48.490% \n",
      "best acc: 49.140000\n",
      "Epoch: [57][0/391]\tTime 0.535 (0.535)\tData 0.485 (0.485)\tLoss 1.3674 (1.3674)\tPrec 52.344% (52.344%)\n",
      "Epoch: [57][100/391]\tTime 0.053 (0.062)\tData 0.003 (0.009)\tLoss 1.4615 (1.4517)\tPrec 42.969% (46.256%)\n",
      "Epoch: [57][200/391]\tTime 0.058 (0.059)\tData 0.002 (0.006)\tLoss 1.4119 (1.4420)\tPrec 46.875% (46.708%)\n",
      "Epoch: [57][300/391]\tTime 0.054 (0.058)\tData 0.002 (0.005)\tLoss 1.3876 (1.4334)\tPrec 46.875% (46.963%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.290 (0.290)\tLoss 1.4463 (1.4463)\tPrec 49.219% (49.219%)\n",
      " * Prec 46.890% \n",
      "best acc: 49.140000\n",
      "Epoch: [58][0/391]\tTime 0.342 (0.342)\tData 0.297 (0.297)\tLoss 1.5033 (1.5033)\tPrec 46.094% (46.094%)\n",
      "Epoch: [58][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.005)\tLoss 1.5594 (1.4391)\tPrec 41.406% (47.014%)\n",
      "Epoch: [58][200/391]\tTime 0.065 (0.056)\tData 0.029 (0.005)\tLoss 1.2743 (1.4337)\tPrec 53.906% (47.260%)\n",
      "Epoch: [58][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.005)\tLoss 1.3910 (1.4318)\tPrec 50.000% (47.428%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.394 (0.394)\tLoss 1.4592 (1.4592)\tPrec 46.094% (46.094%)\n",
      " * Prec 48.430% \n",
      "best acc: 49.140000\n",
      "Epoch: [59][0/391]\tTime 0.418 (0.418)\tData 0.367 (0.367)\tLoss 1.4625 (1.4625)\tPrec 42.969% (42.969%)\n",
      "Epoch: [59][100/391]\tTime 0.057 (0.061)\tData 0.002 (0.009)\tLoss 1.3259 (1.4283)\tPrec 49.219% (47.494%)\n",
      "Epoch: [59][200/391]\tTime 0.062 (0.059)\tData 0.014 (0.006)\tLoss 1.6581 (1.4334)\tPrec 39.844% (47.132%)\n",
      "Epoch: [59][300/391]\tTime 0.064 (0.058)\tData 0.024 (0.006)\tLoss 1.4757 (1.4292)\tPrec 41.406% (47.093%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.413 (0.413)\tLoss 1.4099 (1.4099)\tPrec 53.906% (53.906%)\n",
      " * Prec 48.010% \n",
      "best acc: 49.140000\n",
      "Epoch: [60][0/391]\tTime 0.542 (0.542)\tData 0.497 (0.497)\tLoss 1.5607 (1.5607)\tPrec 45.312% (45.312%)\n",
      "Epoch: [60][100/391]\tTime 0.053 (0.061)\tData 0.002 (0.011)\tLoss 1.3326 (1.4149)\tPrec 52.344% (47.679%)\n",
      "Epoch: [60][200/391]\tTime 0.046 (0.057)\tData 0.002 (0.007)\tLoss 1.3181 (1.4123)\tPrec 55.469% (47.707%)\n",
      "Epoch: [60][300/391]\tTime 0.047 (0.056)\tData 0.002 (0.005)\tLoss 1.4441 (1.4187)\tPrec 44.531% (47.763%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.458 (0.458)\tLoss 1.4244 (1.4244)\tPrec 47.656% (47.656%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 48.920% \n",
      "best acc: 49.140000\n",
      "Epoch: [61][0/391]\tTime 0.543 (0.543)\tData 0.497 (0.497)\tLoss 1.4450 (1.4450)\tPrec 46.875% (46.875%)\n",
      "Epoch: [61][100/391]\tTime 0.054 (0.060)\tData 0.002 (0.008)\tLoss 1.3737 (1.4288)\tPrec 50.000% (47.300%)\n",
      "Epoch: [61][200/391]\tTime 0.059 (0.058)\tData 0.003 (0.006)\tLoss 1.4236 (1.4312)\tPrec 45.312% (47.225%)\n",
      "Epoch: [61][300/391]\tTime 0.053 (0.057)\tData 0.002 (0.005)\tLoss 1.5050 (1.4285)\tPrec 46.094% (47.394%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.335 (0.335)\tLoss 1.4926 (1.4926)\tPrec 44.531% (44.531%)\n",
      " * Prec 47.930% \n",
      "best acc: 49.140000\n",
      "Epoch: [62][0/391]\tTime 0.378 (0.378)\tData 0.320 (0.320)\tLoss 1.5191 (1.5191)\tPrec 37.500% (37.500%)\n",
      "Epoch: [62][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.008)\tLoss 1.4770 (1.4294)\tPrec 50.781% (47.687%)\n",
      "Epoch: [62][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.5180 (1.4522)\tPrec 46.875% (46.856%)\n",
      "Epoch: [62][300/391]\tTime 0.056 (0.057)\tData 0.004 (0.005)\tLoss 1.6442 (1.4579)\tPrec 42.969% (46.442%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 1.4497 (1.4497)\tPrec 48.438% (48.438%)\n",
      " * Prec 48.120% \n",
      "best acc: 49.140000\n",
      "Epoch: [63][0/391]\tTime 0.426 (0.426)\tData 0.384 (0.384)\tLoss 1.5028 (1.5028)\tPrec 47.656% (47.656%)\n",
      "Epoch: [63][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.007)\tLoss 1.5625 (1.4606)\tPrec 40.625% (46.078%)\n",
      "Epoch: [63][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.3488 (1.4426)\tPrec 52.344% (46.859%)\n",
      "Epoch: [63][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.4105 (1.4395)\tPrec 49.219% (46.989%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.408 (0.408)\tLoss 1.5301 (1.5301)\tPrec 45.312% (45.312%)\n",
      " * Prec 45.230% \n",
      "best acc: 49.140000\n",
      "Epoch: [64][0/391]\tTime 0.468 (0.468)\tData 0.423 (0.423)\tLoss 1.5589 (1.5589)\tPrec 45.312% (45.312%)\n",
      "Epoch: [64][100/391]\tTime 0.053 (0.060)\tData 0.002 (0.008)\tLoss 1.4366 (1.4467)\tPrec 47.656% (46.751%)\n",
      "Epoch: [64][200/391]\tTime 0.058 (0.057)\tData 0.002 (0.005)\tLoss 1.4492 (1.4381)\tPrec 46.875% (47.120%)\n",
      "Epoch: [64][300/391]\tTime 0.059 (0.056)\tData 0.002 (0.004)\tLoss 1.4240 (1.4336)\tPrec 42.188% (47.272%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.436 (0.436)\tLoss 1.4281 (1.4281)\tPrec 50.000% (50.000%)\n",
      " * Prec 48.910% \n",
      "best acc: 49.140000\n",
      "Epoch: [65][0/391]\tTime 0.461 (0.461)\tData 0.405 (0.405)\tLoss 1.2856 (1.2856)\tPrec 50.000% (50.000%)\n",
      "Epoch: [65][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.006)\tLoss 1.3904 (1.4405)\tPrec 49.219% (47.447%)\n",
      "Epoch: [65][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.004)\tLoss 1.4894 (1.4341)\tPrec 43.750% (47.069%)\n",
      "Epoch: [65][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.3093 (1.4346)\tPrec 49.219% (47.062%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.440 (0.440)\tLoss 1.4030 (1.4030)\tPrec 48.438% (48.438%)\n",
      " * Prec 46.040% \n",
      "best acc: 49.140000\n",
      "Epoch: [66][0/391]\tTime 0.486 (0.486)\tData 0.441 (0.441)\tLoss 1.4492 (1.4492)\tPrec 44.531% (44.531%)\n",
      "Epoch: [66][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.008)\tLoss 1.4697 (1.4335)\tPrec 47.656% (47.416%)\n",
      "Epoch: [66][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.005)\tLoss 1.5055 (1.4299)\tPrec 42.969% (47.248%)\n",
      "Epoch: [66][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.004)\tLoss 1.4393 (1.4337)\tPrec 43.750% (47.124%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.386 (0.386)\tLoss 1.4114 (1.4114)\tPrec 53.125% (53.125%)\n",
      " * Prec 48.730% \n",
      "best acc: 49.140000\n",
      "Epoch: [67][0/391]\tTime 0.376 (0.376)\tData 0.334 (0.334)\tLoss 1.3997 (1.3997)\tPrec 46.094% (46.094%)\n",
      "Epoch: [67][100/391]\tTime 0.051 (0.060)\tData 0.001 (0.008)\tLoss 1.5593 (1.4216)\tPrec 41.406% (47.308%)\n",
      "Epoch: [67][200/391]\tTime 0.055 (0.058)\tData 0.007 (0.006)\tLoss 1.3838 (1.4306)\tPrec 53.125% (47.264%)\n",
      "Epoch: [67][300/391]\tTime 0.050 (0.057)\tData 0.002 (0.005)\tLoss 1.4717 (1.4310)\tPrec 45.312% (47.337%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.338 (0.338)\tLoss 1.4860 (1.4860)\tPrec 47.656% (47.656%)\n",
      " * Prec 45.660% \n",
      "best acc: 49.140000\n",
      "Epoch: [68][0/391]\tTime 0.518 (0.518)\tData 0.456 (0.456)\tLoss 1.3846 (1.3846)\tPrec 50.781% (50.781%)\n",
      "Epoch: [68][100/391]\tTime 0.058 (0.061)\tData 0.003 (0.008)\tLoss 1.3744 (1.4462)\tPrec 53.125% (47.440%)\n",
      "Epoch: [68][200/391]\tTime 0.061 (0.059)\tData 0.025 (0.007)\tLoss 1.3692 (1.4310)\tPrec 50.781% (47.738%)\n",
      "Epoch: [68][300/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.3910 (1.4296)\tPrec 54.688% (47.685%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.427 (0.427)\tLoss 1.3722 (1.3722)\tPrec 51.562% (51.562%)\n",
      " * Prec 49.460% \n",
      "best acc: 49.460000\n",
      "Epoch: [69][0/391]\tTime 0.347 (0.347)\tData 0.298 (0.298)\tLoss 1.2606 (1.2606)\tPrec 50.000% (50.000%)\n",
      "Epoch: [69][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.006)\tLoss 1.2953 (1.4305)\tPrec 53.906% (47.099%)\n",
      "Epoch: [69][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.005)\tLoss 1.5145 (1.4334)\tPrec 42.188% (46.731%)\n",
      "Epoch: [69][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.005)\tLoss 1.3267 (1.4268)\tPrec 57.812% (47.106%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.370 (0.370)\tLoss 1.3456 (1.3456)\tPrec 50.000% (50.000%)\n",
      " * Prec 49.160% \n",
      "best acc: 49.460000\n",
      "Epoch: [70][0/391]\tTime 0.576 (0.576)\tData 0.530 (0.530)\tLoss 1.2616 (1.2616)\tPrec 55.469% (55.469%)\n",
      "Epoch: [70][100/391]\tTime 0.052 (0.061)\tData 0.003 (0.009)\tLoss 1.5090 (1.4089)\tPrec 47.656% (48.066%)\n",
      "Epoch: [70][200/391]\tTime 0.054 (0.059)\tData 0.002 (0.007)\tLoss 1.4991 (1.4152)\tPrec 46.875% (47.582%)\n",
      "Epoch: [70][300/391]\tTime 0.069 (0.057)\tData 0.002 (0.006)\tLoss 1.4086 (1.4218)\tPrec 48.438% (47.386%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.340 (0.340)\tLoss 1.3979 (1.3979)\tPrec 47.656% (47.656%)\n",
      " * Prec 47.970% \n",
      "best acc: 49.460000\n",
      "Epoch: [71][0/391]\tTime 0.373 (0.373)\tData 0.328 (0.328)\tLoss 1.2982 (1.2982)\tPrec 52.344% (52.344%)\n",
      "Epoch: [71][100/391]\tTime 0.056 (0.058)\tData 0.004 (0.007)\tLoss 1.4689 (1.4117)\tPrec 46.875% (47.873%)\n",
      "Epoch: [71][200/391]\tTime 0.073 (0.059)\tData 0.002 (0.006)\tLoss 1.3753 (1.4166)\tPrec 46.875% (47.952%)\n",
      "Epoch: [71][300/391]\tTime 0.055 (0.058)\tData 0.003 (0.005)\tLoss 1.3922 (1.4192)\tPrec 50.000% (47.698%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.472 (0.472)\tLoss 1.4733 (1.4733)\tPrec 44.531% (44.531%)\n",
      " * Prec 48.490% \n",
      "best acc: 49.460000\n",
      "Epoch: [72][0/391]\tTime 0.547 (0.547)\tData 0.471 (0.471)\tLoss 1.3953 (1.3953)\tPrec 51.562% (51.562%)\n",
      "Epoch: [72][100/391]\tTime 0.054 (0.065)\tData 0.004 (0.009)\tLoss 1.4362 (1.4644)\tPrec 44.531% (46.666%)\n",
      "Epoch: [72][200/391]\tTime 0.048 (0.062)\tData 0.002 (0.007)\tLoss 1.3506 (1.4536)\tPrec 51.562% (47.027%)\n",
      "Epoch: [72][300/391]\tTime 0.058 (0.060)\tData 0.002 (0.006)\tLoss 1.4591 (1.4511)\tPrec 45.312% (46.937%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.440 (0.440)\tLoss 1.4322 (1.4322)\tPrec 50.000% (50.000%)\n",
      " * Prec 47.650% \n",
      "best acc: 49.460000\n",
      "Epoch: [73][0/391]\tTime 0.486 (0.486)\tData 0.427 (0.427)\tLoss 1.5217 (1.5217)\tPrec 45.312% (45.312%)\n",
      "Epoch: [73][100/391]\tTime 0.055 (0.060)\tData 0.015 (0.011)\tLoss 1.5501 (1.4967)\tPrec 43.750% (44.601%)\n",
      "Epoch: [73][200/391]\tTime 0.054 (0.058)\tData 0.014 (0.007)\tLoss 1.5289 (1.4789)\tPrec 41.406% (45.037%)\n",
      "Epoch: [73][300/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.5884 (1.4703)\tPrec 43.750% (45.437%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 1.5539 (1.5539)\tPrec 41.406% (41.406%)\n",
      " * Prec 44.800% \n",
      "best acc: 49.460000\n",
      "Epoch: [74][0/391]\tTime 0.492 (0.492)\tData 0.447 (0.447)\tLoss 1.3444 (1.3444)\tPrec 52.344% (52.344%)\n",
      "Epoch: [74][100/391]\tTime 0.063 (0.061)\tData 0.005 (0.008)\tLoss 1.4868 (1.4604)\tPrec 47.656% (46.272%)\n",
      "Epoch: [74][200/391]\tTime 0.053 (0.059)\tData 0.002 (0.008)\tLoss 1.4082 (1.4528)\tPrec 50.000% (46.630%)\n",
      "Epoch: [74][300/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.3635 (1.4530)\tPrec 42.969% (46.486%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.575 (0.575)\tLoss 1.4490 (1.4490)\tPrec 46.094% (46.094%)\n",
      " * Prec 48.200% \n",
      "best acc: 49.460000\n",
      "Epoch: [75][0/391]\tTime 0.479 (0.479)\tData 0.419 (0.419)\tLoss 1.4695 (1.4695)\tPrec 44.531% (44.531%)\n",
      "Epoch: [75][100/391]\tTime 0.053 (0.062)\tData 0.004 (0.009)\tLoss 1.4090 (1.4490)\tPrec 47.656% (46.682%)\n",
      "Epoch: [75][200/391]\tTime 0.055 (0.058)\tData 0.003 (0.006)\tLoss 1.4122 (1.4505)\tPrec 48.438% (46.630%)\n",
      "Epoch: [75][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.005)\tLoss 1.4124 (1.4465)\tPrec 46.094% (46.688%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.495 (0.495)\tLoss 1.4657 (1.4657)\tPrec 44.531% (44.531%)\n",
      " * Prec 47.160% \n",
      "best acc: 49.460000\n",
      "Epoch: [76][0/391]\tTime 0.565 (0.565)\tData 0.521 (0.521)\tLoss 1.5430 (1.5430)\tPrec 40.625% (40.625%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][100/391]\tTime 0.057 (0.061)\tData 0.020 (0.011)\tLoss 1.4275 (1.4559)\tPrec 46.875% (45.854%)\n",
      "Epoch: [76][200/391]\tTime 0.052 (0.058)\tData 0.002 (0.008)\tLoss 1.3756 (1.4495)\tPrec 50.000% (46.517%)\n",
      "Epoch: [76][300/391]\tTime 0.079 (0.057)\tData 0.006 (0.006)\tLoss 1.5258 (1.4480)\tPrec 39.062% (46.468%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.394 (0.394)\tLoss 1.4530 (1.4530)\tPrec 46.094% (46.094%)\n",
      " * Prec 48.750% \n",
      "best acc: 49.460000\n",
      "Epoch: [77][0/391]\tTime 0.499 (0.499)\tData 0.453 (0.453)\tLoss 1.4417 (1.4417)\tPrec 46.875% (46.875%)\n",
      "Epoch: [77][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.007)\tLoss 1.4769 (1.4520)\tPrec 42.188% (46.627%)\n",
      "Epoch: [77][200/391]\tTime 0.062 (0.057)\tData 0.001 (0.005)\tLoss 1.4466 (1.4475)\tPrec 46.875% (47.093%)\n",
      "Epoch: [77][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.004)\tLoss 1.4391 (1.4396)\tPrec 48.438% (47.192%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.422 (0.422)\tLoss 1.4649 (1.4649)\tPrec 46.094% (46.094%)\n",
      " * Prec 48.450% \n",
      "best acc: 49.460000\n",
      "Epoch: [78][0/391]\tTime 0.545 (0.545)\tData 0.483 (0.483)\tLoss 1.4801 (1.4801)\tPrec 50.000% (50.000%)\n",
      "Epoch: [78][100/391]\tTime 0.053 (0.061)\tData 0.002 (0.008)\tLoss 1.6447 (1.4379)\tPrec 41.406% (46.511%)\n",
      "Epoch: [78][200/391]\tTime 0.047 (0.058)\tData 0.002 (0.005)\tLoss 1.5246 (1.4404)\tPrec 43.750% (46.525%)\n",
      "Epoch: [78][300/391]\tTime 0.053 (0.057)\tData 0.003 (0.005)\tLoss 1.5755 (1.4402)\tPrec 48.438% (46.849%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.334 (0.334)\tLoss 1.4757 (1.4757)\tPrec 42.188% (42.188%)\n",
      " * Prec 47.190% \n",
      "best acc: 49.460000\n",
      "Epoch: [79][0/391]\tTime 0.407 (0.407)\tData 0.363 (0.363)\tLoss 1.6511 (1.6511)\tPrec 44.531% (44.531%)\n",
      "Epoch: [79][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.008)\tLoss 1.6208 (1.4295)\tPrec 44.531% (47.215%)\n",
      "Epoch: [79][200/391]\tTime 0.054 (0.057)\tData 0.001 (0.006)\tLoss 1.4395 (1.4277)\tPrec 45.312% (47.205%)\n",
      "Epoch: [79][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.005)\tLoss 1.6095 (1.4225)\tPrec 36.719% (47.368%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.433 (0.433)\tLoss 1.4024 (1.4024)\tPrec 46.875% (46.875%)\n",
      " * Prec 49.420% \n",
      "best acc: 49.460000\n",
      "Epoch: [80][0/391]\tTime 0.529 (0.529)\tData 0.481 (0.481)\tLoss 1.3969 (1.3969)\tPrec 47.656% (47.656%)\n",
      "Epoch: [80][100/391]\tTime 0.052 (0.060)\tData 0.002 (0.009)\tLoss 1.6032 (1.4356)\tPrec 40.625% (47.246%)\n",
      "Epoch: [80][200/391]\tTime 0.055 (0.057)\tData 0.002 (0.006)\tLoss 1.5402 (1.4267)\tPrec 40.625% (47.493%)\n",
      "Epoch: [80][300/391]\tTime 0.054 (0.056)\tData 0.003 (0.005)\tLoss 1.5691 (1.4231)\tPrec 44.531% (47.729%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.390 (0.390)\tLoss 1.3910 (1.3910)\tPrec 46.875% (46.875%)\n",
      " * Prec 47.430% \n",
      "best acc: 49.460000\n",
      "Epoch: [81][0/391]\tTime 0.574 (0.574)\tData 0.513 (0.513)\tLoss 1.3838 (1.3838)\tPrec 41.406% (41.406%)\n",
      "Epoch: [81][100/391]\tTime 0.058 (0.060)\tData 0.002 (0.008)\tLoss 1.4171 (1.4194)\tPrec 46.094% (48.082%)\n",
      "Epoch: [81][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.4777 (1.4242)\tPrec 50.000% (47.660%)\n",
      "Epoch: [81][300/391]\tTime 0.051 (0.056)\tData 0.002 (0.005)\tLoss 1.3044 (1.4209)\tPrec 51.562% (47.752%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.434 (0.434)\tLoss 1.3655 (1.3655)\tPrec 47.656% (47.656%)\n",
      " * Prec 49.480% \n",
      "best acc: 49.480000\n",
      "Epoch: [82][0/391]\tTime 0.512 (0.512)\tData 0.472 (0.472)\tLoss 1.4176 (1.4176)\tPrec 46.875% (46.875%)\n",
      "Epoch: [82][100/391]\tTime 0.060 (0.059)\tData 0.015 (0.007)\tLoss 1.5254 (1.4235)\tPrec 42.969% (47.625%)\n",
      "Epoch: [82][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.005)\tLoss 1.4775 (1.4208)\tPrec 48.438% (47.722%)\n",
      "Epoch: [82][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.004)\tLoss 1.3247 (1.4260)\tPrec 46.875% (47.488%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.360 (0.360)\tLoss 1.3634 (1.3634)\tPrec 49.219% (49.219%)\n",
      " * Prec 49.830% \n",
      "best acc: 49.830000\n",
      "Epoch: [83][0/391]\tTime 0.536 (0.536)\tData 0.497 (0.497)\tLoss 1.6324 (1.6324)\tPrec 40.625% (40.625%)\n",
      "Epoch: [83][100/391]\tTime 0.059 (0.063)\tData 0.002 (0.011)\tLoss 1.5621 (1.4257)\tPrec 41.406% (47.532%)\n",
      "Epoch: [83][200/391]\tTime 0.053 (0.058)\tData 0.002 (0.006)\tLoss 1.4604 (1.4232)\tPrec 46.094% (47.330%)\n",
      "Epoch: [83][300/391]\tTime 0.054 (0.057)\tData 0.002 (0.005)\tLoss 1.3584 (1.4213)\tPrec 49.219% (47.404%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.450 (0.450)\tLoss 1.3996 (1.3996)\tPrec 46.094% (46.094%)\n",
      " * Prec 48.960% \n",
      "best acc: 49.830000\n",
      "Epoch: [84][0/391]\tTime 0.541 (0.541)\tData 0.501 (0.501)\tLoss 1.4577 (1.4577)\tPrec 45.312% (45.312%)\n",
      "Epoch: [84][100/391]\tTime 0.053 (0.061)\tData 0.002 (0.011)\tLoss 1.3418 (1.4154)\tPrec 47.656% (47.672%)\n",
      "Epoch: [84][200/391]\tTime 0.051 (0.059)\tData 0.002 (0.007)\tLoss 1.4381 (1.4250)\tPrec 45.312% (47.120%)\n",
      "Epoch: [84][300/391]\tTime 0.053 (0.058)\tData 0.002 (0.006)\tLoss 1.4989 (1.4215)\tPrec 41.406% (47.407%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.309 (0.309)\tLoss 1.4046 (1.4046)\tPrec 49.219% (49.219%)\n",
      " * Prec 48.210% \n",
      "best acc: 49.830000\n",
      "Epoch: [85][0/391]\tTime 0.455 (0.455)\tData 0.402 (0.402)\tLoss 1.4639 (1.4639)\tPrec 42.188% (42.188%)\n",
      "Epoch: [85][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.007)\tLoss 1.3044 (1.4014)\tPrec 52.344% (48.051%)\n",
      "Epoch: [85][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.006)\tLoss 1.4231 (1.4140)\tPrec 42.969% (47.932%)\n",
      "Epoch: [85][300/391]\tTime 0.060 (0.056)\tData 0.001 (0.005)\tLoss 1.4190 (1.4123)\tPrec 41.406% (47.996%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.370 (0.370)\tLoss 1.3851 (1.3851)\tPrec 48.438% (48.438%)\n",
      " * Prec 48.420% \n",
      "best acc: 49.830000\n",
      "Epoch: [86][0/391]\tTime 0.436 (0.436)\tData 0.377 (0.377)\tLoss 1.5403 (1.5403)\tPrec 41.406% (41.406%)\n",
      "Epoch: [86][100/391]\tTime 0.053 (0.058)\tData 0.003 (0.006)\tLoss 1.3466 (1.4181)\tPrec 51.562% (47.795%)\n",
      "Epoch: [86][200/391]\tTime 0.055 (0.056)\tData 0.003 (0.004)\tLoss 1.3553 (1.4183)\tPrec 52.344% (47.750%)\n",
      "Epoch: [86][300/391]\tTime 0.054 (0.055)\tData 0.002 (0.004)\tLoss 1.2778 (1.4141)\tPrec 52.344% (47.757%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.392 (0.392)\tLoss 1.4480 (1.4480)\tPrec 45.312% (45.312%)\n",
      " * Prec 48.800% \n",
      "best acc: 49.830000\n",
      "Epoch: [87][0/391]\tTime 0.362 (0.362)\tData 0.316 (0.316)\tLoss 1.3310 (1.3310)\tPrec 53.906% (53.906%)\n",
      "Epoch: [87][100/391]\tTime 0.054 (0.057)\tData 0.004 (0.006)\tLoss 1.4038 (1.4185)\tPrec 46.094% (47.765%)\n",
      "Epoch: [87][200/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 1.3958 (1.4218)\tPrec 44.531% (47.489%)\n",
      "Epoch: [87][300/391]\tTime 0.053 (0.055)\tData 0.002 (0.004)\tLoss 1.4951 (1.4156)\tPrec 45.312% (47.854%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.343 (0.343)\tLoss 1.4355 (1.4355)\tPrec 42.969% (42.969%)\n",
      " * Prec 48.270% \n",
      "best acc: 49.830000\n",
      "Epoch: [88][0/391]\tTime 0.511 (0.511)\tData 0.431 (0.431)\tLoss 1.2568 (1.2568)\tPrec 57.031% (57.031%)\n",
      "Epoch: [88][100/391]\tTime 0.058 (0.060)\tData 0.002 (0.007)\tLoss 1.4749 (1.4052)\tPrec 37.500% (48.407%)\n",
      "Epoch: [88][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.005)\tLoss 1.6705 (1.4064)\tPrec 37.500% (48.535%)\n",
      "Epoch: [88][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.4089 (1.4082)\tPrec 46.875% (48.422%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.427 (0.427)\tLoss 1.3308 (1.3308)\tPrec 50.000% (50.000%)\n",
      " * Prec 51.080% \n",
      "best acc: 51.080000\n",
      "Epoch: [89][0/391]\tTime 0.561 (0.561)\tData 0.492 (0.492)\tLoss 1.4113 (1.4113)\tPrec 48.438% (48.438%)\n",
      "Epoch: [89][100/391]\tTime 0.054 (0.061)\tData 0.006 (0.008)\tLoss 1.4557 (1.4148)\tPrec 42.969% (47.935%)\n",
      "Epoch: [89][200/391]\tTime 0.054 (0.059)\tData 0.002 (0.007)\tLoss 1.3633 (1.4094)\tPrec 47.656% (48.204%)\n",
      "Epoch: [89][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.005)\tLoss 1.2258 (1.4084)\tPrec 57.812% (48.191%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 1.4205 (1.4205)\tPrec 49.219% (49.219%)\n",
      " * Prec 47.220% \n",
      "best acc: 51.080000\n",
      "Epoch: [90][0/391]\tTime 0.380 (0.380)\tData 0.329 (0.329)\tLoss 1.3241 (1.3241)\tPrec 52.344% (52.344%)\n",
      "Epoch: [90][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.006)\tLoss 1.3244 (1.4061)\tPrec 53.125% (48.422%)\n",
      "Epoch: [90][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.004)\tLoss 1.3697 (1.4019)\tPrec 52.344% (48.434%)\n",
      "Epoch: [90][300/391]\tTime 0.053 (0.055)\tData 0.002 (0.003)\tLoss 1.4194 (1.4090)\tPrec 44.531% (48.206%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.327 (0.327)\tLoss 1.4542 (1.4542)\tPrec 39.844% (39.844%)\n",
      " * Prec 49.900% \n",
      "best acc: 51.080000\n",
      "Epoch: [91][0/391]\tTime 0.329 (0.329)\tData 0.289 (0.289)\tLoss 1.2851 (1.2851)\tPrec 50.000% (50.000%)\n",
      "Epoch: [91][100/391]\tTime 0.081 (0.059)\tData 0.002 (0.006)\tLoss 1.3834 (1.4102)\tPrec 43.750% (48.260%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][200/391]\tTime 0.047 (0.057)\tData 0.002 (0.004)\tLoss 1.3721 (1.4155)\tPrec 56.250% (48.002%)\n",
      "Epoch: [91][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.004)\tLoss 1.3509 (1.4103)\tPrec 47.656% (48.061%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.457 (0.457)\tLoss 1.3494 (1.3494)\tPrec 50.000% (50.000%)\n",
      " * Prec 49.530% \n",
      "best acc: 51.080000\n",
      "Epoch: [92][0/391]\tTime 0.535 (0.535)\tData 0.478 (0.478)\tLoss 1.4185 (1.4185)\tPrec 48.438% (48.438%)\n",
      "Epoch: [92][100/391]\tTime 0.053 (0.062)\tData 0.002 (0.009)\tLoss 1.5184 (1.4027)\tPrec 45.312% (48.468%)\n",
      "Epoch: [92][200/391]\tTime 0.066 (0.059)\tData 0.002 (0.006)\tLoss 1.3316 (1.4125)\tPrec 50.781% (47.956%)\n",
      "Epoch: [92][300/391]\tTime 0.054 (0.058)\tData 0.002 (0.005)\tLoss 1.3324 (1.4134)\tPrec 50.000% (47.924%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.392 (0.392)\tLoss 1.3474 (1.3474)\tPrec 51.562% (51.562%)\n",
      " * Prec 49.950% \n",
      "best acc: 51.080000\n",
      "Epoch: [93][0/391]\tTime 0.405 (0.405)\tData 0.358 (0.358)\tLoss 1.4455 (1.4455)\tPrec 43.750% (43.750%)\n",
      "Epoch: [93][100/391]\tTime 0.054 (0.059)\tData 0.010 (0.008)\tLoss 1.4446 (1.4026)\tPrec 47.656% (48.028%)\n",
      "Epoch: [93][200/391]\tTime 0.082 (0.058)\tData 0.002 (0.006)\tLoss 1.4686 (1.4084)\tPrec 44.531% (48.127%)\n",
      "Epoch: [93][300/391]\tTime 0.071 (0.058)\tData 0.006 (0.006)\tLoss 1.4178 (1.4041)\tPrec 44.531% (48.414%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.539 (0.539)\tLoss 1.4584 (1.4584)\tPrec 45.312% (45.312%)\n",
      " * Prec 47.560% \n",
      "best acc: 51.080000\n",
      "Epoch: [94][0/391]\tTime 0.408 (0.408)\tData 0.357 (0.357)\tLoss 1.4394 (1.4394)\tPrec 53.125% (53.125%)\n",
      "Epoch: [94][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.007)\tLoss 1.5958 (1.4057)\tPrec 42.969% (47.594%)\n",
      "Epoch: [94][200/391]\tTime 0.054 (0.056)\tData 0.005 (0.005)\tLoss 1.4933 (1.3960)\tPrec 48.438% (48.033%)\n",
      "Epoch: [94][300/391]\tTime 0.054 (0.055)\tData 0.002 (0.005)\tLoss 1.4375 (1.3992)\tPrec 50.781% (48.225%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.258 (0.258)\tLoss 1.3052 (1.3052)\tPrec 52.344% (52.344%)\n",
      " * Prec 50.920% \n",
      "best acc: 51.080000\n",
      "Epoch: [95][0/391]\tTime 0.387 (0.387)\tData 0.311 (0.311)\tLoss 1.2811 (1.2811)\tPrec 58.594% (58.594%)\n",
      "Epoch: [95][100/391]\tTime 0.067 (0.060)\tData 0.002 (0.010)\tLoss 1.3381 (1.4040)\tPrec 53.906% (48.236%)\n",
      "Epoch: [95][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.006)\tLoss 1.4047 (1.4010)\tPrec 43.750% (48.667%)\n",
      "Epoch: [95][300/391]\tTime 0.057 (0.056)\tData 0.002 (0.005)\tLoss 1.2893 (1.3950)\tPrec 60.938% (48.946%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.362 (0.362)\tLoss 1.3918 (1.3918)\tPrec 46.875% (46.875%)\n",
      " * Prec 50.280% \n",
      "best acc: 51.080000\n",
      "Epoch: [96][0/391]\tTime 0.508 (0.508)\tData 0.464 (0.464)\tLoss 1.4181 (1.4181)\tPrec 50.000% (50.000%)\n",
      "Epoch: [96][100/391]\tTime 0.058 (0.061)\tData 0.002 (0.011)\tLoss 1.3611 (1.4145)\tPrec 49.219% (48.190%)\n",
      "Epoch: [96][200/391]\tTime 0.053 (0.057)\tData 0.005 (0.007)\tLoss 1.2730 (1.4082)\tPrec 54.688% (48.208%)\n",
      "Epoch: [96][300/391]\tTime 0.049 (0.056)\tData 0.003 (0.006)\tLoss 1.4056 (1.4209)\tPrec 50.000% (47.991%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.450 (0.450)\tLoss 1.3383 (1.3383)\tPrec 53.125% (53.125%)\n",
      " * Prec 50.410% \n",
      "best acc: 51.080000\n",
      "Epoch: [97][0/391]\tTime 0.486 (0.486)\tData 0.446 (0.446)\tLoss 1.3807 (1.3807)\tPrec 50.781% (50.781%)\n",
      "Epoch: [97][100/391]\tTime 0.052 (0.060)\tData 0.002 (0.008)\tLoss 1.3300 (1.3995)\tPrec 51.562% (48.832%)\n",
      "Epoch: [97][200/391]\tTime 0.047 (0.058)\tData 0.006 (0.006)\tLoss 1.3329 (1.3979)\tPrec 53.906% (48.585%)\n",
      "Epoch: [97][300/391]\tTime 0.054 (0.057)\tData 0.003 (0.005)\tLoss 1.3154 (1.4022)\tPrec 51.562% (48.412%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.430 (0.430)\tLoss 1.3926 (1.3926)\tPrec 49.219% (49.219%)\n",
      " * Prec 49.820% \n",
      "best acc: 51.080000\n",
      "Epoch: [98][0/391]\tTime 0.444 (0.444)\tData 0.402 (0.402)\tLoss 1.4189 (1.4189)\tPrec 41.406% (41.406%)\n",
      "Epoch: [98][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.006)\tLoss 1.4313 (1.4506)\tPrec 44.531% (46.403%)\n",
      "Epoch: [98][200/391]\tTime 0.054 (0.056)\tData 0.001 (0.005)\tLoss 1.4808 (1.4403)\tPrec 46.875% (46.902%)\n",
      "Epoch: [98][300/391]\tTime 0.054 (0.055)\tData 0.005 (0.004)\tLoss 1.4150 (1.4333)\tPrec 45.312% (47.295%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.338 (0.338)\tLoss 1.4095 (1.4095)\tPrec 42.969% (42.969%)\n",
      " * Prec 48.450% \n",
      "best acc: 51.080000\n",
      "Epoch: [99][0/391]\tTime 0.479 (0.479)\tData 0.439 (0.439)\tLoss 1.3987 (1.3987)\tPrec 45.312% (45.312%)\n",
      "Epoch: [99][100/391]\tTime 0.066 (0.058)\tData 0.004 (0.008)\tLoss 1.3597 (1.4225)\tPrec 44.531% (47.563%)\n",
      "Epoch: [99][200/391]\tTime 0.078 (0.057)\tData 0.002 (0.006)\tLoss 1.3809 (1.4161)\tPrec 46.094% (48.033%)\n",
      "Epoch: [99][300/391]\tTime 0.054 (0.057)\tData 0.006 (0.005)\tLoss 1.4364 (1.4114)\tPrec 46.094% (48.152%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.498 (0.498)\tLoss 1.4283 (1.4283)\tPrec 44.531% (44.531%)\n",
      " * Prec 47.590% \n",
      "best acc: 51.080000\n"
     ]
    }
   ],
   "source": [
    "## Start finetuning (training here), and see how much you can recover your accuracy ##\n",
    "## You can change hyper parameters such as epochs or lr ##\n",
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)+\"_pruning_structured\"\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "    \n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec': best_prec,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, fdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thick-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 5108/10000 (51%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check your accuracy again after finetuning\n",
    "PATH = \"result/VGG16_quant_pruning_structured/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "driving-tanzania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "7 -th layer prehooked\n",
      "12 -th layer prehooked\n",
      "16 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "29 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "38 -th layer prehooked\n",
      "42 -th layer prehooked\n",
      "47 -th layer prehooked\n",
      "51 -th layer prehooked\n",
      "55 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "## Send an image and use prehook to grab the inputs of all the QuantConv2d layers\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "furnished-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "##### Find \"weight_int\" for features[3] ####\n",
    "w_bit = 4\n",
    "weight_q = model.features[3].weight_q\n",
    "w_alpha = model.features[3].weight_quant.wgt_alpha\n",
    "w_delta = w_alpha /(2**(w_bit-1)-1)\n",
    "\n",
    "weight_int = weight_q / w_delta\n",
    "print(weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dated-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.0024, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#### check your sparsity for weight_int is near 90% #####\n",
    "#### Your sparsity could be >90% after quantization #####\n",
    "sparsity_weight_int = (weight_int == 0).sum() / weight_int.nelement()\n",
    "print(\"Sparsity level: \", sparsity_weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-excuse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-whole",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
